[{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Summary Report: ‚ÄúAI-Driven Development Life Cycle: Reimagining Software Engineering‚Äù Event Objectives Discuss how generative AI is reshaping modern software development. Present the AI-Driven Development Life Cycle (AI-DLC) and its main ideas. Showcase Kiro and Amazon Q Developer in practical demos. Speakers Toan Huynh ‚Äì Specialist SA, PACE My Nguyen ‚Äì Sr. Prototyping Architect, Amazon Web Services ‚Äì ASEAN Key Highlights The core theme was AI-DLC, a model where AI helps coordinate the development lifecycle (planning, breaking down work, suggesting architecture), while engineers stay accountable for review, decisions, and governance. - AI-DLC Core Concept: AI-DLC is human-centered: AI plays the role of a collaborator that amplifies developer productivity, with delivery cycles shortened from weeks/months down to hours/days.\n- AI-DLC Workflow: The flow is iterative, alternating between AI steps (drafting plans, implementing changes, asking questions) and human steps (clarifying intent, approving plans), so AI only executes once humans confirm the direction.\n- AI-DLC Stages: The lifecycle is grouped into three phases‚ÄîInception, Construction, and Operation‚Äîwhere each phase enriches the context for the next:\nInception: Capture context, refine intent via User Stories, and organize Units of Work.\nConstruction: Perform Domain Modeling, generate and test code, introduce architecture components, and deploy with IaC plus automated tests.\nOperation: Run in production and handle incidents and runtime operations.\n- Challenges AI-DLC Addresses:\nScaling AI development: Existing AI coding tools often struggle as systems grow more complex.\nLimited control: Current tools offer limited ways to supervise and coordinate AI agents effectively.\nCode quality: Maintaining production-grade quality when evolving from a PoC is difficult without more structure.\nDeep Dive: Kiro ‚Äì The AI IDE from Prototype to Production Kiro is an AI-first IDE built around AI-DLC concepts, emphasizing spec-driven development. - Spec-driven Development: From a single high-level prompt (for example, ‚Äúbuild a Slack-like chat app‚Äù), Kiro derives structured artifacts such as requirements (requirements.md), architecture and design (design.md), and task breakdowns (tasks.md), shifting the workflow from ad‚Äëhoc ‚Äúvibe coding‚Äù to a traceable, spec-first process. Developers work with these specs as the primary source of truth.\n- Agentic Workflows: Kiro‚Äôs agents execute against the spec while keeping developers in charge:\n+ Implementation Plan: Kiro produces a concrete implementation plan with starting tasks and subtasks (for example, ‚Äúadd user registration and login endpoints‚Äù, ‚Äúimplement JWT middleware‚Äù) and links each back to the original requirements for validation.\n+ Agent Hooks: Hooks dispatch work to AI agents on triggers like ‚Äúfile save‚Äù, allowing background automation such as documentation generation, unit test creation, or performance tuning.\nKey Takeaways - AI for Production-Grade Outputs: By generating detailed designs (for example, data flows and API contracts) and tests before writing code, Kiro helps ensure AI-generated code is closer to production-ready software rather than throwaway prototypes.\n- Human Control via Artifacts: Developers steer the system primarily by shaping and approving the artifacts‚Äîrequirements, design docs, and task plans‚Äîrather than manually writing all implementation details, while AI agents handle execution.\nApplying to Work - Use Amazon Q Developer / Similar Tools: Adopt AI coding assistants in academic or side projects to handle boilerplate and repetitive tasks, improving overall throughput.\n- Prioritize High-Value Work: Offload routine work to AI to focus on higher-value activities like Domain Modeling and Architectural Design, which remain key human responsibilities in the Construction phase.\nEvent Experience The AI-Driven Development Life Cycle: Reimagining Software Engineering session gave a clear view of where software engineering is heading. Generative AI was framed not just as a helper for writing code, but as an engine that can coordinate large parts of the lifecycle. The flow of the talk moved from the AI-DLC concepts into live demos with Amazon Q Developer and Kiro. The Kiro demo stood out, illustrating how a short prompt can be expanded into a complete, executable, and auditable development plan inside the IDE.\nLessons learned The pain points around scaling AI development, controlling AI behavior, and ensuring code quality make a structured, human-validated approach like AI-DLC feel both practical and necessary. Some event photos "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Lam Gia Kiet\nPhone Number: 0886659957\nEmail: lamgiakiet2005@gmail.com\nUniversity: FPTU Ho Chi Minh Campus\nMajor: Information Technology\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJA Cloud Intern\nInternship Duration: From 08/09/2025 to 12/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect with FCJ members and mentors. Find out what working in an office is like. Learn the basics of AWS, console and CLI. Learn how to use AWS pricing calculator. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon - Read internship rules - Create AWS account - Learnt what AWS is - Module 1 Lab 1 Done (Learnt how to create AWS account and manage user groups) - Module 1 Lab 7 Done (Learnt how to create budgets of using the service) - Lab 7-3 (Usage Budget) cannot be done, error in usage type dropdown, showing nothing - Module 1 Lab 9 Done (Learnt about AWS Support Services, its type, benefits and how to request supports) 08/09/2025 08/09/2025 Create new AWS Account MFA for AWS Accounts Create Admin Group and Admin User Account Authentication Support Explore and Configure AWS Management Console Creating Support Cases and Case Management in AWS Tue - Learnt overview of AWS Budgets and why cost management is important on AWS - Studied 4 main budget types: Cost Budget, Usage Budget, RI Budget, Savings Plans Budget - Practised creating Cost Budget to receive alerts when total cost exceeds thresholds - Practised creating Usage Budget to monitor usage of specific services such as EC2 hours - Learnt the difference between RI Budget and Savings Plans Budget and how they help reduce long‚Äëterm instance costs - Reviewed best practices for setting alert thresholds and notification recipients 09/09/2025 09/09/2025 B·∫Øt ƒë·∫ßu v·ªõi AWS Budget T·∫°o Cost Budget T·∫°o Usage Budget T·∫°o RI Budget T·∫°o Savings Plans Budget Wed - Learnt overview of AWS Identity and Access Management (IAM) - Studied core IAM concepts: IAM Users, IAM Groups, IAM Roles and IAM Policies - Practised creating IAM Groups and IAM Users for admin access - Attached and tested IAM Policies following the principle of least privilege - Created IAM Roles to provide temporary access instead of attaching long‚Äëterm credentials - Practised switching roles between accounts and verifying access - Reviewed IAM security best practices such as using CloudTrail to monitor access and cleaning up unused users/roles 10/09/2025 10/09/2025 Gi·ªõi thi·ªáu IAM T·∫°o IAM Group v√† IAM User T·∫°o IAM Role Chuy·ªÉn ƒë·ªïi IAM Role Thu - Learnt overview of Amazon Virtual Private Cloud (VPC) and its role as the core networking service on AWS - Studied VPC components: subnets, route tables, internet gateway, NAT gateway and VPN gateway - Learnt about network security in VPC using Security Groups and Network ACLs - Practised deploying Amazon EC2 instances inside public and private subnets - Studied and practised setting up AWS Site-to-Site VPN between on-premises network and AWS VPC - Reviewed best practices for segmenting networks and monitoring traffic with VPC Flow Logs 11/09/2025 11/09/2025 Gi·ªõi thi·ªáu Amazon VPC Network Security v·ªõi Security Groups v√† NACLs Tri·ªÉn khai Amazon EC2 Instance Thi·∫øt l·∫≠p AWS Site-to-Site VPN Fri - Learnt overview of Amazon Elastic Compute Cloud (Amazon EC2) and its use cases - Reviewed prerequisites for working with EC2: key pairs, security groups and networking setup - Practised launching Windows EC2 instance and connecting via RDP - Practised launching Linux EC2 instance and connecting via SSH - Explored basic EC2 operations: start, stop, reboot, resize instance type and manage volumes - Deployed sample AWS User Management application on Linux and Windows EC2 instances using Node.js - Reviewed cost and usage governance for EC2 and cleaned up resources after the lab 12/09/2025 12/09/2025 Gi·ªõi thi·ªáu Amazon EC2 C√°c b∆∞·ªõc chu·∫©n b·ªã Kh·ªüi t·∫°o Windows instance Kh·ªüi t·∫°o Linux instance Amazon EC2 c∆° b·∫£n Tri·ªÉn khai ·ª©ng d·ª•ng Node.js tr√™n EC2 Week 1 Achievements: Built and secured a new AWS account, including MFA, admin IAM users and basic support case handling. Gained a solid foundation in AWS cost management by creating and testing multiple AWS Budgets with email alerts. Strengthened security and access governance using IAM users, groups, roles and least‚Äëprivilege policies. Designed and operated networking on AWS with Amazon VPC, including public/private subnets, security groups, NACLs and Site‚Äëto‚ÄëSite VPN. Deployed and managed Windows and Linux EC2 instances, including connecting via RDP/SSH and performing common EC2 operations. Successfully deployed a sample AWS User Management application on EC2 and practised cleaning up resources to control costs. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS and basic AWS services\nWeek 2: Doing task A\u0026hellip;\nWeek 3: Doing task B\u0026hellip;\nWeek 4: Doing task C\u0026hellip;\nWeek 5: Doing task D\u0026hellip;\nWeek 6: Doing task E\u0026hellip;\nWeek 7: Doing task G\u0026hellip;\nWeek 8: Doing task H\u0026hellip;\nWeek 9: Doing task I\u0026hellip;\nWeek 10: Doing task L\u0026hellip;\nWeek 11: Doing task M\u0026hellip;\nWeek 12: Doing task N\u0026hellip;\nWeek 13: Doing task N\u0026hellip;\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.9-alert-dispatch/","title":"Alert Dispatch Code","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # severity_num = finding.get(\u0026#39;severity\u0026#39;, 0) # if severity_num \u0026gt;= 7.0: # severity = \u0026#34;üî¥ HIGH\u0026#34; # elif severity_num \u0026gt;= 4.0: # severity = \u0026#34;üü† MEDIUM\u0026#34; # else: # severity = \u0026#34;üîµ LOW\u0026#34; # title = finding.get(\u0026#39;title\u0026#39;, \u0026#39;N/A\u0026#39;) # description = finding.get(\u0026#39;description\u0026#39;, \u0026#39;N/A\u0026#39;) # account_id = finding.get(\u0026#39;accountId\u0026#39;, \u0026#39;N/A\u0026#39;) # region = finding.get(\u0026#39;region\u0026#39;, \u0026#39;N/A\u0026#39;) # finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;N/A\u0026#39;) # message_text = ( # f\u0026#34;üö® *GuardDuty Finding* üö®\\n\\n\u0026#34; # f\u0026#34;*Severity:* {severity}\\n\u0026#34; # f\u0026#34;*Account:* {account_id}\\n\u0026#34; # f\u0026#34;*Region:* {region}\\n\u0026#34; # f\u0026#34;*Title:* {title}\\n\u0026#34; # f\u0026#34;*Description:* {description}\\n\\n\u0026#34; # f\u0026#34;*Finding Type:* `{finding_type}`\u0026#34; # ) # payload = {\u0026#39;chat_id\u0026#39;: chat_id, \u0026#39;text\u0026#39;: message_text, \u0026#39;parse_mode\u0026#39;: \u0026#39;Markdown\u0026#39;} # if thread_id: # payload[\u0026#39;message_thread_id\u0026#39;] = thread_id # try: # req = urllib.request.Request( # TELEGRAM_URL, # data=json.dumps(payload).encode(\u0026#39;utf-8\u0026#39;), # headers={\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;} # ) # with urllib.request.urlopen(req) as response: # logger.info(\u0026#34;Telegram response: \u0026#34; + response.read().decode(\u0026#39;utf-8\u0026#39;)) # except Exception as e: # logger.error(f\u0026#34;TELEGRAM FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;üî¥ HIGH\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;üü† MEDIUM\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;üîµ LOW\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;üö® {sev} ‚Äì {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;üö® GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Severity:*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Region:*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Description:*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Account:* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Type:* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;üö® GuardDuty Alert: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Account ID:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Region:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Type:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Finding ID:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Generated by AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tri·ªÉn khai ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán v·ªõi Amazon DynamoDB b·ªüi Aman Dhingra, Jack Le Bon v√† Lee Hannigan | ng√†y 25 th√°ng 9 nƒÉm 2025 | trong Advanced (300), Amazon DynamoDB, Amazon EventBridge, AWS Lambda, Serverless, Technical How-to\nEvent-driven architecturesÔªø l√† l·ª±a ch·ªçn ph·ªï bi·∫øn c·ªßa kh√°ch h√†ng ƒë·ªÉ t√≠ch h·ª£p c√°c d·ªãch v·ª• AWS kh√°c nhau v√† c√°c h·ªá th·ªëng kh√¥ng ƒë·ªìng nh·∫•t. Nh·ªØng ki·∫øn tr√∫c n√†y c√≥ th·ªÉ gi√∫p gi·∫£m chi ph√≠, m·ªü r·ªông v√† th·∫•t b·∫°i c√°c th√†nh ph·∫ßn m·ªôt c√°ch ƒë·ªôc l·∫≠p, ƒë·ªìng th·ªùi h·ªó tr·ª£ x·ª≠ l√Ω song song. ƒê·ªëi v·ªõi c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng DynamoDB, m·ªôt s·ªë c√≥ th·ªÉ c·∫ßn c√°c ch·ª©c nƒÉng Time-to-LiveÔªø (TTL) n√¢ng cao h∆°n, trong khi nh·ªØng ·ª©ng d·ª•ng kh√°c y√™u c·∫ßu kh·∫£ nƒÉng k√≠ch ho·∫°t c√°c h√†nh ƒë·ªông downstreamÔªø, ch·∫≥ng h·∫°n nh∆∞ g·ª≠i email nh·∫Øc nh·ªü cho c√°c s·ª± ki·ªán ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi ·ª©ng d·ª•ng. D√π b·∫°n c·∫ßn lo·∫°i b·ªè d·ªØ li·ªáu ngay l·∫≠p t·ª©c hay ki·ªÉm so√°t ch√≠nh x√°c vi·ªác l√™n l·ªãch c√°c s·ª± ki·ªán t∆∞∆°ng lai, ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán c√≥ th·ªÉ gi√∫p b·∫°n ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u n√†y m·ªôt c√°ch hi·ªáu qu·∫£.\nTrong lo·∫°t b√†i ba ph·∫ßn n√†y, ch√∫ng t√¥i kh√°m ph√° c√°c c√°ch ti·∫øp c·∫≠n ƒë·ªÉ tri·ªÉn khai c√°c patternsÔªø s·ª± ki·ªán n√¢ng cao cho c√°c ·ª©ng d·ª•ng ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi DynamoDB. D∆∞·ªõi ƒë√¢y l√† c√°i nh√¨n s∆° l∆∞·ª£c v·ªÅ c√°c ch·ªß ƒë·ªÅ ch√∫ng t√¥i s·∫Ω ƒë·ªÅ c·∫≠p:\nPh·∫ßn 1: T·∫≠n d·ª•ng Amazon EventBridge Scheduler ƒë·ªÉ lo·∫°i b·ªè d·ªØ li·ªáu ch√≠nh x√°c ‚Äì Kh√°m ph√° c√°ch s·ª≠ d·ª•ng EventBridge Scheduler ƒë·ªÉ qu·∫£n l√Ω v√† lo·∫°i b·ªè d·ªØ li·ªáu t·ª´ DynamoDB m·ªôt c√°ch hi·ªáu qu·∫£ v·ªõi ƒë·ªô ch√≠nh x√°c g·∫ßn th·ªùi gian th·ª±c.\nPh·∫ßn 2: S·ª≠ d·ª•ng Global Secondary Index chuy√™n d·ª•ng ƒë·ªÉ qu·∫£n l√Ω d·ªØ li·ªáu nghi√™m ng·∫∑t ‚Äì T√¨m hi·ªÉu v·ªÅ vi·ªác t·∫°o Global Secondary Index (GSI) chuy√™n bi·ªát ƒë·ªÉ ki·ªÉm so√°t ch√≠nh x√°c vi·ªác lo·∫°i b·ªè v√† qu·∫£n l√Ω d·ªØ li·ªáu.\nPh·∫ßn 3: Tri·ªÉn khai Amazon EventBridge Scheduler ƒë·ªÉ l√™n l·ªãch s·ª± ki·ªán chi ti·∫øt ‚Äì Kh√°m ph√° c√°ch EventBridge Scheduler c√≥ th·ªÉ cho ph√©p l√™n l·ªãch chi ti·∫øt c√°c s·ª± ki·ªán downstreamÔªø, cho ph√©p qu·∫£n l√Ω s·ª± ki·ªán t∆∞∆°ng lai ch√≠nh x√°c.\nTrong b√†i vi·∫øt n√†y (Ph·∫ßn 1), ch√∫ng t√¥i t·∫≠p trung v√†o vi·ªác c·∫£i thi·ªán ch·ª©c nƒÉng TTL b·∫£n ƒë·ªãa c·ªßa DynamoDB b·∫±ng c√°ch tri·ªÉn khai lo·∫°i b·ªè d·ªØ li·ªáu g·∫ßn th·ªùi gian th·ª±c s·ª≠ d·ª•ng EventBridge Scheduler, gi·∫£m th·ªùi gian ƒëi·ªÉn h√¨nh ƒë·ªÉ x√≥a c√°c itemsÔªø h·∫øt h·∫°n t·ª´ v√†i ng√†y xu·ªëng d∆∞·ªõi m·ªôt ph√∫t.\nDynamoDB Time-to-Live: Ch·ª©c nƒÉng b·∫£n ƒë·ªãa v√† H·∫°n ch·∫ø Time to LiveÔªø (TTL), m·ªôt ch·ª©c nƒÉng b·∫£n ƒë·ªãa trong DynamoDB, cho ph√©p b·∫°n ƒë·ªãnh nghƒ©a th·ªùi gian h·∫øt h·∫°n c·ª• th·ªÉ cho c√°c itemsÔªø trong b·∫£ng. Khi TTL ƒë∆∞·ª£c k√≠ch ho·∫°t v√† m·ªôt attributeÔªø h·∫øt h·∫°n ƒë∆∞·ª£c ƒë·∫∑t cho m·ªôt itemÔªø, DynamoDB t·ª± ƒë·ªông lo·∫°i b·ªè itemÔªø ƒë√≥ kh·ªèi b·∫£ng khi th·ªùi gian h·∫øt h·∫°n ƒë∆∞·ª£c ƒë·∫°t t·ªõi. T√≠nh nƒÉng n√†y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ qu·∫£n l√Ω d·ªØ li·ªáu c√≥ th·ªùi gian s·ªëng h·∫°n ch·∫ø, ch·∫≥ng h·∫°n nh∆∞ recordsÔªø sessionÔªø t·∫°m th·ªùi, th√¥ng tin ƒë∆∞·ª£c cacheÔªø, ho·∫∑c d·ªØ li·ªáu nh·∫°y c·∫£m th·ªùi gian kh√°c. V·ªõi TTL, b·∫°n c√≥ th·ªÉ t·ª± ƒë·ªông h√≥a qu√° tr√¨nh d·ªçn d·∫πp d·ªØ li·ªáu, t·ªëi ∆∞u h√≥a qu·∫£n l√Ω d·ªØ li·ªáu, chi ph√≠ v√† hi·ªáu qu·∫£ l∆∞u tr·ªØ.\nƒê·ªÉ s·ª≠ d·ª•ng TTL b·∫£n ƒë·ªãa, b·∫°n ph·∫£i k√≠ch ho·∫°t n√≥ tr√™n b·∫£ng v√† ch·ªâ ƒë·ªãnh m·ªôt attributeÔªø s·∫Ω ch·ª©a th·ªùi gian h·∫øt h·∫°n cho m·ªói itemÔªø. AttributeÔªø n√†y ph·∫£i ·ªü ƒë·ªãnh d·∫°ng th·ªùi gian Unix epochÔªø. TTL b·∫£n ƒë·ªãa kh√¥ng ti√™u th·ª• write throughputÔªø tr√™n b·∫£ng c·ªßa b·∫°n v√† kh√¥ng ph√°t sinh chi ph√≠ b·ªï sung tr·ª´ tr∆∞·ªùng h·ª£p global tablesÔªø, n∆°i vi·ªác x√≥a TTL tr√™n v√πng ngu·ªìn kh√¥ng ph√°t sinh chi ph√≠, nh∆∞ng vi·ªác x√≥a ƒë∆∞·ª£c replicateÔªø sang c√°c b·∫£ng replicaÔªø kh√°c ti√™u th·ª• write throughputÔªø.\nTuy nhi√™n, m·∫∑c d√π t√≠nh nƒÉng TTL b·∫£n ƒë·ªãa hi·ªáu qu·∫£ trong vi·ªác t·ª± ƒë·ªông h·∫øt h·∫°n c√°c itemsÔªø, ƒë·ªô tr·ªÖ v·ªën c√≥ l√™n ƒë·∫øn v√†i ng√†y tr∆∞·ªõc khi x√≥a c√≥ th·ªÉ kh√¥ng ph√π h·ª£p v·ªõi y√™u c·∫ßu qu·∫£n l√Ω d·ªØ li·ªáu ho·∫∑c tu√¢n th·ªß c·ªßa m·ªçi ·ª©ng d·ª•ng. S·ª± kh√°c bi·ªát n√†y tr·ªü n√™n ƒë·∫∑c bi·ªát li√™n quan ƒë·ªëi v·ªõi c√°c h·ªá th·ªëng y√™u c·∫ßu lo·∫°i b·ªè d·ªØ li·ªáu nhanh ch√≥ng v√† ch√≠nh x√°c, ch·∫≥ng h·∫°n nh∆∞ c√°c n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ c·∫ßn c·∫≠p nh·∫≠t h√†ng t·ªìn kho nhanh ch√≥ng ho·∫∑c c√°c sessionÔªø ng∆∞·ªùi d√πng ƒë·ªông y√™u c·∫ßu theo d√µi th·ªùi gian th·ª±c ch√≠nh x√°c. ItemÔªø s·∫Ω ti·∫øp t·ª•c xu·∫•t hi·ªán trong k·∫øt qu·∫£ queryÔªø cho ƒë·∫øn khi vi·ªác x√≥a ƒë∆∞·ª£c th·ª±c hi·ªán. M·ªôt entryÔªø s·∫Ω xu·∫•t hi·ªán trong b·∫•t k·ª≥ change streamÔªø n√†o ƒë∆∞·ª£c c·∫•u h√¨nh khi vi·ªác x√≥a x·∫£y ra.\nT·ªïng quan Gi·∫£i ph√°p: TTL G·∫ßn Th·ªùi gian Th·ª±c v·ªõi EventBridge Scheduler ƒê·ªÉ gi·∫£i quy·∫øt nh·ªØng tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng nh·∫°y c·∫£m th·ªùi gian n√†y, ch√∫ng ta c√≥ th·ªÉ t√≠ch h·ª£p EventBridge Scheduler ƒë·ªÉ th·ª±c thi vi·ªác lo·∫°i b·ªè itemsÔªø k·ªãp th·ªùi trong v√≤ng 1-2 ph√∫t, cung c·∫•p m·ªôt gi·∫£i ph√°p ngay l·∫≠p t·ª©c v√† c√≥ th·ªÉ d·ª± ƒëo√°n h∆°n cho c√°c ·ª©ng d·ª•ng y√™u c·∫ßu h·∫øt h·∫°n d·ªØ li·ªáu nhanh ch√≥ng.\nL·ª£i √≠ch c·ªßa TTL G·∫ßn Th·ªùi gian Th·ª±c ƒê·ªô ch√≠nh x√°c g·∫ßn th·ªùi gian th·ª±c: ƒê·∫£m b·∫£o d·ªØ li·ªáu kh√¥ng c√≤n c·∫ßn thi·∫øt ƒë∆∞·ª£c lo·∫°i b·ªè k·ªãp th·ªùi, ƒëi·ªÅu n√†y quan tr·ªçng ƒë·ªëi v·ªõi c√°c ·ª©ng d·ª•ng nh∆∞ th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ n∆°i m·ª©c h√†ng t·ªìn kho ch√≠nh x√°c l√† quan tr·ªçng ƒë·ªÉ ngƒÉn ch·∫∑n b√°n qu√° m·ª©c ho·∫∑c b√°n thi·∫øu s·∫£n ph·∫©m.\nTr·∫£i nghi·ªám ng∆∞·ªùi d√πng n√¢ng cao: Lo·∫°i b·ªè ngay l·∫≠p t·ª©c d·ªØ li·ªáu sessionÔªø h·∫øt h·∫°n ƒë·∫£m b·∫£o ng∆∞·ªùi d√πng t∆∞∆°ng t√°c v·ªõi th√¥ng tin hi·ªán t·∫°i nh·∫•t, cung c·∫•p tr·∫£i nghi·ªám t·ªët h∆°n v√† ngay l·∫≠p t·ª©c.\nTh√¥ng b√°o k·ªãp th·ªùi: H·ªó tr·ª£ th·ª±c thi b·∫•t k·ª≥ quy tr√¨nh ph·ª• thu·ªôc n√†o d·ª±a v√†o vi·ªác h·∫øt h·∫°n d·ªØ li·ªáu, ch·∫≥ng h·∫°n nh∆∞ timeoutÔªø sessionÔªø ho·∫∑c quy·ªÅn truy c·∫≠p t·∫°m th·ªùi, ƒë∆∞·ª£c th·ª±c thi ch√≠nh x√°c khi c·∫ßn thi·∫øt.\nT·ªëi ∆∞u h√≥a s·ª≠ d·ª•ng t√†i nguy√™n: K·ªãp th·ªùi gi·∫£i ph√≥ng kh√¥ng gian l∆∞u tr·ªØ b·∫±ng c√°ch lo·∫°i b·ªè d·ªØ li·ªáu h·∫øt h·∫°n, gi·∫£m chi ph√≠ li√™n quan ƒë·∫øn l∆∞u tr·ªØ th√¥ng tin l·ªói th·ªùi.\nQu·∫£n l√Ω d·ªØ li·ªáu ƒë∆∞·ª£c c·∫£i thi·ªán: Ch·ªâ d·ªØ li·ªáu li√™n quan v√† hi·ªán t·∫°i ƒë∆∞·ª£c gi·ªØ l·∫°i, ƒë∆°n gi·∫£n h√≥a qu·∫£n l√Ω d·ªØ li·ªáu v√† l√†m cho vi·ªác duy tr√¨ t√≠nh to√†n v·∫πn d·ªØ li·ªáu d·ªÖ d√†ng h∆°n.\nKi·∫øn tr√∫c Gi·∫£i ph√°p S∆° ƒë·ªì sau minh h·ªça ki·∫øn tr√∫c gi·∫£i ph√°p c·ªßa ch√∫ng t√¥i:\nGi·∫£i ph√°p ch·ª©a c√°c th√†nh ph·∫ßn ch√≠nh sau:\nAmazon DynamoDB ‚Äì C∆° s·ªü d·ªØ li·ªáu NoSQL ph√¢n t√°n, serverlessÔªø, ƒë∆∞·ª£c qu·∫£n l√Ω ho√†n to√†n n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ch·∫°y c√°c ·ª©ng d·ª•ng hi·ªáu su·∫•t cao ·ªü b·∫•t k·ª≥ quy m√¥ n√†o. B·∫£ng ph·∫£i ch·ª©a m·ªôt attributeÔªø cho bi·∫øt th·ªùi gian h·∫øt h·∫°n itemÔªø.\nDynamoDB Streams ‚Äì Ch·ª©c nƒÉng b·∫£n ƒë·ªãa n√†y ghi l·∫°i m·ªôt chu·ªói theo th·ª© t·ª± th·ªùi gian c√°c s·ª≠a ƒë·ªïi c·∫•p itemÔªø trong B·∫£ng DynamoDB c·ªßa b·∫°n. Nh·ªØng s·ª≠a ƒë·ªïi n√†y bao g·ªìm c√°c ho·∫°t ƒë·ªông InsertÔªø, UpdateÔªø v√† DeleteÔªø.\nAWS Lambda ‚Äì D·ªãch v·ª• t√≠nh to√°n serverlessÔªø n√†y cho ph√©p b·∫°n ch·∫°y m√£ m√† kh√¥ng c·∫ßn cung c·∫•p ho·∫∑c qu·∫£n l√Ω serversÔªø.\nAmazon EventBridge Scheduler ‚Äì SchedulerÔªø serverlessÔªø n√†y cho ph√©p b·∫°n t·∫°o, ch·∫°y v√† qu·∫£n l√Ω c√°c tasksÔªø t·ª´ m·ªôt d·ªãch v·ª• ƒë∆∞·ª£c qu·∫£n l√Ω t·∫≠p trung.\nC√°ch th·ª©c Ho·∫°t ƒë·ªông ƒê·ªëi v·ªõi m·ªói itemÔªø DynamoDB c√≥ gi√° tr·ªã TTL, ch√∫ng ta li√™n k·∫øt m·ªôt one-time invocationÔªø scheduleÔªø trong EventBridge Scheduler. One-time invocationÔªø ƒë∆∞·ª£c l√™n l·ªãch ƒë·ªÉ k√≠ch ho·∫°t c√πng l√∫c v·ªõi gi√° tr·ªã TTL c·ªßa DynamoDB Item.\nM·ªói scheduleÔªø ph·∫£i bao g·ªìm m·ªôt targetÔªø ƒë·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng khi scheduleÔªø ƒë∆∞·ª£c g·ªçi. Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng Universal TargetÔªø ƒë·ªÉ g·ªçi tr·ª±c ti·∫øp DynamoDB DeleteItem APIÔªø, lo·∫°i b·ªè itemÔªø kh·ªèi b·∫£ng. T√≠ch h·ª£p tr·ª±c ti·∫øp v·ªõi DynamoDB hi·ªáu qu·∫£ v·ªÅ chi ph√≠ h∆°n so v·ªõi vi·ªác g·ªçi Lambda ƒë·ªÉ th·ª±c hi·ªán vi·ªác x√≥a.\nLu·ªìng ho·∫°t ƒë·ªông nh∆∞ sau:\nKhi m·ªôt recordÔªø ƒë∆∞·ª£c th√™m, s·ª≠a ƒë·ªïi ho·∫∑c lo·∫°i b·ªè kh·ªèi b·∫£ng DynamoDB, m·ªôt stream recordÔªø ƒë∆∞·ª£c t·∫°o trong DynamoDB Stream li√™n quan.\nDynamoDB Stream g·ªçi m·ªôt functionÔªø Lambda x·ª≠ l√Ω stream eventÔªø.\nFunctionÔªø Lambda tr√≠ch xu·∫•t primary keyÔªø v√† gi√° tr·ªã TTL c·ªßa itemÔªø, sau ƒë√≥ t·∫°o, c·∫≠p nh·∫≠t ho·∫∑c x√≥a scheduleÔªø EventBridge t∆∞∆°ng ·ª©ng.\nEventBridge Schedule ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ g·ªçi DynamoDB DeleteItem API t·∫°i th·ªùi gian TTL ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh, lo·∫°i b·ªè itemÔªø kh·ªèi b·∫£ng.\nScheduleÔªø t·ª± ƒë·ªông x√≥a ch√≠nh n√≥ sau khi ho√†n th√†nh th√†nh c√¥ng.\nEventBridge Schedule li√™n quan ƒë·∫øn m·ªôt itemÔªø ƒë∆∞·ª£c ƒë·∫∑t ƒë·ªÉ k√≠ch ho·∫°t t·∫°i th·ªùi gian TTL itemÔªø ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh. C√°c scheduleÔªø c√≥ ng√†y trong t∆∞∆°ng lai th∆∞·ªùng s·∫Ω k√≠ch ho·∫°t trong v√≤ng m·ªôt ph√∫t t·ª´ th·ªùi gian scheduleÔªø khi kh√¥ng s·ª≠ d·ª•ng t√≠nh nƒÉng flexible time windowÔªø.\nƒêi·ªÅu ki·ªán Ti√™n quy·∫øt Tr∆∞·ªõc khi tri·ªÉn khai gi·∫£i ph√°p n√†y, b·∫°n n√™n c√≥:\nT√†i kho·∫£n AWS ‚Äì Truy c·∫≠p v√†o t√†i kho·∫£n AWS ƒëang ho·∫°t ƒë·ªông ƒë·ªÉ ki·ªÉm tra gi·∫£i ph√°p\nKi·∫øn th·ª©c c∆° b·∫£n DynamoDB ‚Äì Hi·ªÉu bi·∫øt n·ªÅn t·∫£ng v·ªÅ c√°c kh√°i ni·ªám DynamoDB\nFunctionsÔªø Lambda ‚Äì Quen thu·ªôc v·ªõi Lambda ƒë·ªÉ x·ª≠ l√Ω c√°c eventsÔªø DynamoDB Streams\nKi·∫øn th·ª©c c∆° b·∫£n EventBridge ‚Äì Ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ EventBridge ƒë·ªÉ thi·∫øt l·∫≠p scheduler rulesÔªø\nTh√†nh th·∫°o AWS CLI ho·∫∑c consoleÔªø ‚Äì ƒê·ªÉ c·∫•u h√¨nh d·ªãch v·ª• v√† gi√°m s√°t logsÔªø. Ch√∫ng t√¥i s·ª≠ d·ª•ng AWS Management Console trong su·ªët b√†i vi·∫øt n√†y.\nC√°c B∆∞·ªõc Tri·ªÉn khai ƒê·∫ßu ti√™n, b·∫°n t·∫°o m·ªôt b·∫£ng DynamoDB v·ªõi DynamoDB Streams ƒë∆∞·ª£c k√≠ch ho·∫°t:\nTr√™n DynamoDB console, ch·ªçn Tables trong navigation paneÔªø.\nCh·ªçn Create table.\nƒê·ªëi v·ªõi Table name, nh·∫≠p t√™n cho b·∫£ng m·ªõi c·ªßa b·∫°n (ch·∫≥ng h·∫°n: TTL-table).\nƒê·ªëi v·ªõi Partition key, nh·∫≠p PK l√†m t√™n v√† ch·ªçn String l√†m lo·∫°i.\nƒê·ªëi v·ªõi Sort key, nh·∫≠p SK l√†m t√™n v√† ch·ªçn String l√†m lo·∫°i.\nƒê·ªÉ t·∫•t c·∫£ c√°c c·∫•u h√¨nh kh√°c ·ªü m·∫∑c ƒë·ªãnh v√† ch·ªçn Create table.\nCh·ªçn Tables trong navigation paneÔªø v√† m·ªü chi ti·∫øt b·∫£ng c·ªßa b·∫°n.\nTr√™n tab Exports and streams, d∆∞·ªõi DynamoDB stream details, ch·ªçn Turn on.\nTrong wizardÔªø Turn on DynamoDB stream, ch·ªçn New and old images, sau ƒë√≥ ch·ªçn Turn on stream. B√¢y gi·ªù b·∫°n s·∫Ω th·∫•y chi ti·∫øt DynamoDB stream, v·ªõi \u0026ldquo;Stream Status\u0026rdquo; ƒë∆∞·ª£c ƒë·∫∑t th√†nh \u0026ldquo;On\u0026rdquo;. H√£y ch·∫Øc ch·∫Øn ghi ch√∫ \u0026ldquo;Latest stream ARN\u0026rdquo;, b·∫°n s·∫Ω c·∫ßn n√≥ sau n√†y. ƒêi·ªÅu n√†y s·∫Ω k√≠ch ho·∫°t DynamoDB Streams tr√™n b·∫£ng ƒë·ªÉ hi·ªÉn th·ªã c·∫£ tr·∫°ng th√°i c≈© v√† m·ªõi c·ªßa c√°c itemsÔªø trong stream recordsÔªø, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ qu·∫£n l√Ω c√°c c·∫≠p nh·∫≠t v·ªÅ gi√° tr·ªã TTL c·ªßa itemsÔªø. Ti·∫øp theo, ch√∫ng ta t·∫°o functionÔªø Lambda ƒë∆∞·ª£c g·ªçi b·ªüi DynamoDB Stream.\nC·∫•u h√¨nh Quy·ªÅn IAM EventBridge Scheduler c·∫ßn quy·ªÅn th√≠ch h·ª£p ƒë·ªÉ g·ªçi DynamoDB DeleteItem API. T·∫°o m·ªôt roleÔªø IAM v·ªõi trust policyÔªø sau:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;scheduler.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } } V√† ƒë√≠nh k√®m m·ªôt policyÔªø v·ªõi c√°c quy·ªÅn sau:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:\\[REGION\\_NAME\\]:\\[ACCOUNT\\_ID\\]:table/\\[TABLE\\_NAME\\]\u0026#34; } } Ghi ch√∫ ARN cho roleÔªø n√†y, v√¨ ch√∫ng ta s·∫Ω c·∫ßn n√≥ sau n√†y.\nT·∫°o Lambda function\nLambda function c√≥ tr√°ch nhi·ªám c·∫•u h√¨nh EventBridge Scheduler ƒë·ªÉ th·ª±c hi·ªán vi·ªác x√≥a ch·ªçn l·ªçc c√°c item c·ª• th·ªÉ t·ª´ DynamoDB table:\nTr√™n Lambda console, ch·ªçn m·ª•c Functions trong menu ƒëi·ªÅu h∆∞·ªõng.\nCh·ªçn Create function.\nCh·ªçn Author from scratch.\nV·ªõi tr∆∞·ªùng Function name, nh·∫≠p t√™n (v√≠ d·ª•: DDBStreamTriggerEventScheduler).\nCh·ªçn m·ªôt Runtime. B√†i vi·∫øt s·ª≠ d·ª•ng Python 3.11, nh∆∞ng b·∫°n c√≥ th·ªÉ ch·ªçn b·∫•t k·ª≥ runtime n√†o quen thu·ªôc.\nTh√™m v√†o Lambda execution role hai policy IAM l√† AWSLambdaDynamoDBExecutionRole v√† m·ªôt inline policy c√≥ quy·ªÅn scheduler:CreateSchedule.\nCh·ªçn Create function.\nB·∫•m v√†o tab Configuration c·ªßa Lambda Function v√† ch·ªçn b·∫£ng Permissions.\nTrong ph·∫ßn Execution role, nh·∫•n v√†o Role name li√™n k·∫øt. T√™n n√†y th∆∞·ªùng c√≥ d·∫°ng nh∆∞ YourLambdaFunctionName-Role-abc.\nCh·ªçn Add permissions, sau ƒë√≥ ch·ªçn Create inline policy\nChuy·ªÉn t·ª´ giao di·ªán Visual sang JSON v√† th√™m ch√≠nh s√°ch sau, c·∫•p quy·ªÅn cho Lambda function truy c·∫≠p DynamoDB Stream (nh·ªõ nh·∫≠p ARN DynamoDB Stream ƒë√£ note tr∆∞·ªõc ƒë√≥) v√† t·∫°o, c·∫≠p nh·∫≠t, x√≥a EventBridge Schedules:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBStreamAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;[Your DynamoDB Stream ARN]\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBListStreams\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:ListStreams\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;EventBridgeSchedulerAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;scheduler:CreateSchedule\u0026#34;, \u0026#34;scheduler:UpdateSchedule\u0026#34;, \u0026#34;scheduler:DeleteSchedule\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:scheduler:*:*:schedule/default/dynamodb_ttl_*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;PassRoleToScheduler\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;iam:PassRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: \u0026#34;scheduler.amazonaws.com\u0026#34; } } } ] } Ch·ªçn Next.\nNh·∫≠p Policy name, v√≠ d·ª•: AWSLambdaToEventBridgeScheduler.\nCh·ªçn Create policy.\nQuay l·∫°i DynamoDB console, ch·ªçn Tables ·ªü menu v√† ch·ªçn b·∫£ng v·ª´a t·∫°o (TTL-Table).\nChuy·ªÉn sang tab Exports and streams.\n·ªû v√πng Trigger, nh·∫•n Create trigger.\nT·∫°i ph·∫ßn AWS Lambda function details, ch·ªçn Lambda function v·ª´a t·∫°o (DDBStreamTriggerEventScheduler).\nCh·ªçn Create trigger.\nQuay l·∫°i Lambda console, ch·ªçn Functions ·ªü menu, t√¨m v√† ch·ªçn Lambda function v·ª´a t·∫°o.\nT·∫°i tab Code c·ªßa Lambda function, th√™m m√£ code ph√π h·ª£p.\nCode M·∫´u Lambda Function (Python)\nimport json import datetime import boto3 import os import logging logger = logging.getLogger() logger.setLevel(logging.INFO) ROLE_ARN = os.environ.get(\u0026#39;SCHEDULER_ROLE_ARN\u0026#39;) TABLE_NAME = os.environ.get(\u0026#39;DYNAMODB_TABLE_NAME\u0026#39;) TIMEZONE = os.environ.get(\u0026#39;TIMEZONE\u0026#39;, \u0026#39;UTC\u0026#39;) scheduler_client = boto3.client(\u0026#39;scheduler\u0026#39;) def lambda_handler(event, context): try: if not event.get(\u0026#39;Records\u0026#39;): logger.error(\u0026#34;No records found in the event\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;No records found in the event\u0026#39;) } for record in event[\u0026#39;Records\u0026#39;]: process_record(record) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;DynamoDB near-real time TTL operations completed successfully.\u0026#39;) } except Exception as e: logger.error(f\u0026#34;Error processing event: {str(e)}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps(f\u0026#39;Error: {str(e)}\u0026#39;) } def process_record(record): try: event_name = record.get(\u0026#39;eventName\u0026#39;) if event_name == \u0026#34;INSERT\u0026#34;: handle_insert(record) elif event_name == \u0026#34;MODIFY\u0026#34;: handle_modify(record) elif event_name == \u0026#34;REMOVE\u0026#34;: handle_remove(record) else: logger.warning(f\u0026#34;Unhandled event type: {event_name}\u0026#34;) except Exception as e: logger.warning(f\u0026#34;Error processing record: {str(e)}\u0026#34;) raise def handle_insert(record): keys = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;Keys\u0026#39;] pk = keys[\u0026#39;PK\u0026#39;][\u0026#39;S\u0026#39;] sk = keys[\u0026#39;SK\u0026#39;][\u0026#39;S\u0026#39;] ttl_value = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;][\u0026#39;ttl\u0026#39;][\u0026#39;N\u0026#39;] epoch_dt = datetime.datetime.fromtimestamp(int(ttl_value)) logger.info(f\u0026#34;Creating schedule for item {pk}#{sk} with TTL at {epoch_dt}\u0026#34;) scheduler_client.create_schedule( ActionAfterCompletion=\u0026#34;DELETE\u0026#34;, FlexibleTimeWindow={\u0026#34;Mode\u0026#34;: \u0026#34;OFF\u0026#34;}, Name=f\u0026#34;dynamodb_ttl_{pk}_{sk}\u0026#34;, ScheduleExpression=f\u0026#34;at({epoch_dt.strftime(\u0026#39;%Y-%m-%dT%H:%M:%S\u0026#39;)})\u0026#34;, ScheduleExpressionTimezone=TIMEZONE, Target={ \u0026#34;RoleArn\u0026#34;: ROLE_ARN, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:scheduler:::aws-sdk:dynamodb:deleteItem\u0026#34;, \u0026#34;Input\u0026#34;: json.dumps({\u0026#34;Key\u0026#34;: {\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: pk}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: sk}}, \u0026#34;TableName\u0026#34;: TABLE_NAME}) } ) def handle_modify(record): if \u0026#39;OldImage\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;] or \u0026#39;NewImage\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;]: return if \u0026#39;ttl\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;][\u0026#39;OldImage\u0026#39;] or \u0026#39;ttl\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;]: return keys = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;Keys\u0026#39;] pk = keys[\u0026#39;PK\u0026#39;][\u0026#39;S\u0026#39;] sk = keys[\u0026#39;SK\u0026#39;][\u0026#39;S\u0026#39;] old_ttl = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;OldImage\u0026#39;][\u0026#39;ttl\u0026#39;][\u0026#39;N\u0026#39;] new_ttl = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;][\u0026#39;ttl\u0026#39;][\u0026#39;N\u0026#39;] if old_ttl != new_ttl: epoch_dt = datetime.datetime.fromtimestamp(int(new_ttl)) logger.info(f\u0026#34;Updating schedule for item {pk}#{sk} with new TTL at {epoch_dt}\u0026#34;) try: scheduler_client.update_schedule( Name=f\u0026#34;dynamodb_ttl_{pk}_{sk}\u0026#34;, FlexibleTimeWindow={\u0026#34;Mode\u0026#34;: \u0026#34;OFF\u0026#34;}, ScheduleExpression=f\u0026#34;at({epoch_dt.strftime(\u0026#39;%Y-%m-%dT%H:%M:%S\u0026#39;)})\u0026#34;, ScheduleExpressionTimezone=TIMEZONE, Target={ \u0026#34;RoleArn\u0026#34;: ROLE_ARN, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:scheduler:::aws-sdk:dynamodb:deleteItem\u0026#34;, \u0026#34;Input\u0026#34;: json.dumps({\u0026#34;Key\u0026#34;: {\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: pk}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: sk}}, \u0026#34;TableName\u0026#34;: TABLE_NAME}) } ) except scheduler_client.exceptions.ResourceNotFoundException: handle_insert(record) def handle_remove(record): keys = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;Keys\u0026#39;] pk = keys[\u0026#39;PK\u0026#39;][\u0026#39;S\u0026#39;] sk = keys[\u0026#39;SK\u0026#39;][\u0026#39;S\u0026#39;] logger.info(f\u0026#34;Deleting schedule for item {pk}#{sk}\u0026#34;) try: scheduler_client.delete_schedule(Name=f\u0026#39;dynamodb_ttl_{pk}_{sk}\u0026#39;) except scheduler_client.exceptions.ResourceNotFoundException: pass Ch·ªçn Deploy ƒë·ªÉ c·∫≠p nh·∫≠t m√£ function m·ªõi nh·∫•t.\nCu·ªëi c√πng, th√™m t√™n DynamoDB table v√† ARN c·ªßa EventBridge Scheduler role v√†o bi·∫øn m√¥i tr∆∞·ªùng c·ªßa Lambda Function. V√†o tab Configuration v√† ph·∫ßn Environment variables.\nCh·ªçn Edit.\nCh·ªçn Add environment variable r·ªìi nh·∫≠p:\nKey: DYNAMODB_TABLE_NAME\nValue: T√™n b·∫£ng c·ªßa b·∫°n (v√≠ d·ª• TTL-Table)\nCh·ªçn Add environment variable m·ªôt l·∫ßn n·ªØa, r·ªìi nh·∫≠p:\nKey: SCHEDULER_ROLE_ARN\nValue: ARN c·ªßa scheduler role ƒë√£ ghi ch√∫ tr∆∞·ªõc ƒë√≥ (d·∫°ng arn:aws:iam::****:role/eventbridge_scheduler_role)\nCh·ªçn Save Ki·ªÉm tra Gi·∫£i ph√°p B·∫°n c√≥ th·ªÉ ki·ªÉm tra gi·∫£i ph√°p b·∫±ng c√°ch th√™m c√°c itemsÔªø v√†o b·∫£ng DynamoDB c·ªßa b·∫°n v·ªõi gi√° tr·ªã TTL. D∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• t·∫°o 10 itemsÔªø m·∫´u v·ªõi gi√° tr·ªã TTL s·ª≠ d·ª•ng AWS CLI:\n#!/bin/bash TABLE=\u0026#34;TTL-Table\u0026#34; for PK_VALUE in {1..10}; do ISO_TIMESTAMP_PLUS_3_MINS=$(date -v+3M -u +\u0026#34;%Y-%m-%dT%H:%M:%S\u0026#34;) aws dynamodb put-item --table-name $TABLE \\ --item \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;StaticSK\u0026#34;}, \u0026#34;REMINDER_TIMESTAMP\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$ISO_TIMESTAMP_PLUS_3_MINS\u0026#39;\u0026#34;}, \u0026#34;email\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;abc@example.com\u0026#34;}, \u0026#34;ATTR_1\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;This is a static attribute\u0026#34;}}\u0026#39; done B·∫°n c√≥ th·ªÉ ƒëi·ªÅu h∆∞·ªõng ƒë·∫øn tab Monitoring c·ªßa nh√≥m l·ªãch tr√¨nh EventBridge ƒë·ªÉ xem c√°c l·ªánh x√≥a ƒëang ƒë∆∞·ª£c th·ª±c thi. Schedule s·∫Ω k√≠ch ho·∫°t c√°c thao t√°c v√†o m·ªôt th·ªùi ƒëi·ªÉm c·ª• th·ªÉ; b·∫°n c√≥ th·ªÉ quan s√°t c√°c l·∫ßn k√≠ch ho·∫°t n√†y b·∫±ng c√°ch xem ch·ªâ s·ªë InvocationAttemptCount. Trong tr∆∞·ªùng h·ª£p c·ªßa ch√∫ng t√¥i, c√°c l·∫ßn k√≠ch ho·∫°t l√† c√°c l·ªánh x√≥a ƒë∆∞·ª£c th·ª±c hi·ªán ƒë·ªëi v·ªõi b·∫£ng DynamoDB. ƒê·ªÉ xem danh s√°ch t·∫•t c·∫£ c√°c ch·ªâ s·ªë c√≥ s·∫µn cho m·ªôt nh√≥m l·ªãch tr√¨nh, h√£y tham kh·∫£o Monitoring Amazon EventBridge Scheduler with Amazon CloudWatchÔªø. C√¢n nh·∫Øc Chi ph√≠ Chi ph√≠ c·ªßa vi·ªác s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p n√†y cho 1,000,000 m·ª•c TTL ƒë∆∞·ª£c ∆∞·ªõc t√≠nh trong b·∫£ng sau ƒë√¢y c√πng v·ªõi so s√°nh v·ªõi vi·ªác s·ª≠ d·ª•ng ch·ª©c nƒÉng DynamoDB g·ªëc. M·ªói m·ª•c DynamoDB c√≥ k√≠ch th∆∞·ªõc d∆∞·ªõi 1KB v√† ƒë∆∞·ª£c l∆∞u tr·ªØ trong b·∫£ng s·ª≠ d·ª•ng ch·∫ø ƒë·ªô on-demand t·∫°i v√πng us-east-1. C√°c t·∫ßng mi·ªÖn ph√≠ kh√¥ng ƒë∆∞·ª£c xem x√©t trong ph√¢n t√≠ch n√†y.\nTTL g·∫ßn th·ªùi gian th·ª±c TTL DynamoDB b·∫£n ƒë·ªãa DynamoDB Stream $0 (DynamoDB streams mi·ªÖn ph√≠ khi ƒë∆∞·ª£c ti√™u th·ª• b·ªüi Lambda) - Lambda EventBridge Scheduler $1 - DynamoDB Delete $0.63 - T·ªïng Chi ph√≠ $1.63 $0 H·∫°n ch·∫ø Gi·ªõi h·∫°n tr√™n cho gi·∫£i ph√°p n√†y li√™n quan ƒë·∫øn h·∫°n m·ª©c t·ªëc ƒë·ªô y√™u c·∫ßu c·ªßa EventBridge Scheduler. C√°c y√™u c·∫ßu CreateSchedule, UpdateSchedule v√† DeleteSchedule m·∫∑c ƒë·ªãnh ƒë·ªÅu c√≥ gi·ªõi h·∫°n t·ªëi ƒëa l√† 1.000 y√™u c·∫ßu m·ªói gi√¢y ƒë·ªëi v·ªõi h·∫ßu h·∫øt c√°c khu v·ª±c. C√°c gi·ªõi h·∫°n n√†y c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c. N·∫øu gi·ªõi h·∫°n n√†y b·ªã v∆∞·ª£t qu√°, EventBridge Scheduler s·∫Ω t·ª´ ch·ªëi m·ªçi y√™u c·∫ßu cho thao t√°c ƒë√≥ trong kho·∫£ng th·ªùi gian c√≤n l·∫°i. Dead-Letter Queue - DLQ c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ b·∫Øt v√† th·ª±c hi·ªán l·∫°i c√°c l·∫ßn th·ª±c thi th·∫•t b·∫°i.\nEventBridge Scheduler c≈©ng √°p d·ª•ng m·ªôt gi·ªõi h·∫°n ƒëi·ªÅu ti·∫øt (throttle limit) ƒë·ªëi v·ªõi l∆∞·ª£t g·ªçi m·ª•c ti√™u (target invocations) ƒë·ªìng th·ªùi, m·∫∑c ƒë·ªãnh l√† 1.000 l∆∞·ª£t g·ªçi m·ªói gi√¢y ·ªü h·∫ßu h·∫øt c√°c khu v·ª±c. ƒêi·ªÅu n√†y ƒë·ªÅ c·∫≠p ƒë·∫øn t·ªëc ƒë·ªô m√† c√°c schedule payloads ƒë∆∞·ª£c g·ª≠i ƒë·∫øn c√°c m·ª•c ti√™u c·ªßa ch√∫ng. N·∫øu gi·ªõi h·∫°n n√†y b·ªã v∆∞·ª£t qu√°, c√°c l∆∞·ª£t g·ªçi s·∫Ω kh√¥ng b·ªã h·ªßy b·ªè m√† b·ªã ƒëi·ªÅu ti·∫øt (throttled), nghƒ©a l√† ch√∫ng s·∫Ω b·ªã tr√¨ ho√£n v√† ƒë∆∞·ª£c x·ª≠ l√Ω sau. H·∫°n m·ª©c (quota) n√†y c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh v√† c√≥ th·ªÉ m·ªü r·ªông l√™n ƒë·∫øn h√†ng ch·ª•c ngh√¨n l∆∞·ª£t g·ªçi m·ªói gi√¢y.\nCu·ªëi c√πng, m·ªôt gi·ªõi h·∫°n tr√™n kh√°c ƒë·ªëi v·ªõi gi·∫£i ph√°p n√†y s·∫Ω l√† h·∫°n m·ª©c th·ª±c thi ƒë·ªìng th·ªùi (concurrent executions quota) c√≥ s·∫µn cho c√°c Lambda function c·ªßa b·∫°n, m·∫∑c ƒë·ªãnh l√† 1.000 m·ªói gi√¢y cho m·ªói t√†i kho·∫£n. ƒê√¢y l√† m·ªôt gi·ªõi h·∫°n quan tr·ªçng c·∫ßn xem x√©t, ƒë·∫∑c bi·ªát n·∫øu b·∫°n c√≥ c√°c Lambda function kh√°c ƒëang ch·∫°y trong c√πng m·ªôt t√†i kho·∫£n. N·∫øu b·∫°n ƒë·∫°t ƒë·∫øn gi·ªõi h·∫°n ƒë·ªìng th·ªùi (concurrency limit), function c·ªßa b·∫°n s·∫Ω b·ªã ƒëi·ªÅu ti·∫øt (throttled). Gi·ªõi h·∫°n n√†y c√≥ th·ªÉ ƒë∆∞·ª£c tƒÉng l√™n.\nD·ªçn d·∫πp N·∫øu b·∫°n t·∫°o m√¥i tr∆∞·ªùng ki·ªÉm tra ƒë·ªÉ theo d√µi b√†i vi·∫øt n√†y, h√£y ch·∫Øc ch·∫Øn:\nX√≥a DynamoDB table\nX√≥aÔªø Lambda function\nX√≥a EventBridge schedule\nX√≥a b·∫•t k·ª≥ rolesÔªø IAM n√†o ƒë∆∞·ª£c t·∫°o trong qu√° tr√¨nh n√†y\nX√≥a b·∫•t k·ª≥ t√†i nguy√™n n√†o kh√°c b·∫°n ƒë√£ t·∫°o ƒë·ªÉ ki·ªÉm tra gi·∫£i ph√°p\nK·∫øt lu·∫≠n Trong b√†i vi·∫øt n√†y, ch√∫ng t√¥i ƒë√£ kh√°m ph√° c√°ch b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng Amazon EventBridge Scheduler ƒë·ªÉ tri·ªÉn khai TTL g·∫ßn th·ªùi gian th·ª±c cho DynamoDB, gi·∫£m th·ªùi gian x√≥a m·ªôt itemÔªø sau khi TTL h·∫øt h·∫°n t·ª´ v√†i ng√†y xu·ªëng th∆∞·ªùng d∆∞·ªõi 1-2 ph√∫t.\nGi·∫£i ph√°p serverlessÔªø n√†y thu h·∫πp kho·∫£ng c√°ch gi·ªØa kh·∫£ nƒÉng t√≠ch h·ª£p s·∫µn c·ªßa DynamoDB v√† nhu c·∫ßu lo·∫°i b·ªè itemsÔªø ngay l·∫≠p t·ª©c, c√≥ ki·ªÉm so√°t. M·∫∑c d√π n√≥ ph√°t sinh m·ªôt s·ªë chi ph√≠ b·ªï sung so v·ªõi ch·ª©c nƒÉng TTL b·∫£n ƒë·ªãa, n√≥ gi·∫£i quy·∫øt hi·ªáu qu·∫£ nhu c·∫ßu lo·∫°i b·ªè d·ªØ li·ªáu nhanh ch√≥ng v√† ƒë√°ng tin c·∫≠y.\nC√°ch ti·∫øp c·∫≠n n√†y c√≥ th·ªÉ m·ªü r·ªông ƒë·∫øn h√†ng t·ª∑ recordsÔªø x√≥a TTL ho·∫°t ƒë·ªông, v·ªõi th·ªùi gian x√≥a tƒÉng l√™n khi vi·ªác x√≥a ƒë·ªìng th·ªùi m·ªü r·ªông v∆∞·ª£t qu√° gi·ªõi h·∫°n g·ªçi EventBridge Scheduler.\nTrong Ph·∫ßn 2, ch√∫ng t√¥i s·∫Ω ƒëi s√¢u h∆°n v√†o vi·ªác tri·ªÉn khai lo·∫°i b·ªè d·ªØ li·ªáu nghi√™m ng·∫∑t trong DynamoDB s·ª≠ d·ª•ng Global Secondary Index. Lo·∫°t b√†i k·∫øt th√∫c v·ªõi Ph·∫ßn 3, n∆°i ch√∫ng t√¥i s·∫Ω s·ª≠ d·ª•ng Amazon EventBridge Scheduler ƒë·ªÉ l√™n l·ªãch s·ª± ki·ªán chi ti·∫øt. Nh·ªØng patternsÔªø h∆∞·ªõng s·ª± ki·ªán n√†y s·∫Ω gi√∫p b·∫°n t·ª± ƒë·ªông h√≥a c√°c quy tr√¨nh ch√≠nh, duy tr√¨ d·ªØ li·ªáu ch√≠nh x√°c v√† ƒë√°p ·ª©ng c√°c y√™u c·∫ßu ·ª©ng d·ª•ng ch√≠nh x√°c v·ªõi n·ªó l·ª±c th·ªß c√¥ng t·ªëi thi·ªÉu.\nV·ªÅ c√°c t√°c gi·∫£\nLee Hannigan Lee Hannigan l√† Chuy√™n gia gi·∫£i ph√°p DynamoDB cao c·∫•p (Sr. DynamoDB Specialist Solutions Architect) l√†m vi·ªác t·∫°i Donegal, Ireland. Anh c√≥ chuy√™n m√¥n s√¢u r·ªông v·ªÅ c√°c h·ªá th·ªëng ph√¢n t√°n (distributed systems), c√πng n·ªÅn t·∫£ng v·ªØng ch·∫Øc v·ªÅ c√°c c√¥ng ngh·ªá d·ªØ li·ªáu l·ªõn (big data) v√† ph√¢n t√≠ch (analytics technologies). Trong vai tr√≤ Chuy√™n gia gi·∫£i ph√°p DynamoDB, Lee xu·∫•t s·∫Øc trong vi·ªác h·ªó tr·ª£ kh√°ch h√†ng thi·∫øt k·∫ø, ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác (workloads) s·ª≠ d·ª•ng c√°c kh·∫£ nƒÉng c·ªßa DynamoDB. Aman Dhingra Aman Dhingra l√† Chuy√™n gia gi·∫£i ph√°p DynamoDB cao c·∫•p (Sr. DynamoDB Specialist Solutions Architect) l√†m vi·ªác t·∫°i Dublin, Ireland. Anh c√≥ ƒëam m√™ v·ªÅ c√°c h·ªá th·ªëng ph√¢n t√°n (distributed systems) v√† n·ªÅn t·∫£ng chuy√™n s√¢u v·ªÅ d·ªØ li·ªáu l·ªõn \u0026amp; ph√¢n t√≠ch (big data \u0026amp; analytics). Aman l√† t√°c gi·∫£ c·ªßa cu·ªën \u0026ldquo;Amazon DynamoDB ‚Äì The Definitive Guide\u0026rdquo; v√† h·ªó tr·ª£ kh√°ch h√†ng trong vi·ªác thi·∫øt k·∫ø, ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác v·∫≠n h√†nh tr√™n Amazon DynamoDB. Jack Le Bon Jack Le Bon l√† Ki·∫øn tr√∫c s∆∞ gi·∫£i ph√°p (Solutions Architect) l√†m vi·ªác t·∫°i London, chuy√™n h·ªó tr·ª£ c√°c kh√°ch h√†ng thu·ªôc lƒ©nh v·ª±c truy·ªÅn th√¥ng v√† gi·∫£i tr√≠ (Media \u0026amp; Entertainment). L√† th√†nh vi√™n c·ªßa nh√≥m chuy√™n v·ªÅ c√¥ng ngh·ªá kh√¥ng m√°y ch·ªß (Serverless speciality group) t·∫°i AWS, Jack gi√∫p kh√°ch h√†ng thi·∫øt k·∫ø v√† tri·ªÉn khai ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán (event-driven architectures) s·ª≠ d·ª•ng c√°c c√¥ng ngh·ªá Serverless. Jack t·∫≠p trung v√†o h·ªó tr·ª£ c√°c t·ªï ch·ª©c x√¢y d·ª±ng ki·∫øn tr√∫c hi·ªáu qu·∫£, gi√∫p h·ªç t·∫≠p trung v√†o ho·∫°t ƒë·ªông kinh doanh c·ªët l√µi thay v√¨ qu·∫£n l√Ω h·∫° t·∫ßng. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Tri·ªÉn khai ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán v·ªõi Amazon DynamoDB ‚Äì Ph·∫ßn 3 b·ªüi Lee Hannigan v√† Aman Dhingra | v√†o ng√†y 25 th√°ng 9 nƒÉm 2025 | trong Advanced (300), Amazon DynamoDB, Amazon EventBridge, AWS Lambda, Serverless, Technical How-to\n·ªû Ph·∫ßn 1, ch√∫ng ta ƒë√£ t√¨m hi·ªÉu c√°ch s·ª≠ d·ª•ng Amazon EventBridge Scheduler ƒë·ªÉ x√≥a d·ªØ li·ªáu t·ª± ƒë·ªông trong Amazon DynamoDB m·ªôt c√°ch ch√≠nh x√°c. Ph·∫ßn 2 ƒë√£ th·∫£o lu·∫≠n c√°ch s·ª≠ d·ª•ng global secondary index (GSI) ƒë·ªÉ qu·∫£n l√Ω d·ªØ li·ªáu nghi√™m ng·∫∑t trong DynamoDB. B√†i vi·∫øt n√†y t·∫≠p trung v√†o vi·ªác s·ª≠ d·ª•ng EventBridge Scheduler ƒë·ªÉ l·∫≠p l·ªãch s·ª± ki·ªán chi ti·∫øt d·ª±a tr√™n d·ªØ li·ªáu ghi v√†o DynamoDB.\nTrong to√†n b·ªô chu·ªói b√†i, ch√∫ng t√¥i ki·ªÉm tra c√°c chi·∫øn l∆∞·ª£c qu·∫£n l√Ω d·ªØ li·ªáu trong DynamoDB. B√†i n√†y chuy·ªÉn sang m·∫´u h∆∞·ªõng s·ª± ki·ªán ƒë·ªÉ l√™n l·ªãch h√†nh ƒë·ªông downstream tin c·∫≠y trong t∆∞∆°ng lai b·∫±ng EventBridge Scheduler. M·ªôt l·ª£i th·∫ø c·ªßa c√°ch ti·∫øp c·∫≠n n√†y l√† kh·∫£ nƒÉng k√≠ch ho·∫°t c√°c s·ª± ki·ªán downstream quan tr·ªçng v·ªÅ th·ªùi gian, nh∆∞ g·ª≠i th√¥ng b√°o nh·∫Øc nh·ªü c√°c cu·ªôc h·∫πn, h·∫øt h·∫°n ∆∞u ƒë√£i, ho·∫∑c gia h·∫°n ƒëƒÉng k√Ω. V√≠ d·ª•, khi ƒëƒÉng k√Ω c·ªßa ng∆∞·ªùi d√πng s·∫Øp h·∫øt h·∫°n, EventBridge Scheduler c√≥ th·ªÉ k√≠ch ho·∫°t m·ªôt s·ª± ki·ªán g·ªçi AWS Lambda k√®m chi ti·∫øt item DynamoDB li√™n quan. Lambda n√†y sau ƒë√≥ c√≥ th·ªÉ d√πng Amazon Simple Email Service (Amazon SES) ƒë·ªÉ g·ª≠i th√¥ng b√°o k·ªãp th·ªùi t·ªõi ng∆∞·ªùi d√πng.\nKi·∫øn tr√∫c n√†y gi√∫p ng∆∞·ªùi d√πng nh·∫≠n ƒë∆∞·ª£c nh·∫Øc nh·ªü ƒë√∫ng l√∫c, c·∫£i thi·ªán tr·∫£i nghi·ªám v√† tƒÉng m·ª©c ƒë·ªô t∆∞∆°ng t√°c. EventBridge Scheduler linh ho·∫°t cho ph√©p ki·ªÉm so√°t ch√≠nh x√°c th·ªùi gian th√¥ng b√°o, ƒë√°p ·ª©ng nhi·ªÅu b√†i to√°n kinh doanh kh√°c nhau.\nT·ªïng quan gi·∫£i ph√°p Gi·∫£i ph√°p n√†y tr√¨nh di·ªÖn c√°ch s·ª≠ d·ª•ng Amazon DynamoDB Streams v√† AWS Lambda ƒë·ªÉ t·ª± ƒë·ªông l√™n l·ªãch h√†nh ƒë·ªông trong t∆∞∆°ng lai d·ª±a tr√™n vi·ªác ghi item v√†o DynamoDB. B·∫±ng c√°ch nh·∫≠n stream records t·ª´ c√°c l·∫ßn ghi, m·ªôt h√†m Lambda ƒë∆∞·ª£c k√≠ch ho·∫°t ƒë·ªÉ t·∫°o c√°c l·ªãch chi ti·∫øt theo th·ªùi gian qua Amazon EventBridge Scheduler. Nh·ªØng l·ªãch n√†y sau ƒë√≥ c√≥ th·ªÉ g·ªçi c√°c d·ªãch v·ª• downstream nh∆∞ Amazon SES ƒë·ªÉ g·ª≠i email nh·∫Øc nh·ªü, Amazon Simple Queue Service (Amazon SQS), AWS Step Functions ho·∫∑c c√°c d·ªãch v·ª• AWS kh√°c, cho ph√©p quy tr√¨nh h∆∞·ªõng s·ª± ki·ªán c√≥ t√≠nh m·ªü r·ªông, tin c·∫≠y cao.\nS∆° ƒë·ªì sau minh h·ªça ki·∫øn tr√∫c gi·∫£i ph√°p.\nM·ªôt tr∆∞·ªùng h·ª£p ph·ªï bi·∫øn cho m·∫´u n√†y l√† l·∫≠p l·ªãch c√°c s·ª± ki·ªán trong t∆∞∆°ng lai nh∆∞ nh·∫Øc nh·ªü cu·ªôc h·∫πn, h·∫øt h·∫°n ∆∞u ƒë√£i, ho·∫∑c gia h·∫°n ƒëƒÉng k√Ω v·ªõi ƒë·ªô tin c·∫≠y cao. EventBridge Scheduler cho ph√©p l·∫≠p l·ªãch h√†nh ƒë·ªông m·ªôt l·∫ßn ho·∫∑c l·∫∑p l·∫°i d·ª±a tr√™n thu·ªôc t√≠nh l∆∞u trong c√°c item DynamoDB. Lu·ªìng ho·∫°t ƒë·ªông nh∆∞ sau:\nGhi d·ªØ li·ªáu ‚Äì Khi m·ªôt item ƒë∆∞·ª£c ghi l√™n DynamoDB table, m·ªôt b·∫£n ghi stream ·ª©ng s·∫Ω ƒë∆∞·ª£c t·∫°o trong DynamoDB stream ƒë∆∞·ª£c li√™n k·∫øt c·ªßa n√≥.\nK√≠ch ho·∫°t ‚Äì B·∫£n ghi stream n√†y, ri√™ng l·∫ª ho·∫∑c trong batch, s·∫Ω k√≠ch ho·∫°t m·ªôt AWS Lambda function.\nT·∫°o l·ªãch ‚Äì Lambda function d√πng EventBridge Scheduler ƒë·ªÉ l√™n l·ªãch trong t∆∞∆°ng lai. L·ªãch bao g·ªìm timestamp ch√≠nh x√°c v√† d·ªØ li·ªáu item li√™n quan.\nK√≠ch ho·∫°t m·ª•c ti√™u ‚Äì ƒê·∫øn th·ªùi gian ƒë√£ ƒë·ªãnh, EventBridge Scheduler g·ªçi m·ª•c ti√™u c·∫•u h√¨nh, v√≠ d·ª• g·ª≠i email v·ªõi Amazon SES, ƒë∆∞a message v√†o SQS, ho·∫∑c b·∫Øt ƒë·∫ßu th·ª±c thi Step Functions.\nKi·∫øn tr√∫c n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ m·ªü r·ªông theo d·ªØ li·ªáu, cho ph√©p l·∫≠p l·ªãch logic ch√≠nh x√°c m√† kh√¥ng l√†m ph·ª©c t·∫°p m√¥ h√¨nh d·ªØ li·ªáu DynamoDB ho·∫∑c c·∫ßn polling li√™n t·ª•c. H√£y tham kh·∫£o c√°c b∆∞·ªõc √°p d·ª•ng gi·∫£i ph√°p.\nY√™u c·∫ßu tr∆∞·ªõc Tr∆∞·ªõc khi √°p d·ª•ng gi·∫£i ph√°p h∆∞·ªõng s·ª± ki·ªán, b·∫°n c·∫ßn ph·∫£i c√≥ c√°c y√™u c·∫ßu sau:\nT√†i kho·∫£n AWS ‚Äì Truy c·∫≠p m·ªôt t√†i kho·∫£n AWS ƒëang ho·∫°t ƒë·ªông.\nKi·∫øn th·ª©c c∆° b·∫£n v·ªÅ DynamoDB ‚Äì Hi·ªÉu v·ªÅ kh√°i ni·ªám DynamoDB: b·∫£ng, item, thu·ªôc t√≠nh, thao t√°c CRUD c∆° b·∫£n l√† c·∫ßn thi·∫øt ƒë·ªÉ c·∫•u h√¨nh v√† qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu m·ªôt c√°ch hi·ªáu qu·∫£.\nLambda functions ‚Äì Th√†nh th·∫°o Lambda v√¨ b·∫°n s·∫Ω t·∫°o v√† tri·ªÉn khai Lambda function ƒë·ªÉ x·ª≠ l√Ω s·ª± ki·ªán Amazon DynamoDB Streams v√† t·∫°o l·ªãch qua EventBridge Scheduler.\nEventBridge Scheduler ‚Äì Ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ Amazon EventBridge l√† c·∫ßn thi·∫øt cho vi·ªác c·∫•u h√¨nh EventBridge Scheduler rule ƒë·ªÉ g·ªçi API c·ª• th·ªÉ.\nAmazon SES ‚Äì Ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ Amazon SES v√† x√°c th·ª±c email ng∆∞·ªùi g·ª≠i. ƒê·ªÉ t·∫°o v√† x√°c th·ª±c ƒë·ªãa ch·ªâ email, xem t·∫°i Creating and verifying identities in Amazon SES.\nTh√†nh th·∫°o AWS CLI ho·∫∑c console ‚Äì Th√†nh th·∫°o d√πng AWS Command Line Interface (AWS CLI) ho·∫∑c AWS Management Console cho vi·ªác c·∫•u h√¨nh d·ªãch v·ª•, t·∫°o resource v√† gi√°m s√°t log.\nT·∫°o b·∫£ng DynamoDB Ho√†n th√†nh c√°c b∆∞·ªõc sau ƒë·ªÉ t·∫°o DynamoDB table:\n·ªû DynamoDB console, ch·ªçn Tables ·ªü thanh ƒëi·ªÅu h∆∞·ªõng.\nCh·ªçn Create table.\nV√≥i t√™n Table, nh·∫≠p t√™n table c·ªßa b·∫°n.\nV·ªõi Partition key, nh·∫≠p PK l√†m t√™n, ch·ªçn ki·ªÉu String l√†m ki·ªÉu d·ªØ li·ªáu.\nV·ªõi Sort key, nh·∫≠p SK l√†m t√™n, ch·ªçn ki·ªÉu String l√†m ki·ªÉu d·ªØ li·ªáu.\nƒê·ªÉ m·∫∑c ƒë·ªãnh c√°c c·∫•u h√¨nh kh√°c, ch·ªçn Create table. B·∫£ng s·∫Ω t·∫°o sau v√†i gi√¢y.\nV√†o l·∫°i Tables, m·ªü b·∫£ng v·ª´a t·∫°o.\nTrong m·ª•c DynamoDB stream details, ch·ªçn Turn on.\nCh·ªçn New and old images, sau ƒë√≥ ch·ªçn Turn on stream. ƒêi·ªÅu n√†y s·∫Ω cho ph√©p Lu·ªìng DynamoDB tr√™n b·∫£ng hi·ªÉn th·ªã c·∫£ tr·∫°ng th√°i c≈© v√† m·ªõi c·ªßa c√°c m·ª•c trong b·∫£n ghi stream, ƒë·ªÉ b·∫°n c√≥ th·ªÉ qu·∫£n l√Ω c√°c c·∫≠p nh·∫≠t gi√° tr·ªã Time to Live (TTL) c·ªßa c√°c item.\nT·∫°o Lambda function Ho√†n th√†nh c√°c b∆∞·ªõc sau ƒë·ªÉ t·∫°o Lambda function:\nV√†o console Lambda, ch·ªçn Functions.\nCh·ªçn Create function.\nCh·ªçn Author from scratch.\nƒê·ªëi v·ªõi Function name, h√£y nh·∫≠p t√™n (v√≠ d·ª•: DDBStreamTriggerEventScheduler).\nCh·ªçn Runtime Node.js m·ªõi nh·∫•t.\nƒê·ªëi v·ªõi vai tr√≤ d·ªãch v·ª• Lambda m√† b·∫°n ƒë√£ g·∫Øn v√†o function, h√£y th√™m ch√≠nh s√°ch ƒë∆∞·ª£c qu·∫£n l√Ω AWS Identity and Access Management (IAM) AWSLambdaDynamoDBExecutionRole v√† m·ªôt ch√≠nh s√°ch n·ªôi tuy·∫øn c√≥ quy·ªÅn l√™n l·ªãch: CreateSchedule.\nCh·ªçn Create function.\nSau khi t·∫°o Lambda function, ch·ªçn Add trigger ƒë·ªÉ c·∫•u h√¨nh event source mapping cho b·∫£ng DynamoDB.\nCh·ªçn DynamoDB l√†m source.\nƒê·ªëi v·ªõi DynamoDB table, h√£y nh·∫≠p ARN cho Appointment-Table.\nƒê·ªÉ m·∫∑c ƒë·ªãnh c√°c c·∫•u h√¨nh c√≤n l·∫°i, ch·ªçn Add ƒë·ªÉ t·∫°o trigger.\n·ªû tab Code c·ªßa Lambda function, thay code m·∫∑c ƒë·ªãnh b·∫±ng ƒëo·∫°n m√£ Node.js sau. ƒê·∫£m b·∫£o c·∫≠p nh·∫≠t ph·∫ßn gi·ªØ ch·ªó v·ªõi c√°c gi√° tr·ªã th√≠ch h·ª£p‚Äîch·∫≥ng h·∫°n nh∆∞ thay th·∫ø ses-verified-email@example.com b·∫±ng ƒë·ªãa ch·ªâ email Amazon SES ƒë√£ ƒë∆∞·ª£c x√°c minh c·ªßa b·∫°n. Ngo√†i ra, h√£y ƒë·∫£m b·∫£o r·∫±ng vai tr√≤ IAM m√† EventBridge Scheduler s·ª≠ d·ª•ng c√≥ quy·ªÅn ses:SendEmail. import { SchedulerClient, CreateScheduleCommand } from \u0026#34;@aws-sdk/client-scheduler\u0026#34;; const client = new SchedulerClient({ region: \u0026#34;eu-west-1\u0026#34; }); export const handler = async (event) =\u0026gt; { try { for (const record of event.Records) { let params = { eventID: record.eventID, sequenceNumber: record.dynamodb.SequenceNumber, email: record.dynamodb.NewImage.email.S, subject: \u0026#34;Time for your appointment\u0026#34;, reminderTS: record.dynamodb.NewImage.REMINDER_TIMESTAMP.S, // Expects ISO format }; params.body = \u0026#34;This is the email body, you have a reminder\u0026#34;; await scheduleEmail(params); } return { statusCode: 200, body: JSON.stringify(\u0026#39;Complete\u0026#39;), }; } catch (error) { console.error(\u0026#34;Error processing event: \u0026#34;, error); return { statusCode: 500, body: JSON.stringify({ message: \u0026#39;Error processing event\u0026#39;, error: error.message }), }; } }; const scheduleEmail = async (params) =\u0026gt; { try { const sesParams = { Destination: { ToAddresses: [params.email] }, Message: { Body: { Text: { Data: params.body } }, Subject: { Data: params.subject }, }, Source: \u0026#34;ses-verified-email@example.com\u0026#34;, }; const target = { RoleArn: \u0026#34;arn:aws:iam::YOUR_ACCOUNT_ID:role/YourSchedulerRole\u0026#34;, Arn: \u0026#34;arn:aws:scheduler:::aws-sdk:ses:sendEmail\u0026#34;, Input: JSON.stringify(sesParams), }; const schedulerInput = { Name: `Appointment_Reminder_${params.eventID}`, FlexibleTimeWindow: { Mode: \u0026#34;OFF\u0026#34; }, ActionAfterCompletion: \u0026#34;DELETE\u0026#34;, Target: target, ScheduleExpression: `at(${params.reminderTS})`, ClientToken: params.sequenceNumber, }; const command = new CreateScheduleCommand(schedulerInput); const result = await client.send(command); return result; } catch (error) { console.error(\u0026#34;Error scheduling email: \u0026#34;, error); throw new Error(`Failed to schedule email: ${error.message}`); } }; Ch·ªçn Deploy ƒë·ªÉ tri·ªÉn khai code m·ªõi nh·∫•t. M·∫πo: ƒê·ªÉ c·∫£i thi·ªán ƒë·ªô tin c·∫≠y v√† kh·∫£ nƒÉng theo d√µi, b·∫°n c√≥ th·ªÉ ƒë·ªãnh c·∫•u h√¨nh Dead Letter Queues (DLQ) t·∫°i hai ƒëi·ªÉm trong ki·∫øn ‚Äã‚Äãtr√∫c n√†y. Tr∆∞·ªõc ti√™n, b·∫°n c√≥ th·ªÉ th√™m DLQ v√†o Lambda function s·ª≠ d·ª•ng t·ª´ DynamoDB stream, thao t√°c n√†y ghi l·∫°i m·ªçi l·ªói x·∫£y ra trong khi x·ª≠ l√Ω b·∫£n ghi stream ho·∫∑c t·∫°o l·ªãch tr√¨nh, ch·∫≥ng h·∫°n nh∆∞ l·ªói ƒë·∫ßu v√†o ho·∫∑c l·ªói quy·ªÅn h·∫°n. Th·ª© hai, b·∫°n c√≥ th·ªÉ ƒë·ªãnh c·∫•u h√¨nh DLQ nh∆∞ m·ªôt ph·∫ßn c·ªßa EventBridge Scheduler target. ƒêi·ªÅu n√†y ghi l·∫°i c√°c l·ªói x·∫£y ra t·∫°i th·ªùi ƒëi·ªÉm th·ª±c thi, ch·∫≥ng h·∫°n nh∆∞ n·∫øu Amazon SES kh√¥ng g·ª≠i ƒë∆∞·ª£c email ho·∫∑c d·ªãch v·ª• ƒë√≠ch kh√¥ng kh·∫£ d·ª•ng. Vi·ªác s·ª≠ d·ª•ng c·∫£ hai DLQ cho ph√©p b·∫°n theo d√µi, ph√¢n t√≠ch v√† th·ª≠ l·∫°i c√°c l·ªói trong to√†n b·ªô v√≤ng ƒë·ªùi l·∫≠p k·∫ø ho·∫°ch v√† ph√¢n ph·ªëi.\nSinh d·ªØ li·ªáu m·∫´u ƒë·ªÉ ki·ªÉm tra gi·∫£i ph√°p Ch·∫°y l·ªánh AWS CLI sau ƒë·ªÉ m√¥ ph·ªèng ho·∫°t ƒë·ªông ghi v√†o DynamoDB table c·ªßa b·∫°n. V√≤ng l·∫∑p n√†y ch√®n 10 items m·∫´u v√†o b·∫£ng, m·ªói m·ª•c c√≥ m·ªôt kh√≥a ph√¢n v√πng duy nh·∫•t (PK) v√† m·ªôt kh√≥a s·∫Øp x·∫øp tƒ©nh (SK). M·ªói m·ª•c bao g·ªìm REMINDER_TIMESTAMP ƒë∆∞·ª£c ƒë·∫∑t th√†nh 3 ph√∫t k·ªÉ t·ª´ th·ªùi ƒëi·ªÉm hi·ªán t·∫°i v√† ƒë·ªãa ch·ªâ email ki·ªÉm tra. Nh·ªØng l·∫ßn ghi n√†y s·∫Ω k√≠ch ho·∫°t DynamoDB Stream, lu·ªìng n√†y g·ªçi Lambda function c·ªßa b·∫°n ƒë·ªÉ l√™n l·ªãch g·ª≠i email nh·∫Øc nh·ªü th√¥ng qua EventBridge Scheduler. H√£y nh·ªõ thay th·∫ø abc@example.com b·∫±ng ƒë·ªãa ch·ªâ email h·ª£p l·ªá, ƒë√£ ƒë∆∞·ª£c x√°c minh trong Amazon SES ƒë·ªÉ quan s√°t to√†n b·ªô quy tr√¨nh c·ªßa gi·∫£i ph√°p.\n#!/bin/bash TABLE=\u0026#34;Appointment-Table\u0026#34; for PK_VALUE in {1..10}; do ISO_TIMESTAMP_PLUS_3_MINS=$(date -v+3M -u +\u0026#34;%Y-%m-%dT%H:%M:%S\u0026#34;) aws dynamodb put-item --table-name $TABLE \\ --item \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;StaticSK\u0026#34;}, \u0026#34;REMINDER_TIMESTAMP\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$ISO_TIMESTAMP_PLUS_3_MINS\u0026#39;\u0026#34;}, \u0026#34;email\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;abc@example.com\u0026#34;}, \u0026#34;ATTR_1\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;This is a static attribute\u0026#34;}}\u0026#39; done ƒê·ªÉ theo d√µi c√°c email nh·∫Øc nh·ªü ƒëang ƒë∆∞·ª£c g·ª≠i, h√£y ƒëi·ªÅu h∆∞·ªõng ƒë·∫øn Monitoring tab c·ªßa EventBridge schedule group. B·∫°n c√≥ th·ªÉ xem c√°c s·ª± ki·ªán ƒë∆∞·ª£c EventBridge Scheduler g·ªçi v√†o m·ªôt th·ªùi ƒëi·ªÉm c·ª• th·ªÉ b·∫±ng c√°ch xem s·ªë li·ªáu InvocationAttemptCount. Trong tr∆∞·ªùng h·ª£p c·ªßa ch√∫ng ta, l·ªùi g·ªçi l√† c√°c email nh·∫Øc nh·ªü cu·ªôc h·∫πn t·ªõi ng∆∞·ªùi d√πng th√¥ng qua Amazon SES. ƒê·ªÉ c√≥ danh s√°ch t·∫•t c·∫£ s·ªë li·ªáu c√≥ s·∫µn cho m·ªôt schedule group, tham kh·∫£o Monitoring Amazon EventBridge Scheduler with Amazon CloudWatch.\nD·ªçn d·∫πp N·∫øu b·∫°n d·ª±ng m√¥i tr∆∞·ªùng test theo b√†i vi·∫øt, nh·ªõ xo√° DynamoDB table, Lambda function, EventBridge schedule v√† c√°c resource kh√°c ƒë√£ t·∫°o ƒë·ªÉ ti·∫øt ki·ªám chi ph√≠.\nT√≥m t·∫Øt Trong b√†i vi·∫øt n√†y, ch√∫ng ta ƒë√£ ƒë∆∞·ª£c tr√¨nh b√†y c√°ch d√πng EventBridge Scheduler ƒë·ªÉ l·∫≠p l·ªãch s·ª± ki·ªán chi ti·∫øt d·ª±a tr√™n d·ªØ li·ªáu ghi ·ªü DynamoDB. Gi·∫£i ph√°p n√†y cho ph√©p b·∫°n th·ª±c hi·ªán c√°c h√†nh ƒë·ªông ch√≠nh x√°c, k·ªãp th·ªùi d·ª±a tr√™n d·∫•u th·ªùi gian ƒë∆∞·ª£c l∆∞u tr·ªØ trong DynamoDB items khi b·∫°n mu·ªën g·ª≠i th√¥ng b√°o c√≥ gi·ªõi h·∫°n th·ªùi gian ho·∫∑c g·ªçi c√°c downstream jobs.\nTrong lo·∫°t b√†i g·ªìm ba ph·∫ßn n√†y, ch√∫ng ta ƒë√£ kh√°m ph√° c√°ch m·ªü r·ªông c√°c kh·∫£ nƒÉng g·ªëc c·ªßa Amazon DynamoDB b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c m·∫´u ki·∫øn ‚Äã‚Äãtr√∫c h∆∞·ªõng s·ª± ki·ªán ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh cho ph√π h·ª£p v·ªõi nhu c·∫ßu trong th·∫ø gi·ªõi th·ª±c:\nPh·∫ßn 1: Gi·ªõi thi·ªáu gi·∫£i ph√°p TTL g·∫ßn real-time, d√πng EventBridge Scheduler x√≥a item qu√° h·∫°n b·∫±ng ƒë·ªô ch√≠nh x√°c cao h∆°n TTL g·ªëc.\nPh·∫ßn 2: Tr√¨nh b√†y c√°ch x√¢y d·ª±ng gi·∫£i ph√°p qu·∫£n l√Ω d·ªØ li·ªáu nghi√™m ng·∫∑t b·∫±ng c√°ch s·ª≠ d·ª•ng sharded global secondary index (GSI), EventBridge Scheduler v√† Lambda ƒë·ªÉ truy v·∫•n ƒë·ªãnh k·ª≥ v√† lo·∫°i b·ªè c√°c b·∫£n ghi ƒë√£ h·∫øt h·∫°n.\nPh·∫ßn 3: T·∫≠p trung v√†o vi·ªác s·ª≠ d·ª•ng DynamoDB Streams v√† EventBridge Scheduler ƒë·ªÉ l√™n l·ªãch c√°c h√†nh ƒë·ªông xu√¥i d√≤ng trong t∆∞∆°ng lai d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c ghi v√†o DynamoDB table, ch·∫≥ng h·∫°n nh∆∞ g·ª≠i email nh·∫Øc nh·ªü cho c√°c cu·ªôc h·∫πn s·∫Øp t·ªõi.\nƒê·ªÉ t√¨m hi·ªÉu s√¢u h∆°n v√† kh√°m ph√° th√™m best practice thi·∫øt k·∫ø v·ªõi DynamoDB, EventBridge t·∫°i t√†i li·ªáu Amazon DynamoDB v√† t√†i li·ªáu Amazon EventBridge.\nV·ªÅ c√°c t√°c gi·∫£\nLee Hannigan Lee Hannigan l√† Chuy√™n gia gi·∫£i ph√°p DynamoDB cao c·∫•p (Sr. DynamoDB Specialist Solutions Architect) l√†m vi·ªác t·∫°i Donegal, Ireland. Anh c√≥ chuy√™n m√¥n s√¢u r·ªông v·ªÅ c√°c h·ªá th·ªëng ph√¢n t√°n (distributed systems), c√πng n·ªÅn t·∫£ng v·ªØng ch·∫Øc v·ªÅ c√°c c√¥ng ngh·ªá d·ªØ li·ªáu l·ªõn (big data) v√† ph√¢n t√≠ch (analytics technologies). Trong vai tr√≤ Chuy√™n gia gi·∫£i ph√°p DynamoDB, Lee xu·∫•t s·∫Øc trong vi·ªác h·ªó tr·ª£ kh√°ch h√†ng thi·∫øt k·∫ø, ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác (workloads) s·ª≠ d·ª•ng c√°c kh·∫£ nƒÉng c·ªßa DynamoDB. Aman Dhingra Aman Dhingra l√† Chuy√™n gia gi·∫£i ph√°p DynamoDB cao c·∫•p (Sr. DynamoDB Specialist Solutions Architect) l√†m vi·ªác t·∫°i Dublin, Ireland. Anh c√≥ ƒëam m√™ v·ªÅ c√°c h·ªá th·ªëng ph√¢n t√°n (distributed systems) v√† n·ªÅn t·∫£ng chuy√™n s√¢u v·ªÅ d·ªØ li·ªáu l·ªõn \u0026amp; ph√¢n t√≠ch (big data \u0026amp; analytics). Aman l√† t√°c gi·∫£ c·ªßa cu·ªën \u0026ldquo;Amazon DynamoDB ‚Äì The Definitive Guide\u0026rdquo; v√† h·ªó tr·ª£ kh√°ch h√†ng trong vi·ªác thi·∫øt k·∫ø, ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác v·∫≠n h√†nh tr√™n Amazon DynamoDB. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.1-cloudtrail-etl/","title":"CloudTrail ETL Code","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIG # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Extract VPC ID from file path vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Read and process file content content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Create flattened JSON record out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Add newline for JSONL format json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Send to Firehose in batches of 500 if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.1-cloudtrail-etl/","title":"CloudTrail ETL Code","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIG # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Extract VPC ID from file path vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Read and process file content content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Create flattened JSON record out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Add newline for JSONL format json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Send to Firehose in batches of 500 if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.5-processing-setup/5.5.1-create-kinesis-data-firehose/","title":"Create Kinesis Data Firehose","tags":[],"description":"","content":"Create Kinesis Data Firehose Delivery Streams Create cloudtrail-firehose-stream Open Kinesis Console ‚Üí Delivery streams ‚Üí Create delivery stream\nConfigure:\nSource: Direct PUT Destination: Amazon S3 Stream name: cloudtrail-firehose-stream S3 bucket: processed-cloudtrail-logs-ACCOUNT_ID-REGION Prefix: processed-cloudtrail/date=!{timestamp:yyyy-MM-dd}/ Error prefix: processed-cloudtrail/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ Buffer size: 10 MB Buffer interval: 300 seconds Compression: GZIP IAM role: CloudTrailFirehoseRole Create delivery stream\nCreate vpc-dns-firehose-stream Stream name: vpc-dns-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: vpc-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: vpc-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Same buffer/compression settings as above) Create vpc-flow-firehose-stream Stream name: vpc-flow-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: eni-flow-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: eni-flow-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Same buffer/compression settings as above) "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.1-create-lambda-excecution-roles/","title":"Create Lambda Execution Roles","tags":[],"description":"","content":"Create CloudTrailETLLambdaServiceRole Open the IAM Console:\nNavigate to https://console.aws.amazon.com/iam/ Or: AWS Management Console ‚Üí Search for \u0026ldquo;IAM\u0026rdquo; ‚Üí Click \u0026ldquo;IAM\u0026rdquo; Navigate to Roles:\nIn the left sidebar, click \u0026ldquo;Roles\u0026rdquo; Click \u0026ldquo;Create role\u0026rdquo;\nSelect trusted entity:\nTrusted entity type: Select \u0026ldquo;AWS service\u0026rdquo; Use case: Select \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Add permissions:\nIn the search box, type AWSLambdaBasicExecutionRole Check the box next to \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Name, review, and create:\nRole name: Enter CloudTrailETLLambdaServiceRole Description: Enter Execution role for CloudTrail ETL Lambda function Click \u0026ldquo;Create role\u0026rdquo; Add inline policy:\nAfter creation, you\u0026rsquo;ll be on the role details page Click on the \u0026ldquo;Permissions\u0026rdquo; tab Click \u0026ldquo;Add permissions\u0026rdquo; ‚Üí \u0026ldquo;Create inline policy\u0026rdquo; Create inline policy:\nClick on the \u0026ldquo;JSON\u0026rdquo; tab Paste the following policy (replace ACCOUNT_ID and REGION): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/cloudtrail-firehose-stream\u0026#34; } ] } Click \u0026ldquo;Next\u0026rdquo;\nPolicy name:\nPolicy name: Enter CloudTrailETLPolicy Click \u0026ldquo;Create policy\u0026rdquo; Verify role creation:\nYou should see the role with both managed and inline policies attached Create Remaining Lambda Roles Follow the same process for each role below (steps 3-11):\nGuardDutyETLLambdaServiceRole\nRole name: GuardDutyETLLambdaServiceRole Description: Execution role for GuardDuty ETL Lambda function Managed policy: AWSLambdaBasicExecutionRole Inline policy name: GuardDutyETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kms:REGION:ACCOUNT_ID:key/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:CreatePartition\u0026#34;, \u0026#34;glue:GetPartition\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:catalog\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:database/security_logs\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:table/security_logs/processed_guardduty\u0026#34; ] } ] } CloudWatchETLLambdaServiceRole\nRole name: CloudWatchETLLambdaServiceRole Description: Execution role for VPC DNS logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-dns-firehose-stream\u0026#34; } ] } CloudWatchENIETLLambdaServiceRole\nRole name: CloudWatchENIETLLambdaServiceRole Description: Execution role for VPC Flow logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchENIETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-flow-firehose-stream\u0026#34; } ] } CloudWatchExportLambdaServiceRole\nRole name: CloudWatchExportLambdaServiceRole Description: Execution role for CloudWatch log export Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchExportPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateExportTask\u0026#34;, \u0026#34;logs:DescribeExportTasks\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34;, \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } ParseFindingsLambdaServiceRole\nRole name: ParseFindingsLambdaServiceRole Description: Execution role for parsing GuardDuty findings Managed policy: AWSLambdaBasicExecutionRole No inline policy needed IsolateEC2LambdaServiceRole\nRole name: IsolateEC2LambdaServiceRole Description: Execution role for isolating compromised EC2 instances Managed policy: AWSLambdaBasicExecutionRole Inline policy name: IsolateEC2Policy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeInstances\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } QuarantineIAMLambdaServiceRole\nRole name: QuarantineIAMLambdaServiceRole Description: Execution role for quarantining compromised IAM users Managed policy: AWSLambdaBasicExecutionRole Inline policy name: QuarantineIAMPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:AttachUserPolicy\u0026#34;, \u0026#34;iam:ListAttachedUserPolicies\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::ACCOUNT_ID:user/*\u0026#34;, \u0026#34;arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy\u0026#34; ] } ] } AlertDispatchLambdaServiceRole\nRole name: AlertDispatchLambdaServiceRole Description: Execution role for dispatching alerts via SNS/SES/Slack Managed policy: AWSLambdaBasicExecutionRole Inline policy name: AlertDispatchPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:REGION:ACCOUNT_ID:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.1-create-iam-role-and-policy-for-lambda/","title":"Lambda IAM Role and Policy setup","tags":[],"description":"","content":"In this guide, you will setup IAM Role and Policy for Lambda.\nCreate IAM Role for Lambda Open the IAM Console\nNavigate to https://console.aws.amazon.com/iam/ Or: AWS Management Console ‚Üí Services ‚Üí IAM Create Role:\nChoose the Role option on the left menu panel. Then click Create role. Select trusted entity:\nTrusted entity type: AWS Service Use case: Lambda Click \u0026ldquo;Next\u0026rdquo; Attach permissions policies:\nIn the search box, type AWSLambdaBasicExecutionRole Check the box next to \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Name, review, and create:\nRole name: Enter dashboard-query-role Description: Enter Execution role for Lambda function Click \u0026ldquo;Create role\u0026rdquo; Add inline policy:\nAfter creation, you\u0026rsquo;ll be on the role details page Click on the \u0026ldquo;Permissions\u0026rdquo; tab Click \u0026ldquo;Add permissions\u0026rdquo; ‚Üí \u0026ldquo;Create inline policy\u0026rdquo; Create inline policy:\nClick on the \u0026ldquo;JSON\u0026rdquo; tab Paste the following policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AthenaActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;athena:StartQueryExecution\u0026#34;, \u0026#34;athena:GetQueryExecution\u0026#34;, \u0026#34;athena:GetQueryResults\u0026#34;, \u0026#34;athena:StopQueryExecution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;GlueCatalogRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:GetDatabase\u0026#34;, \u0026#34;glue:GetDatabases\u0026#34;, \u0026#34;glue:GetTable\u0026#34;, \u0026#34;glue:GetTables\u0026#34;, \u0026#34;glue:GetPartitions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3SourceAndResultAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::vel-athena-results\u0026#34;, \u0026#34;arn:aws:s3:::vel-athena-results/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty/*\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted/*\u0026#34; ] } ] } Click \u0026ldquo;Next\u0026rdquo;\nPolicy name:\nPolicy name: Enter lambda-query-policy Click \u0026ldquo;Create policy\u0026rdquo; Verify role creation:\nYou should see the role with both managed and inline policies attached "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.1-workshop-overview/","title":"Overview","tags":[],"description":"","content":"System Components Auto Incident Response and Forensics is an architecture that uses automation services to ingest, process, and automatically respond to security findings, minimizing the time required for human intervention and aids security personel in visualizing and analyzing logs. This system is built around AWS Security Services (CloudTrail, GuardDuty, VPC Flow Logs, CloudWatch) feeding data into a Centralized Data Lake (S3/Glue/Athena) for analysis. The core automation is driven by AWS EventBridge rules triggering AWS Step Functions workflows, which then execute AWS Lambda functions to perform isolation and alerting actions. Workshop overview In this workshop, you will deploy a multi-phase system to achieve end-to-end security automation. This includes:\nFoundation Setup: Creating dedicated S3 buckets and IAM roles to support all services. Monitoring Setup: Enabling and configuring key security logs (CloudTrail, GuardDuty, VPC Flow Logs) to direct data to the central log ingestion point. Processing Setup: Deploying Kinesis Firehose, Lambda ETLs, and Glue/Athena tables to transform raw logs into an easily queryable security data lake. Automation Setup: Creating the Isolation Security Group, SNS Topic, Incident Response Lambda Functions, and the Step Functions State Machine that executes automatic quarantine actions when GuardDuty detects findings. Dashboard Setup: Hosting a secure, S3-based static web interface accelerated by CloudFront and protected by Cognito to provide analysts with real-time visualization of forensic data and direct query capabilities via API Gateway. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.4-monitoring-setup/5.4.1-prepare/","title":"Prepare the environment","tags":[],"description":"","content":"To prepare for this part of the workshop you will need to:\nDeploying a CloudFormation stack Modifying a VPC route table. These components work together to simulate on-premises DNS forwarding and name resolution.\nDeploy the CloudFormation stack The CloudFormation template will create additional services to support an on-premises simulation:\nOne Route 53 Private Hosted Zone that hosts Alias records for the PrivateLink S3 endpoint One Route 53 Inbound Resolver endpoint that enables \u0026ldquo;VPC Cloud\u0026rdquo; to resolve inbound DNS resolution requests to the Private Hosted Zone One Route 53 Outbound Resolver endpoint that enables \u0026ldquo;VPC On-prem\u0026rdquo; to forward DNS requests for S3 to \u0026ldquo;VPC Cloud\u0026rdquo; Click the following link to open the AWS CloudFormation console. The required template will be pre-loaded into the menu. Accept all default and click Create stack. It may take a few minutes for stack deployment to complete. You can continue with the next step without waiting for the deployemnt to finish.\nUpdate on-premise private route table This workshop uses a strongSwan VPN running on an EC2 instance to simulate connectivty between an on-premises datacenter and the AWS cloud. Most of the required components are provisioned before your start. To finalize the VPN configuration, you will modify the \u0026ldquo;VPC On-prem\u0026rdquo; routing table to direct traffic destined for the cloud to the strongSwan VPN instance.\nOpen the Amazon EC2 console\nSelect the instance named infra-vpngw-test. From the Details tab, copy the Instance ID and paste this into your text editor\nNavigate to the VPC menu by using the Search box at the top of the browser window.\nClick on Route Tables, select the RT Private On-prem route table, select the Routes tab, and click Edit Routes.\nClick Add route. Destination: your Cloud VPC cidr range Target: ID of your infra-vpngw-test instance (you saved in your editor at step 1) Click Save changes "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.2-prerequiste/","title":"Prerequisites","tags":[],"description":"","content":"Required Access and Information Before proceeding with the setup of the Automated AWS Incident Response and Forensics System, ensure you have gathered the required access credentials and information below.\nüîë Access \u0026amp; Identifiers AWS Account with Administrative Access You need full administrative permissions to create resources across multiple AWS services. Access to the AWS Management Console. Your AWS Account ID Format: 12-digit number (e.g., 123456789012). Placeholder: Replace ACCOUNT_ID throughout the guide. Target AWS Region Choose the region where you\u0026rsquo;ll deploy the system (e.g., us-east-1). Placeholder: Replace REGION throughout the guide. VPC ID A VPC with at least one subnet is required for VPC Flow Logs. Placeholder: Replace YOUR_VPC_ID in the guide. Amazon SES Verified Email Address Required for sending and recieving email alerts. Verify this address in the SES Console. Placeholder: Replace YOUR_VERIFIED_EMAIL@example.com. Slack Webhook URL (Optional) If you want Slack notifications, obtain a webhook URL from your Slack workspace. Placeholder: Replace YOUR_SLACK_WEBHOOK_URL. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/5.3.1-set-up-s3-buckets/","title":"Set up S3 buckets","tags":[],"description":"","content":"In this section, you will create 5 S3 buckets that serve as the foundation for the Auto Incident Response system.\nImportant: Replace ACCOUNT_ID with your AWS Account ID and REGION with your target region (e.g., us-east-1) in all bucket names.\nBucket Names incident-response-log-list-bucket-ACCOUNT_ID-REGION - Primary log collection bucket processed-cloudtrail-logs-ACCOUNT_ID-REGION - Stores processed CloudTrail logs athena-query-results-ACCOUNT_ID-REGION - Stores Athena query results processed-cloudwatch-logs-ACCOUNT_ID-REGION - Stores processed CloudWatch logs processed-guardduty-findings-ACCOUNT_ID-REGION - Stores processed GuardDuty findings Bucket Creation Instructions Open the Amazon S3 Console Navigate to https://console.aws.amazon.com/s3/ Or: AWS Management Console ‚Üí Services ‚Üí S3 Click on \u0026ldquo;Create bucket\u0026rdquo; General configuration: Bucket name: Enter incident-response-log-list-bucket-ACCOUNT_ID-REGION Example: incident-response-log-list-bucket-123456789012-us-east-1 AWS Region: Select your target region (e.g., US East (N. Virginia) us-east-1) Object Ownership:\nKeep default: ACLs disabled (recommended) Block Public Access settings for this bucket:\nCheck \u0026ldquo;Block all public access\u0026rdquo; Ensure all 4 sub-options are checked: ‚úì Block public access to buckets and objects granted through new access control lists (ACLs) ‚úì Block public access to buckets and objects granted through any access control lists (ACLs) ‚úì Block public access to buckets and objects granted through new public bucket or access point policies ‚úì Block public and cross-account access to buckets and objects through any public bucket or access point policies Bucket Versioning:\nSelect \u0026ldquo;Enable\u0026rdquo; Tags (optional):\nAdd tags if desired Example: Key=Purpose, Value=IncidentResponse Default encryption:\nEncryption type: Select \u0026ldquo;Server-side encryption with Amazon S3 managed keys (SSE-S3)\u0026rdquo; Bucket Key: Keep default (Enabled) Advanced settings:\nKeep all defaults Click \u0026ldquo;Create bucket\u0026rdquo;\nVerify bucket creation:\nYou should see a success message The bucket should appear in your S3 buckets list Repeat steps 2-10 for the remaining 4 buckets:\nprocessed-cloudtrail-logs-ACCOUNT_ID-REGION athena-query-results-ACCOUNT_ID-REGION processed-cloudwatch-logs-ACCOUNT_ID-REGION processed-guardduty-findings-ACCOUNT_ID-REGION Verify all 5 buckets are created:\nNavigate to S3 Console You should see all 5 buckets listed "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.1-setup-s3/","title":"Setup S3 Bucket for Dashboard","tags":[],"description":"","content":"In this guide, you will setup a S3 to contain web files and folder. Important: Replace ACCOUNT_ID with your AWS Account ID and REGION with your target region (e.g., us-east-1) in all bucket names.\nBucket Names static-dashboard-bucket-ACCOUNT_ID-REGION - Store builded web files and folder\nBucket Creation Instructions Open the Amazon S3 Console\nNavigate to https://console.aws.amazon.com/s3/ Or: AWS Management Console ‚Üí Services ‚Üí S3 Click on \u0026ldquo;Create bucket\u0026rdquo;\nBucket create setting:\nKeep the setting like default: Bucket name: Enter static-dashboard-bucket-ACCOUNT_ID-REGION Example: static-dashboard-bucket-123456789012-us-east-1 Ownership: ACLs disabled Block Public Access: Block all public access Bucket versioning: Disable Tags(Optional): Add if you want Encryption: SSE-S3 Bucket key: Enable Click Create bucket Verify bucket creation:\nYou should see a success message The bucket should appear in your S3 buckets list Upload files and folder:\nGo to Github to get the web content and upload to S3 "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Tri·ªÉn khai ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán v·ªõi Amazon DynamoDB ‚Äì Ph·∫ßn 2Ôªø b·ªüi Aman Dhingra v√† Lee Hannigan | v√†o ng√†y 25 th√°ng 9 nƒÉm 2025 | trong Advanced (300), Amazon DynamoDB, Amazon EventBridge, AWS Lambda, Serverless, Technical How-to\nTrong b√†i ƒëƒÉng tr∆∞·ªõcÔªø (Ph·∫ßn 1Ôªø) c·ªßa lo·∫°t b√†i n√†y, ch√∫ng t√¥i ƒë√£ th·∫£o lu·∫≠n v·ªÅ c√°ch b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ngÔªø Amazon EventBridge Scheduler ƒë·ªÉ qu·∫£n l√Ω lo·∫°i b·ªè d·ªØ li·ªáu ch√≠nh x√°c trongÔªø Amazon DynamoDB. Trong b√†i ƒëƒÉng n√†yÔªø (Ph·∫ßn 2Ôªø), ch√∫ng t√¥i kh√°m ph√° m·ªôt ph∆∞∆°ng ph√°p kh√°c s·ª≠ d·ª•ngÔªø global secondary indexes (GSIs) ƒë·ªÉ x·ª≠ l√Ω c√°c y√™u c·∫ßu Time to Live (TTL) chi ti·∫øtÔªø.\nKhi x·ª≠ l√Ω c√°c ·ª©ng d·ª•ng th√¥ng l∆∞·ª£ng cao, vi·ªác ki·ªÉm so√°t ch√≠nh x√°c v·ªÅ th·ªùi h·∫°n d·ªØ li·ªáu l√† quan tr·ªçng. S·ª± tr–∑–∞–¥–µ—Ä–∂–∫–∞ t·ª± nhi√™n trong t√≠nh nƒÉng TTL g·ªëc c·ªßa DynamoDB c√≥ th·ªÉ kh√¥ng lu√¥n ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa c√°c ·ª©ng d·ª•ng y√™u c·∫ßu lo·∫°i b·ªè d·ªØ li·ªáu ngay l·∫≠p t·ª©c. B·∫±ng c√°ch s·ª≠ d·ª•ng GSIs, ch√∫ng ta c√≥ th·ªÉ t·∫°o ra m·ªôt h·ªá th·ªëng ph·∫£n h·ªìi t·ªët h∆°n ph√π h·ª£p v·ªõi c√°c y√™u c·∫ßu th·ªùi gian th·ª±c c·ªßa ·ª©ng d·ª•ng.\nT·ªïng quan gi·∫£i ph√°pÔªø S·ª≠ d·ª•ng GSI cho tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng n√†y cho ph√©p b·∫°n truy v·∫•n hi·ªáu qu·∫£ d·ªØ li·ªáu ƒë·ªß ƒëi·ªÅu ki·ªán ƒë·ªÉ lo·∫°i b·ªè theo c√°c kho·∫£ng th·ªùi gian ph√π h·ª£p v·ªõi nhu c·∫ßu c·ª• th·ªÉ c·ªßa b·∫°n. Gi·∫£i ph√°p n√†y c√≥ th·ªÉ cung c·∫•p ƒë·ªô chi ti·∫øt g·∫ßn th·ªùi gian th·ª±c, t∆∞∆°ng t·ª± nh∆∞ ph∆∞∆°ng ph√°p EventBridge Scheduler tr∆∞·ªõc ƒë√≥. B·∫±ng c√°ch thi·∫øt l·∫≠p m·ªôt sharded GSI v·ªõi thu·ªôc t√≠nh TTL l√†m sort key, ch√∫ng ta c√≥ th·ªÉ ƒë·ªãnh k·ª≥ truy v·∫•n v√† lo·∫°i b·ªè c√°c m·ª•c h·∫øt h·∫°n v·ªõi ƒë·ªô ch√≠nh x√°c g·∫ßn 1 ph√∫tÔªø.\nS∆° ƒë·ªì sau ƒë√¢y minh h·ªça ki·∫øn tr√∫c gi·∫£i ph√°pÔªø.\nEventBridge Scheduler k√≠ch ho·∫°t m·ªôt Lambda function theo l·ªãch tr√¨nh ƒë√£ ƒë·ªãnhÔªø.\nLambda function truy v·∫•n GSI ƒë·ªÉ l·∫•y c√°c m·ª•c ƒë∆∞·ª£c ƒë√°nh d·∫•u ƒë·ªÉ x√≥aÔªø.\nLambda function x√≥a c√°c m·ª•c ƒë√£ l·∫•y t·ª´ b·∫£ng DynamoDBÔªø.\nNhu c·∫ßu v·ªÅ shardingÔªø ƒê·ªÉ qu·∫£n l√Ω hi·ªáu qu·∫£ th√¥ng l∆∞·ª£ng ghi v√† ƒë·ªçc caoÔªø, sharding GSI l√† c·∫ßn thi·∫øt. Sharding ph√¢n ph·ªëi t·∫£i tr√™n nhi·ªÅu partition, ngƒÉn ch·∫∑n b·∫•t k·ª≥ partition ƒë∆°n l·∫ª n√†o tr·ªü th√†nh n√∫t th·∫Øt c·ªï chai v√† g√¢y ra throttling. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c b·∫±ng c√°ch th√™m h·∫≠u t·ªë ng·∫´u nhi√™n ho·∫∑c ƒë∆∞·ª£c t√≠nh to√°n v√†o c√°c gi√° tr·ªã partition key. B·∫±ng c√°ch ng·∫´u nhi√™n h√≥a partition key, c√°c ghi ƒë∆∞·ª£c ph√¢n b·ªï ƒë·ªÅu h∆°n tr√™n kh√¥ng gian partition key, c·∫£i thi·ªán t√≠nh song song v√† th√¥ng l∆∞·ª£ng t·ªïng th·ªÉ.\nTuy nhi√™n, truy v·∫•n d·ªØ li·ªáu h·∫øt h·∫°n y√™u c·∫ßu th·ª±c hi·ªán truy v·∫•n cho t·ª´ng shard trong ph·∫°m vi. C√°ch ti·∫øp c·∫≠n n√†y ƒë·∫£m b·∫£o r·∫±ng t·∫•t c·∫£ c√°c partition c√≥ th·ªÉ ƒë∆∞·ª£c ki·ªÉm tra ƒë·ªÉ t√¨m c√°c m·ª•c h·∫øt h·∫°n, nh∆∞ng n√≥ ƒë√≤i h·ªèi nhi·ªÅu truy v·∫•n ƒë·ªÉ bao ph·ªß t·∫•t c·∫£ c√°c shard.\nS·ªë l∆∞·ª£ng shard ƒë∆∞·ª£c t√≠nh to√°n d·ª±a tr√™n th√¥ng l∆∞·ª£ng ghi ƒë·ªânh d·ª± ki·∫øn c·ªßa b·∫£ng c∆° s·ªü b·∫±ng c√¥ng th·ª©c sauÔªø:\nnumber of shards = (peak write capacity units (WCU) / 1000) + buffer Bao g·ªìm buffer trong t√≠nh to√°n c·ªßa b·∫°n ƒë∆∞·ª£c khuy·∫øn ngh·ªã ƒë·ªÉ ƒë·∫£m b·∫£o b·∫°n c√≥ ƒë·ªß shard ƒë·ªÉ tr√°nh throttling tr√™n b·∫£ng DynamoDB. Buffer c≈©ng cung c·∫•p ph√¢n ph·ªëi b·ªï sung ƒë·ªÉ x·ª≠ l√Ω c√°c ƒë·ªânh b·∫•t ng·ªù trong th√¥ng l∆∞·ª£ng ghi, duy tr√¨ hi·ªáu su·∫•t v√† ƒë·ªô tin c·∫≠y c·ªßa ·ª©ng d·ª•ng.\nN·∫øu v·ªÅ l√¢u d√†i WCU ƒë·ªânh d·ª± ki·∫øn c·ªßa b·∫°n tƒÉng, b·∫°n c√≥ th·ªÉ tr∆∞·ªõc ti√™n s·ª≠a ƒë·ªïi Lambda function ƒë·ªÉ truy v·∫•n c√°c shard b·ªï sung, v√† sau ƒë√≥ c·∫≠p nh·∫≠t ·ª©ng d·ª•ng ƒë·ªÉ tƒÉng s·ªë l∆∞·ª£ng shard khi ghi d·ªØ li·ªáu v√†o b·∫£ng. Lambda c√≥ th·ªÉ truy v·∫•n c√°c shard kh√¥ng t·ªìn t·∫°i trong GSI m√† kh√¥ng g·∫∑p v·∫•n ƒë·ªÅ.\nL·ª±a ch·ªçn primary key cho GSIÔªø Khi ch·ªçn key cho GSI c·ªßa b·∫°n, partition key GSI_PK s·∫Ω ƒë∆∞·ª£c t·∫°o b·∫±ng m·ªôt shard ng·∫´u nhi√™n, v·ªõi ph·∫°m vi ƒë∆∞·ª£c x√°c ƒë·ªãnh b·ªüi t√≠nh to√°n tr∆∞·ªõc ƒë√≥ ƒë·ªÉ ƒë·∫£m b·∫£o ph√¢n ph·ªëi t·∫£i ƒë·ªÅu. Sort key s·∫Ω l√† thu·ªôc t√≠nh TTL c·ªßa b·∫°n, c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng s·ªë epoch ho·∫∑c ƒë·ªãnh d·∫°ng th·ªùi gian chu·ªói. S·ª± k·∫øt h·ª£p n√†y cho ph√©p truy v·∫•n hi·ªáu qu·∫£ c√°c m·ª•c d·ª±a tr√™n th·ªùi gian h·∫øt h·∫°n, trong khi partition key ƒë∆∞·ª£c chia s·∫ª gi√∫p ph√¢n ph·ªëi c√°c ho·∫°t ƒë·ªông ghi v√† ƒë·ªçc tr√™n nhi·ªÅu partition, t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t t·ªïng th·ªÉ v√† kh·∫£ nƒÉng m·ªü r·ªông c·ªßa b·∫£ng DynamoDB.\nT·ªëi ∆∞u chi ph√≠Ôªø Indexing Duy tr√¨ GSI hi·ªáu qu·∫£ bao g·ªìm vi·ªác s·ª≠ d·ª•ngÔªø KEYS_ONLY projection v√† ƒë·∫£m b·∫£o indexÔªø l√† sparse. B·∫±ng c√°ch s·ª≠ d·ª•ngÔªø KEYS_ONLY, GSI ch·ªâ l∆∞u tr·ªØ c√°c thu·ªôc t√≠nh primary key v√† c√°c thu·ªôc t√≠nh index key, gi·∫£m ƒë√°ng k·ªÉ chi ph√≠ l∆∞u tr·ªØ v√† th√¥ng l∆∞·ª£ng. Ngo√†i ra, l√†m cho GSI sparse c√≥ nghƒ©a n√≥ ch·ªâ bao g·ªìm c√°c m·ª•c c√≥ thu·ªôc t√≠nh TTL. Vi·ªác l·∫≠p ch·ªâ m·ª•c c√≥ ch·ªçn l·ªçc n√†y ƒë·∫£m b·∫£o r·∫±ng ch·ªâ c√°c m·ª•c li√™n quan, nh·ªØng m·ª•c c√≥ th·ªùi gian h·∫øt h·∫°n, ƒë∆∞·ª£c bao g·ªìm trong GSI, t·ªëi ∆∞u h√≥a th√™m hi·ªáu su·∫•t v√† s·ª≠ d·ª•ng t√†i nguy√™n. ƒêi·ªÅu n√†y kh√¥ng ch·ªâ n√¢ng cao hi·ªáu qu·∫£ truy v·∫•n m√† c√≤n gi√∫p qu·∫£n l√Ω chi ph√≠ b·∫±ng c√°ch gi·ªØ cho index g·ªçn v√† t·∫≠p trung v√†o c√°c m·ª•c y√™u c·∫ßu qu·∫£n l√Ω TTL.\nM√¥ h√¨nh d·ªØ li·ªáu m·∫´uÔªø M√¥ h√¨nh d·ªØ li·ªáu v√≠ d·ª• sau ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω qu·∫£n l√Ω tr·∫°ng th√°i session trong m√¥i tr∆∞·ªùng th√¥ng l∆∞·ª£ng cao, n∆°i c√°c session y√™u c·∫ßu qu·∫£n l√Ω TTL chi ti·∫øt. B·∫±ng c√°ch chia s·∫ª GSI, ch√∫ng t√¥i ph√¢n ph·ªëi t·∫£i ghi tr√™n b·ªën shard ƒë·ªÉ x·ª≠ l√Ω hi·ªáu qu·∫£ th√¥ng l∆∞·ª£ng ƒë·ªânh 3.000 WCU, v·ªõi s·ªë l∆∞·ª£ng shard ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ bao g·ªìm dung l∆∞·ª£ng buffer b·ªï sung v∆∞·ª£t qu√° ƒë·ªânh d·ª± ki·∫øn. M·ªói m·ª•c session bao g·ªìm thu·ªôc t√≠nh TTL ƒë·ªÉ ƒë·∫£m b·∫£o h·∫øt h·∫°n k·ªãp th·ªùi, v√† partition key c·ªßa GSI (GSI_PK) l√† ƒë·ªãnh danh shard ng·∫´u nhi√™n ƒë·ªÉ cho ph√©p truy v·∫•n v√† x√≥a ch√≠nh x√°c c√°c session h·∫øt h·∫°n, duy tr√¨ hi·ªáu su·∫•t t·ªëi ∆∞u v√† t√≠nh to√†n v·∫πn d·ªØ li·ªáuÔªø.\nV√≠ d·ª• sau cho th·∫•yÔªø SessionTable m√† ch√∫ng t√¥i ƒë√£ t·∫°o b·∫±ngÔªø NoSQL Workbench:\nV√≠ d·ª• sau cho th·∫•y TTL GSI c·ªßa ch√∫ng t√¥iÔªø.\nV·ªõi m√¥ h√¨nh d·ªØ li·ªáu n√†y, b√¢y gi·ªù ch√∫ng ta c√≥ th·ªÉ truy v·∫•n t·ª´ng shard b·∫±ng GSI, √°p d·ª•ng ƒëi·ªÅu ki·ªán tr√™n thu·ªôc t√≠nh timestamp TTL ƒë·ªÉ x√°c ƒë·ªãnh c√°c b·∫£n ghi c≈© h∆°n th·ªùi gian hi·ªán t·∫°i. ƒêi·ªÅu n√†y cho ph√©p ch√∫ng ta t√¨m v√† lo·∫°i b·ªè hi·ªáu qu·∫£ c√°c session h·∫øt h·∫°n.\nƒêi·ªÅu ki·ªán ti√™n quy·∫øtÔªø Tr∆∞·ªõc khi ƒëi s√¢u v√†o tri·ªÉn khai gi·∫£i ph√°p TTL t√πy ch·ªânh, b·∫°n n√™n c√≥ c√°c ƒëi·ªÅu ki·ªán ti√™n quy·∫øt sauÔªø:\nAWS account ‚Äì Truy c·∫≠p v√†o m·ªôtÔªø AWS account ho·∫°t ƒë·ªôngÔªø\nDynamoDB basics ‚Äì Hi·ªÉu bi·∫øt c∆° b·∫£n v·ªÅÔªø DynamoDB concepts, bao g·ªìm b·∫£ng, m·ª•c, thu·ªôc t√≠nh v√† c√°c ho·∫°t ƒë·ªông CRUD c∆° b·∫£n, l√† c·∫ßn thi·∫øt ƒë·ªÉ c·∫•u h√¨nh v√† qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu hi·ªáu qu·∫£Ôªø\nSharding ‚Äì Hi·ªÉu bi·∫øt c∆° b·∫£n v·ªÅÔªø sharding techniques cho DynamoDBÔªø\nLambda functions ‚Äì B·∫°n n√™n quen thu·ªôc v·ªõiÔªø AWS Lambda, v√¨ b·∫°n s·∫Ω t·∫°o v√† tri·ªÉn khai c√°c Lambda function ƒë·ªÉ truy v·∫•n DynamoDB v√† ch·∫°y logic TTL t√πy ch·ªânhÔªø\nEventBridge basics ‚Äì Ki·∫øn th·ª©c c∆° b·∫£n v·ªÅÔªø Amazon EventBridge l√† c·∫ßn thi·∫øt ƒë·ªÉ thi·∫øt l·∫≠pÔªø EventBridge Scheduler rules ƒë·ªÉ g·ªçi Lambda function theo c√°c kho·∫£ng th·ªùi gian c·ª• th·ªÉÔªø\nAWS CLI ho·∫∑c th√†nh th·∫°o consoleÔªø ‚Äì ƒê·ªÉ c·∫•u h√¨nh d·ªãch v·ª• v√† gi√°m s√°t log. Ch√∫ng t√¥i s·ª≠ d·ª•ngÔªø AWS Management Console trong su·ªët b√†i ƒëƒÉng n√†yÔªø.\nT·∫°o b·∫£ng DynamoDB v·ªõi GSIÔªø B∆∞·ªõc ƒë·∫ßu ti√™n c·ªßa ch√∫ng t√¥i l√† t·∫°o b·∫£ng DynamoDB v·ªõiÔªø Amazon DynamoDB Streams ƒë∆∞·ª£c b·∫≠t. Ho√†n th√†nh c√°c b∆∞·ªõc sauÔªø:\nTr√™n console DynamoDB, ch·ªçnÔªø Tables trong navigation paneÔªø.\nCh·ªçnÔªø Create table.\nV·ªõi Table name, nh·∫≠p t√™n cho b·∫£ng m·ªõi c·ªßa b·∫°nÔªø.\nV·ªõi Partition key, nh·∫≠p PK l√†m t√™n v√† ch·ªçnÔªø String l√†m ki·ªÉuÔªø.\nV·ªõi Sort key, nh·∫≠p SK l√†m t√™n v√† ch·ªçnÔªø String l√†m ki·ªÉuÔªø.\nV·ªõi Table settings, ch·ªçnÔªø Customize settings. T√πy ch·ªçnÔªø Customize settings c≈©ng cho ph√©p b·∫°n ƒë·ªãnh nghƒ©a secondary index tr√™n b·∫£ng, b·∫≠t/t·∫Øt deletion protection, chuy·ªÉn ƒë·ªïi ki·ªÉu m√£ h√≥a v√† th√™m resource tag khi t·∫°o b·∫£ng.\nV·ªõi Read/write capacity settings, ƒë·∫£m b·∫£oÔªø On-demand ƒë∆∞·ª£c ch·ªçnÔªø.\nCu·ªôn xu·ªëng ph·∫ßnÔªø Secondary indexes.\nCh·ªçnÔªø Create global index.\nV·ªõi Partition key, nh·∫≠p GSI_PK l√†m t√™n v√† ch·ªçnÔªø String l√†m ki·ªÉuÔªø.\nChoÔªø Sort key, nh·∫≠p TTL l√†m t√™n v√† ch·ªçnÔªø String l√†m ki·ªÉuÔªø.\nV·ªõiÔªø Index name, nh·∫≠p t√™n cho index m·ªõi c·ªßa b·∫°nÔªø.\nV·ªõi Attribute projections, ch·ªçnÔªø Only keys.\nCh·ªçnÔªø Create index.\nƒê·ªÉ t·∫•t c·∫£ c·∫•u h√¨nh kh√°c m·∫∑c ƒë·ªãnh v√† ch·ªçnÔªø Create table. T·∫°o LambdaÔªø function Ti·∫øp theo, ch√∫ng t√¥i c·∫•u h√¨nh Lambda function s·∫Ω ƒë∆∞·ª£c g·ªçi b·ªüi EventBridge Scheduler. Lambda function n√†y ch·ªãu tr√°ch nhi·ªám l·∫•y c√°c m·ª•c ƒë·ªß ƒëi·ªÅu ki·ªán ƒë·ªÉ x√≥a v√† x√≥a nh·ªØng m·ª•c ƒë√≥. Ho√†n th√†nh c√°c b∆∞·ªõc sau:\nTr√™n console Lambda, ch·ªçnÔªø Functions trong navigation paneÔªø.\nCh·ªçnÔªø Create function.\nCh·ªçnÔªø Author from scratch.\nV·ªõi Function name, nh·∫≠p t√™n (v√≠ d·ª•, StrictDataManagement)Ôªø.\nV·ªõi Runtime, ch·ªçnÔªø Python 3.12.\nTh√™m policy cho ph√©p h√†m ƒë·ªçc t·ª´ GSI v√† ghi v√†o b·∫£ngÔªø:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ReadFromGSI\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/\u0026lt;table-name\u0026gt;\u0026#34;, \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/\u0026lt;table-name\u0026gt;/index/\u0026lt;gsi-name\u0026gt;\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;WriteToTable\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/\u0026lt;table-name\u0026gt;\u0026#34; } ] } Ch·ªçnÔªø Create function. Tr√™n tabÔªø Code c·ªßa Lambda function, thay th·∫ø m√£ Lambda function b·∫±ng m√£ sau. Thay ƒë·ªïi c√°c h·∫±ng s·ªëÔªø, SHARDS, TABLE_NAME, v√†Ôªø INDEX_NAME ƒë·ªÉ ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ª• th·ªÉ c·ªßa b·∫°nÔªø: import boto3 from datetime import datetime # Constants SHARDS = 4 TABLE_NAME = \u0026#39;TTL-Table\u0026#39; INDEX_NAME = \u0026#39;TTL-index\u0026#39; dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(TABLE_NAME) def lambda_handler(event, context): current_time = datetime.now().replace(second=0, microsecond=0).isoformat() for shard in range(SHARDS): shard_key = str(shard) query_and_delete_expired_items(shard_key, current_time) def query_and_delete_expired_items(shard_key, current_time): last_evaluated_key = None while True: # Print for logging purposes print(f\u0026#34;Checking shard {shard_key} at {current_time}\u0026#34;) query_kwargs = { \u0026#39;IndexName\u0026#39;: INDEX_NAME, \u0026#39;KeyConditionExpression\u0026#39;: \u0026#39;GSI_PK = :shard AND #ttl \u0026lt; :current_time\u0026#39;, \u0026#39;ExpressionAttributeValues\u0026#39;: { \u0026#39;:shard\u0026#39;: shard_key, \u0026#39;:current_time\u0026#39;: current_time }, \u0026#39;ExpressionAttributeNames\u0026#39;: { \u0026#39;#ttl\u0026#39;: \u0026#39;TTL\u0026#39; } } if last_evaluated_key: query_kwargs[\u0026#39;ExclusiveStartKey\u0026#39;] = last_evaluated_key response = table.query(**query_kwargs) items_to_delete = response.get(\u0026#39;Items\u0026#39;, []) if items_to_delete: delete_expired_items(items_to_delete) last_evaluated_key = response.get(\u0026#39;LastEvaluatedKey\u0026#39;) if not last_evaluated_key: break def delete_expired_items(items): with table.batch_writer() as batch: for item in items: batch.delete_item( Key={ \u0026#39;PK\u0026#39;: item[\u0026#39;PK\u0026#39;], \u0026#39;SK\u0026#39;: item[\u0026#39;SK\u0026#39;] } ) Ch·ªçnÔªø Deploy ƒë·ªÉ tri·ªÉn khai m√£ h√†m m·ªõi nh·∫•tÔªø. H√†mÔªø delete_expired_items s·ª≠ d·ª•ngÔªø Boto3 batch_writer ƒë·ªÉ th·ª±c hi·ªán x√≥a h√†ng lo·∫°t cho hi·ªáu qu·∫£. Tuy nhi√™nÔªø, batch_writer kh√¥ng h·ªó tr·ª£Ôªø ConditionExpression, c√≥ nghƒ©a l√† kh√¥ng c√≥ c√°ch n√†o ƒë·ªÉ ki·ªÉm tra xem m·ªôt m·ª•c v·∫´n ƒë·ªß ƒëi·ªÅu ki·ªán ƒë·ªÉ x√≥a t·∫°i th·ªùi ƒëi·ªÉm ghi. ƒêi·ªÅu n√†y c√≥ th·ªÉ r·ªßi ro trong c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng m√† gi√° tr·ªã TTL c√≥ th·ªÉ ƒë√£ thay ƒë·ªïi gi·ªØa l·∫ßn ƒë·ªçc ban ƒë·∫ßu v√† n·ªó l·ª±c x√≥a. ƒê·ªÉ tr√°nh v√¥ t√¨nh x√≥a c√°c m·ª•c kh√¥ng c√≤n h·∫øt h·∫°n, ƒë∆∞·ª£c khuy·∫øn ngh·ªã s·ª≠ d·ª•ng ho·∫°t ƒë·ªông DeleteItem v·ªõiÔªø ConditionExpression x√°c minh gi√° tr·ªã TTL v·∫´n trong ph·∫°m vi mong ƒë·ª£iÔªø.\nT·∫°o EventBridge SchedulerÔªø B√¢y gi·ªù ch√∫ng t√¥i t·∫°o l·ªãch tr√¨nh EventBridge g·ªçi Lambda function m·ªói 5 ph√∫t. B·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh kho·∫£ng th·ªùi gian n√†y ƒë·ªÉ ph√π h·ª£p v·ªõi y√™u c·∫ßu lo·∫°i b·ªè d·ªØ li·ªáu c·ªßa b·∫°n.\nTr√™n console EventBridge, ch·ªçnÔªø Schedules trong navigation paneÔªø.\nCh·ªçnÔªø Create schedule.\nChoÔªø Schedule name, nh·∫≠p t√™n cho l·ªãch tr√¨nh m·ªõi c·ªßa b·∫°nÔªø.\nChoÔªø Schedule pattern, ch·ªçnÔªø Recurring schedule.\nChoÔªø Schedule type, ch·ªçnÔªø Rate-based schedule.\nChoÔªø Rate expression, ƒë·∫∑tÔªø Value th√†nhÔªø 5 v√†Ôªø Unit th√†nhÔªø minutes.\nChoÔªø Flexible time window, ch·ªçnÔªø Off.\nƒê·ªÉ t·∫•t c·∫£ c·∫•u h√¨nh kh√°c m·∫∑c ƒë·ªãnh v√† ch·ªçnÔªø Next.\nChoÔªø Templated targets, ch·ªçnÔªø AWS Lambda Invoke.\nChoÔªø Lambda function, ch·ªçn Lambda function StrictDataManagement c·ªßa b·∫°nÔªø.\nƒê·ªÉ t·∫•t c·∫£ c·∫•u h√¨nh kh√°c m·∫∑c ƒë·ªãnh v√† ch·ªçnÔªø Next.\nChoÔªø Action after schedule completion, ch·ªçnÔªø NONE.\nƒê·ªÉ t·∫•t c·∫£ c·∫•u h√¨nh kh√°c m·∫∑c ƒë·ªãnh v√† ch·ªçnÔªø Next.\nXem l·∫°i c·∫•u h√¨nh c·ªßa b·∫°n v√† ch·ªçnÔªø Create schedule. T·∫°o m·ª•c m·∫´u ƒë·ªÉ xem gi·∫£i ph√°p ho·∫°t ƒë·ªôngÔªø B·∫°n c√≥ th·ªÉ ki·ªÉm tra gi·∫£i ph√°p b·∫±ng c√°ch th√™m m·ª•c v√†o b·∫£ng DynamoDB v·ªõi gi√° tr·ªã TTL. ƒê√¢y l√† v√≠ d·ª• t·∫°o 10 m·ª•c m·∫´u v·ªõi gi√° tr·ªã TTL b·∫±ng AWS CLIÔªø:\n#!/bin/bash TABLE=\u0026#34;TTL-Table\u0026#34; for PK_VALUE in {1..10}; do # Get current UTC time in ISO 8601 format ISO_TIMESTAMP=$(date -u +\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) # Generate a random shard value between 0 and 3 GSI_PK_VALUE=$((RANDOM % 4)) # Put item into DynamoDB aws dynamodb put-item --table-name $TABLE \\ --item \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;StaticSK\u0026#34;}, \u0026#34;GSI_PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$GSI_PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;TTL\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$ISO_TIMESTAMP\u0026#39;\u0026#34;}, \u0026#34;SessionData\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;{\\\u0026#34;cart\\\u0026#34;: \\\u0026#34;item\u0026#39;$PK_VALUE\u0026#39;\\\u0026#34;}\u0026#34;}}\u0026#39; done ƒê·ªÉ theo d√µi c√°c ho·∫°t ƒë·ªông x√≥a tr√™n b·∫£ng DynamoDB c·ªßa b·∫°n, ƒëi·ªÅu h∆∞·ªõng ƒë·∫øn tabÔªø Monitoring tr√™n console DynamoDB. Trong thi·∫øt l·∫≠p n√†y, l·ªãch tr√¨nh EventBridge g·ªçi Lambda function m·ªói 5 ph√∫t ƒë·ªÉ l·∫•y v√† x√≥a m·ª•c b·∫±ng l·ªánhÔªø BatchWriteItem. B·∫°n c√≥ th·ªÉ theo d√µi c√°c ho·∫°t ƒë·ªông x√≥a b·∫±ng c√°ch xem metricÔªø SuccessfulRequestLatency cho ho·∫°t ƒë·ªôngÔªø BatchWriteItem, s·ª≠ d·ª•ng th·ªëng k√™Ôªø Sample Count ƒë·ªÉ xem s·ªë l·∫ßn g·ªçi x√≥a. ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt v·ªÅ metrics DynamoDB, tham kh·∫£oÔªø DynamoDB Metrics and dimensions.\nBi·ªÉu ƒë·ªì sau cho th·∫•yÔªø BatchWriteItem ƒë∆∞·ª£c g·ªçi b·ªën l·∫ßn, m·ªôt l·∫ßn g·ªçi cho m·ªói shard ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a cho tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng c·ªßa ch√∫ng t√¥iÔªø.\nC√¢n nh·∫Øc chi ph√≠Ôªø Chi ph√≠ s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p n√†y cho 1.000.000 m·ª•c TTL ƒë∆∞·ª£c ∆∞·ªõc t√≠nh trong b·∫£ng sau v·ªõi so s√°nh s·ª≠ d·ª•ng ch·ª©c nƒÉng DynamoDB g·ªëc. M·ªói m·ª•c DynamoDB nh·ªè h∆°n 1KB v√† ƒë∆∞·ª£c l∆∞u tr·ªØ trong b·∫£ng s·ª≠ d·ª•ng ch·∫ø ƒë·ªô on-demand ·ªü Region us-east-1. Free tier kh√¥ng ƒë∆∞·ª£c xem x√©t cho ph√¢n t√≠ch n√†y.\nTTL g·∫ßn th·ªùi gian th·ª±c TTL DynamoDB b·∫£n ƒë·ªãa DynamoDB global secondary index Vi·∫øt: $0.63 ƒê·ªçc: $0.11 - Lambda EventBridge Scheduler $1 - DynamoDB Delete $1.26 - T·ªïng Chi ph√≠ $2.43 $0 D·ªçn d·∫πpÔªø N·∫øu b·∫°n t·∫°o m√¥i tr∆∞·ªùng ki·ªÉm tra ƒë·ªÉ theo d√µi b√†i ƒëƒÉng n√†y, h√£y ƒë·∫£m b·∫£oÔªø:\nX√≥a DynamoDB tableÔªø\nX√≥a Lambda functionÔªø\nX√≥a EventBridge scheduleÔªø\nX√≥a b·∫•t k·ª≥ IAM role n√†o c√≤n l·∫°i ƒë∆∞·ª£c t·∫°o trong qu√° tr√¨nh n√†yÔªø\nX√≥a b·∫•t k·ª≥ t√†i nguy√™n n√†o kh√°c b·∫°n t·∫°o ƒë·ªÉ ki·ªÉm tra gi·∫£i ph√°pÔªø.\nT√≥m t·∫ØtÔªø Trong b√†i ƒëƒÉng n√†y, ch√∫ng t√¥i ƒë√£ th·∫£o lu·∫≠n v·ªÅ c√°ch DynamoDB GSI k·∫øt h·ª£p v·ªõi EventBridge v√† Lambda cung c·∫•p gi·∫£i ph√°p m·∫°nh m·∫Ω ƒë·ªÉ qu·∫£n l√Ω h·∫øt h·∫°n d·ªØ li·ªáu trong th·ªùi gian th·ª±c, cung c·∫•p hi·ªáu su·∫•t ·ª©ng d·ª•ng t·ªëi ∆∞u v√† x·ª≠ l√Ω d·ªØ li·ªáu hi·ªáu qu·∫£.\nTrongÔªø Ph·∫ßn 3Ôªø, ch√∫ng t√¥i kh√°m ph√° c√°ch EventBridge Scheduler c√≥ th·ªÉ cho ph√©p l·∫≠p l·ªãch chi ti·∫øt c√°c s·ª± ki·ªán downstream. Ph∆∞∆°ng ph√°p n√†y cung c·∫•p qu·∫£n l√Ω d·ªØ li·ªáu t∆∞∆°ng lai ch√≠nh x√°c cho ·ª©ng d·ª•ng c·ªßa b·∫°n, n√¢ng cao ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán c·ªßa b·∫°n.\nV·ªÅ c√°c t√°c gi·∫£Ôªø Lee Hannigan Lee Hannigan l√† Chuy√™n gia gi·∫£i ph√°p DynamoDB cao c·∫•p (Sr. DynamoDB Specialist Solutions Architect) l√†m vi·ªác t·∫°i Donegal, Ireland. Anh c√≥ chuy√™n m√¥n s√¢u r·ªông v·ªÅ c√°c h·ªá th·ªëng ph√¢n t√°n (distributed systems), c√πng n·ªÅn t·∫£ng v·ªØng ch·∫Øc v·ªÅ c√°c c√¥ng ngh·ªá d·ªØ li·ªáu l·ªõn (big data) v√† ph√¢n t√≠ch (analytics technologies). Trong vai tr√≤ Chuy√™n gia gi·∫£i ph√°p DynamoDB, Lee xu·∫•t s·∫Øc trong vi·ªác h·ªó tr·ª£ kh√°ch h√†ng thi·∫øt k·∫ø, ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác (workloads) s·ª≠ d·ª•ng c√°c kh·∫£ nƒÉng c·ªßa DynamoDB. Aman Dhingra Aman Dhingra l√† Chuy√™n gia gi·∫£i ph√°p DynamoDB cao c·∫•p (Sr. DynamoDB Specialist Solutions Architect) l√†m vi·ªác t·∫°i Dublin, Ireland. Anh c√≥ ƒëam m√™ v·ªÅ c√°c h·ªá th·ªëng ph√¢n t√°n (distributed systems) v√† n·ªÅn t·∫£ng chuy√™n s√¢u v·ªÅ d·ªØ li·ªáu l·ªõn \u0026amp; ph√¢n t√≠ch (big data \u0026amp; analytics). Aman l√† t√°c gi·∫£ c·ªßa cu·ªën \u0026ldquo;Amazon DynamoDB ‚Äì The Definitive Guide\u0026rdquo; v√† h·ªó tr·ª£ kh√°ch h√†ng trong vi·ªác thi·∫øt k·∫ø, ƒë√°nh gi√° v√† t·ªëi ∆∞u h√≥a kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác v·∫≠n h√†nh tr√™n Amazon DynamoDB. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/2-proposal/","title":"Proposal","tags":[],"description":"","content":"\nAutomated AWS Incident Response and Forensics System Proposal Link: Proposal\n1. Executive Summary Our team is building an automated incident response and forensics solution as part of the AWS First Cloud Journey internship program. The idea is straightforward‚Äîwhen a security issue happens in AWS, we want the system to respond automatically without waiting for manual intervention.\nWe\u0026rsquo;re creating a platform that automatically detects security findings from GuardDuty, isolates affected resources, captures forensic evidence through comprehensive data collection, and provides analytics and dashboards where security teams can investigate what happened. Everything is built using Infrastructure-as-Code with AWS CDK, so customers can easily deploy it into their own AWS accounts.\n2. Problem Statement What‚Äôs the Problem? The increasing frequency and sophistication of cyber threats pose significant risks to organizations relying on cloud infrastructure. Manual incident response processes are often slow, inconsistent, and prone to human error, which can lead to prolonged system downtime, data breaches, and financial losses. The project aims to address these challenges by developing an automated, reliable, and scalable incident response system that minimizes response time, enhances forensic capabilities, and reduces operational costs.\nThe Solution The main use cases include detecting unauthorized AWS credential use, identifying compromised EC2 instances, and ensuring forensic data is properly collected, processed, and stored for investigation. Our architecture integrates VPC Flow Logs, CloudTrail, CloudWatch, and GuardDuty to detect threats, while Step Functions orchestrates the automated response workflow including EC2 isolation, ASG detachment, Create Snapshot and IAM quarantine. All evidence is collected and processed through custom ETL Lambda and Data Firehose, using Athena for forensic analysis. The system also includes alert dispatching, notification via messaging and email, and provides dashboards and analytics for security teams to investigate what happened.\nBenefits and Return on Investment Rapid threat detection: Automated response reduces the window of vulnerability. Comprehensive evidence gathering: Automated forensic data collection facilitates faster investigations. Cost-effective deployment: Leveraging AWS serverless services minimizes infrastructure expenses. Improved security posture: Continuous monitoring and real-time alerts. Actionable insights: Dashboards and analytics empower security teams. Scalability: Adaptable to organizations of various sizes and incident volumes. 3. Solution Architecture Our solution uses a comprehensive multi-stage architecture for automated incident response and forensics:\nAWS Services Used Amazon GuardDuty: Continuously monitors for security threats and suspicious activity. AWS Step Functions: Orchestrates the incident response workflow. AWS Lambda: Runs automation code for isolation and data processing. Amazon EventBridge: Routes findings from GuardDuty to Step Functions. Amazon S3: Stores forensic evidence and hosts static dashboard. Amazon Athena: Enables SQL queries against forensic datasets. Amazon API Gateway: Facilitates communication between dashboard and backend. Amazon Cognito: Secures access for dashboard users. Amazon CloudFront: Accelerates dashboard delivery across the globe. Amazon SNS \u0026amp; SES: Handles notifications via messaging and email. AWS CloudTrail: Logs all actions for auditing. Amazon CloudWatch: Monitoring and dashboards. Amazon EC2: Optional instances for analysis. AWS KMS: Key management for encryption. Amazon Kinesis Data Firehose: Streams data to S3. Component Design Data Collection \u0026amp; Detection Layer: Collects events from VPC Flow Logs, CloudTrail, CloudWatch, EC2, and GuardDuty. Event Processing Layer: Alert Dispatch, EventBridge routes findings to Step Functions; events are classified by type. Automated Response Orchestration: Step Functions handle parsing, decision making, EC2 isolation, termination protection, ASG detachment, snapshot creation, and IAM quarantine. Alerting \u0026amp; Notification Layer: SNS, Slack \u0026amp; SES handles notifications via messaging and email, Alert Dispatch. Data Processing \u0026amp; Analytics Layer: ETL pipeline with Lambda and Data Firehose processes raw logs into S3; Athena queries the data. Dashboard \u0026amp; Analysis Layer: S3-hosted React dashboard with Cognito auth, consuming data via API Gateway and Athena. 4. Technical Implementation Implementation Phases We use Agile Scrum with 1-week sprints over 6 weeks:\nSprint 1: Foundation \u0026amp; Setup (VPC, Security Groups, Training). Sprint 2: Core Orchestration (Step Functions, Lambda, GuardDuty integration). Sprint 3: Data \u0026amp; Analytics (S3, Athena, ETL pipeline). Sprint 4: Dashboard \u0026amp; UI (Static site, API Gateway, CloudFront). Sprint 5: Testing \u0026amp; Optimization (Cognito, Performance testing, Simulations). Sprint 6: Documentation \u0026amp; Handover (Guides, Demos, Final Polish). Technical Requirements Frontend \u0026amp; Dashboards: Custom HTML/CSS/JS hosted on S3, served via CloudFront. Backend \u0026amp; Processing: Python 3.12 for Lambda, Step Functions for orchestration. Data \u0026amp; Storage: S3 for evidence, Athena for querying, Firehose for streaming. Infrastructure: All defined in AWS CDK (Python). Security: GuardDuty for detection, IAM for least privilege, KMS for encryption. 5. Timeline \u0026amp; Milestones Project Timeline Project Timeline\nWeek 6-7 (Foundation \u0026amp; Setup) Activities: Team training on GuardDuty/Step Functions, architecture design review, VPC and security setup. Deliverables: Architecture document v1, team training completion, GitHub repository established. Week 7-9 (Core Orchestration) Activities: Step Functions workflow development, Lambda function coding for all response actions, EventBridge integration, SNS/SES setup, integration testing. Deliverables: Step Functions state machine definition, 7+ Lambda functions with documentation, GuardDuty integration, notification system, API Gateway. Week 10 (Data \u0026amp; Analytics) Activities: S3 forensic storage setup, Athena table creation, ETL pipeline development, SQL query library. Deliverables: 15+ Athena queries documented, forensic analysis runbooks, processed data storage. Week 11 (Dashboard \u0026amp; UI) Activities: Static dashboard development, Cognito authentication, API Gateway setup, CloudFront CDN configuration, dashboard integration. Deliverables: S3-hosted dashboard, authentication system, query interface, real-time results integration. Week 12 (Testing \u0026amp; Validation \u0026amp; Optimization) Activities: Manual testing, security scanning including simulated incident scenarios (5+ workflows), performance testing, attack simulation. Optimize data with Athena query and Data Firehose. Deliverables: Security scan results, incident simulation videos, data optimization. Week 13 (Documentation \u0026amp; Handover) Activities: Deployment guide, API documentation, knowledge transfer sessions, final demo, GitHub cleanup. Deliverables: Complete GitHub repository (public), deployment guide instructions, live workshop demonstration. 6. Budget Estimation You can find the detailed budget estimation on the AWS Pricing Calculator.\nInfrastructure Costs Typical monthly deployment cost (Free Tier / Low scale): ~$5.01\nGuardDuty: ~$1.80/month S3: ~$1.07/month KMS: ~$1.12/month CloudTrail: ~$0.55/month Athena: ~$0.29/month Amazon Simple Email Service (SES): ~$0.09/month Amazon API Gateway: ~$0.05/month Amazon Data firehose: ~$0.04/month Lambda, Step Functions, SNS: Generally within Free Tier limits for typical usage. Note: Costs assume typical usage of 20-150 incidents per month.\n7. Risk Assessment Risk Matrix Performance Bottlenecks: High data volume slowing down queries. Security Breaches: Compromise of the forensic data itself. Cost Overruns: Unchecked logging or infinite loops. Mitigation Strategies Performance: Monitor Athena/Firehose; optimize queries; dynamic resource adjustment. Security: Encryption (KMS), strict IAM roles, audit logging, compliance checks. Cost: AWS budget alerts, cost anomaly detection, auto-scaling limits. Disaster Recovery: Backups, failover procedures, and redundancy measures. 8. Expected Outcomes Technical Improvements Automated Response: Zero-touch isolation of compromised resources. Speed: Reduction of investigation time from hours to minutes. Reliability: Consistent, repeatable evidence collection without human error. Long-term Value Scalable Architecture: Foundation for future security automation. Knowledge: Team competency in advanced AWS security and serverless concepts. Reusable Asset: A deployable solution for other AWS customers or teams. Status: Ready for Review \u0026amp; Approval Project Code: AWS-FCJ-IR-FORENSICS-2025\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Summary Report: ‚ÄúAWS Cloud Mastery Series #1 ‚Äì AI/ML/GenAI on AWS‚Äù Event Objectives Provide an overview of key AI/ML/GenAI capabilities available on AWS. Highlight practical building blocks such as Amazon Bedrock, pretrained AI services, and AgentCore for real-world solutions. Speakers Lam Tuan Kiet ‚Äì Sr DevOps Engineer, FPT Software Danh Hoang Hieu Nghi ‚Äì AI Engineer, Renova Cloud Dinh Le Hoang Anh ‚Äì Cloud Engineer Trainee, First Cloud AI Journey Van Hoang Kha ‚Äì Cloud Security Engineer, AWS Community Builder Key Highlights Generative AI with Amazon Bedrock - Foundation Models:\nBedrock exposes multiple foundation models (FMs) through a managed API, allowing teams to plug in models from different providers and adapt them to tasks like chat, search, and summarization without managing underlying infrastructure.\n- Prompt Engineering:\nCovered practical prompting patterns for controlling model behavior:\nZero-shot prompting: Ask the model to solve a task directly with only the instruction. Few-shot prompting: Add a few examples to guide the model toward the desired format and style. Chain-of-thought: Ask the model to reason step by step so it can expose intermediate logic before giving a final answer. - Retrieval-Augmented Generation (RAG):\nRAG pipelines combine search and generation so the model answers questions using your own data, not just its pretraining.\nR ‚Äì Retrieval: Fetch relevant chunks from a knowledge base or vector store. A ‚Äì Augmented: Attach retrieved content to the prompt as extra context. G ‚Äì Generation: Let the model generate an answer grounded in that context. Common use cases: domain-aware chatbots, question answering over internal docs, semantic search, and near real-time content summarization. - Amazon Titan Embeddings:\nTitan Embeddings converts text into numeric vectors that capture semantic meaning, enabling more accurate similarity search, RAG, recommendations, and clustering across 100+ languages.\n- Pretrained AI Services on AWS:\nThe session briefly walked through managed AI APIs that hide ML complexity behind simple calls:\nAmazon Rekognition ‚Äì Image and video analysis (labeling, faces, moderation, etc.). Amazon Translate ‚Äì Automatic language detection and translation. Amazon Textract ‚Äì Extracts text and layout from documents. Amazon Transcribe ‚Äì Converts speech to text for captions and call analytics. Amazon Polly ‚Äì Text-to-speech for natural-sounding voices. Amazon Comprehend ‚Äì NLP for entities, sentiment, and key phrase extraction. Amazon Kendra ‚Äì Enterprise search over heterogeneous content sources. Amazon Lookout services ‚Äì Detect anomalies in metrics, equipment data, and images. Amazon Personalize ‚Äì Recommendation engine for personalized rankings and suggestions. - Demo ‚Äì AMZPhoto:\nDemonstration app that uses Bedrock and image recognition to identify faces from uploaded photos and associate them with stored metadata, illustrating a typical end-to-end pipeline from ingestion to inference.\nAmazon Bedrock AgentCore - Overview:\nAgentCore is a modular, fully managed platform for building and operating AI agents in production, handling runtime, security, and observability concerns so teams can focus on agent logic.\n- What AgentCore Solves:\nSecurely execute and scale agent code with a dedicated runtime. Provide short-term and long-term memory so agents can learn from prior interactions. Integrate with identity systems to enforce access control for agents and tools. Connect agents to tools and APIs (via Gateway and MCP) for complex workflows. Offer observability and evaluations to monitor quality and trace agent decisions. - Core Service Groups (as presented):\nFoundational services: Runtime, Identity, Gateway, Policy ‚Äì handle secure execution, tool access, and guardrails. Tools \u0026amp; memory layer: Memory, Browser tool, Code Interpreter, and other integrations used to extend agent capabilities. Secure deployment at scale: Serverless Runtime and Identity support multi-tenant and enterprise use cases. Operational insights: Observability and Evaluations provide traces, metrics, and continuous quality checks. - Frameworks for Building Agents:\nAgentCore interoperates with popular agent frameworks so teams aren‚Äôt locked in: CrewAI, Google ADK, LangGraph/LangChain, LlamaIndex, OpenAI Agents SDK, Strands Agents SDK, and others.\nKey Takeaways Bedrock as a GenAI hub: Amazon Bedrock centralizes access to multiple FMs and tools, so teams can experiment and ship GenAI features without standing up their own model infrastructure. Customization through prompts and data: Techniques like zero-shot, few-shot, chain-of-thought prompting and RAG let you adapt generic models to your domain with minimal fine-tuning. Embeddings as a core primitive: Titan Embeddings and similar models are critical for semantic search and RAG workflows, turning unstructured text into vectors that can be indexed and retrieved efficiently. Pretrained services for common use cases: Rekognition, Textract, Comprehend, Transcribe, and others provide building blocks for vision, document, and text analytics without needing to train models from scratch. AgentCore for production agents: AgentCore fills the gap between proof-of-concept agents and production deployments by adding runtime, memory, identity, and observability out of the box. Applying to Work Plan to incorporate Bedrock-hosted FMs and Titan Embeddings into upcoming team projects, particularly for search and RAG-style features in internal tools. Evaluate where pretrained services (e.g., Rekognition, Textract, Comprehend) can replace custom scripts in data processing pipelines to reduce maintenance overhead. Consider AgentCore as a foundation for any future agentic components in the architecture, especially where secure tool usage and observability are important. Event Experience The speakers delivered clear, practical explanations with concrete AWS service mappings, making it easy to connect high-level concepts to implementation options. During Q\u0026amp;A, a teammate raised an architecture issue: an SNS topic handling GuardDuty findings occasionally received bursts of 1000+ alerts, risking missed processing. The recommended mitigation was to insert an SQS queue between SNS and downstream consumers to buffer spikes and ensure all events are processed. Finished in the top 10 of the closing Kahoot quiz and had the chance to take photos with the speakers. Formed an unofficial joint group, ‚ÄúM√®o Cam ƒêeo KhƒÉn‚Äù, combining members from ‚ÄúThe Ballers‚Äù and ‚ÄúVinhomies‚Äù, which added a fun community aspect to the event. Some event photos "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives Rest and recover after minor abscess surgery. Follow the doctor‚Äôs instructions and avoid intensive activity. Change wound dressing daily as prescribed. Tasks to be carried out this week Day Task Start Date Completion Date Reference Material Monday Rest at home after surgery; follow pain medication schedule; first wound check. 15/09/2025 15/09/2025 Tuesday Daily dressing change as instructed by the doctor; avoid prolonged sitting. 16/09/2025 16/09/2025 Wednesday Daily dressing change; light walking only; monitor wound for pain. 17/09/2025 17/09/2025 Thursday Daily dressing change; keep the area clean and dry. 18/09/2025 18/09/2025 Friday Daily dressing change; focus on rest and nutrition. 19/09/2025 19/09/2025 Week 2 Achievements Followed post-surgery care plan, including daily dressing changes and rest as advised by the doctor. Avoided study and project work to reduce risk of complications and support proper wound healing. Maintained a simple log of recovery progress to keep the worklog consistent. Got ready, both physically and mentally, to restart AWS learning and project tasks in Week 3. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.10-cleanup/5.10.2-cdk-cleanup/","title":"CDK Cleanup","tags":[],"description":"","content":"Clean up (CDK) This guide ensures you correctly decommission all resources provisioned by the AWS CDK stack and clean up manually created data to avoid ongoing charges.\nPhase 1: Manual Data Cleanup (Before CDK Destroy) The CDK automatically deletes most resources failed in deleting content from S3 buckets. You must empty the contents of these buckets before running the cdk destroy command.\nResource Name Purpose Action Required incident-response-log-list-bucket Primary Log Source Empty Contents processed-cloudwatch-logs ETL Destination Empty Contents processed-guardduty-findings ETL Destination Empty Contents processed-cloudtrail-logs ETL Destination Empty Contents athena-query-results Athena Query Results Empty Contents aws-incident-response-automation-dashboard React Dashboard S3 Bucket Empty Contents Instructions for Emptying Buckets:\nOpen the Amazon S3 Console in your browser. For each of the buckets listed above (look for the names based on your AWS Account ID and Region): Click on the bucket name. Navigate to the \u0026ldquo;Objects\u0026rdquo; tab. Click the \u0026ldquo;Empty\u0026rdquo; button. Follow the prompts to confirm the permanent deletion of all objects. Phase 2: CDK Stack Destruction This step uses the CDK CLI to destroy all resources provisioned by the CloudFormation stack.\nEnsure Virtual Environment is Active\nIf you deactivated your Python environment, re-activate it (e.g., source .venv/bin/activate). Navigate to the Project Root\nEnsure you are in the main directory where the cdk.json file is located. Execute the Destroy Command\nRun the command to destroy all deployed stacks. When prompted, type y to approve the deletion. $ cdk destroy --all Phase 3: Post-Destruction Cleanup This step addresses remaining manual cleanup of lingering resources.\nDelete Remaining S3 Buckets\nThe cdk destroy command should remove the empty S3 buckets. If any remain (due to final checks or service protections), delete them now via the S3 Console. Disable Amazon GuardDuty\nGo to GuardDuty Console ‚Üí Settings ‚Üí General. Verify the service is disabled to ensure billing stops. Remove Cognito User and Pool\nGo to Cognito Console ‚Üí User pools. Delete the test user you created. Delete the User Pool created for the dashboard. Remove SES Identity\nGo to Amazon SES Console ‚Üí Verified Identities. Delete the sender email identity (sender_email) you verified. Deactivate Virtual Environment\nDeactivate the Python virtual environment: $ deactivate "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.4-monitoring-setup/5.4.2-create-interface-enpoint/","title":"Create an S3 Interface endpoint","tags":[],"description":"","content":"In this section you will create and test an S3 interface endpoint using the simulated on-premises environment deployed as part of this workshop.\nReturn to the Amazon VPC menu. In the navigation pane, choose Endpoints, then click Create Endpoint.\nIn Create endpoint console:\nName the interface endpoint In Service category, choose aws services In the Search box, type S3 and press Enter. Select the endpoint named com.amazonaws.us-east-1.s3. Ensure that the Type column indicates Interface. For VPC, select VPC Cloud from the drop-down. Make sure to choose \u0026ldquo;VPC Cloud\u0026rdquo; and not \u0026ldquo;VPC On-prem\u0026rdquo;\nExpand Additional settings and ensure that Enable DNS name is not selected (we will use this in the next part of the workshop) Select 2 subnets in the following AZs: us-east-1a and us-east-1b For Security group, choose SGforS3Endpoint: Keep the default policy - full access and click Create endpoint Congratulation on successfully creating S3 interface endpoint. In the next step, we will test the interface endpoint.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.5-processing-setup/5.5.2-create-aws-glue-database-and-tables/","title":"Create AWS Glue Database and Tables","tags":[],"description":"","content":"Create AWS Glue Database and Tables Create Database Open Glue Console ‚Üí Databases ‚Üí Add database\nDatabase name: security_logs\nCreate database\nCreate Tables (Using Athena DDL) Open Athena Console\nSet query result location: s3://athena-query-results-ACCOUNT_ID-REGION/\nSelect database: security_logs\nCreate processed_cloudtrail Table Run this DDL in Athena (replace ACCOUNT_ID and REGION):\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_cloudtrail ( `eventtime` string, `eventname` string, `eventsource` string, `awsregion` string, `sourceipaddress` string, `useragent` string, `useridentity` struct\u0026lt; type:string, invokedby:string, principalid:string, arn:string, accountid:string, accesskeyid:string, username:string, sessioncontext:struct\u0026lt; attributes:map\u0026lt;string,string\u0026gt;, sessionissuer:struct\u0026lt; type:string, principalid:string, arn:string, accountid:string, username:string \u0026gt; \u0026gt;, inscopeof:struct\u0026lt; issuertype:string, credentialsissuedto:string \u0026gt; \u0026gt;, `requestparameters` string, `responseelements` string, `resources` array\u0026lt;struct\u0026lt;arn:string,type:string\u0026gt;\u0026gt;, `recipientaccountid` string, `serviceeventdetails` string, `errorcode` string, `errormessage` string, `hour` string, `usertype` string, `username` string, `isconsolelogin` boolean, `isfailedlogin` boolean, `isrootuser` boolean, `isassumedrole` boolean, `ishighriskevent` boolean, `isprivilegedaction` boolean, `isdataaccess` boolean, `target_bucket` string, `target_key` string, `target_username` string, `target_rolename` string, `target_policyname` string, `new_access_key` string, `new_instance_id` string, `target_group_id` string, `identity_principalid` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Create processed_guardduty Table Run this DDL in Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_guardduty ( `finding_id` string, `finding_type` string, `title` string, `severity` double, `account_id` string, `region` string, `created_at` string, `event_last_seen` string, `remote_ip` string, `remote_port` int, `connection_direction` string, `protocol` string, `dns_domain` string, `dns_protocol` string, `scanned_ip` string, `scanned_port` int, `aws_api_service` string, `aws_api_name` string, `aws_api_caller_type` string, `aws_api_error` string, `aws_api_remote_ip` string, `target_resource_arn` string, `instance_id` string, `instance_type` string, `image_id` string, `instance_tags` string, `resource_region` string, `access_key_id` string, `principal_id` string, `user_name` string, `s3_bucket_name` string, `service_raw` string, `resource_raw` string, `metadata_raw` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/\u0026#39; TBLPROPERTIES ( \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39;, \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/date=${date}/\u0026#39; ); Create vpc_logs Table Run this DDL in Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.vpc_logs ( `version` string, `account_id` string, `region` string, `vpc_id` string, `query_timestamp` string, `query_name` string, `query_type` string, `query_class` string, `rcode` string, `answers` string, `srcaddr` string, `srcport` int, `transport` string, `srcids_instance` string, `timestamp` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;ignore.malformed.json\u0026#39; = \u0026#39;true\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Create eni_flow_logs Table Run this DDL in Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.eni_flow_logs ( `version` int, `account_id` string, `interface_id` string, `srcaddr` string, `dstaddr` string, `srcport` int, `dstport` int, `protocol` int, `packets` bigint, `bytes` bigint, `start_time` bigint, `end_time` bigint, `action` string, `log_status` string, `timestamp_str` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/","title":"Create IAM Roles and Policies","tags":[],"description":"","content":"In this section, you will create IAM role and Policy for Lambda. After that you will create Lambda Function to execute query\nContent Create Lambda Execution Roles and Policy Create Lambda Function "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.2-create-service-roles/","title":"Create Service Roles","tags":[],"description":"","content":"Create Firehose Roles Create CloudTrailFirehoseRole Open IAM Console ‚Üí Roles ‚Üí Create role\nSelect trusted entity:\nTrusted entity type: AWS service Use case: Select \u0026ldquo;Kinesis\u0026rdquo; ‚Üí \u0026ldquo;Kinesis Firehose\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Add permissions:\nSkip adding managed policies (we\u0026rsquo;ll add inline policy) Click \u0026ldquo;Next\u0026rdquo; Name and create:\nRole name: CloudTrailFirehoseRole Description: Allows Firehose to write CloudTrail logs to S3 Click \u0026ldquo;Create role\u0026rdquo; Add inline policy:\nPolicy name: FirehosePolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Create CloudWatchFirehoseRole Role name: CloudWatchFirehoseRole Description: Allows Firehose to write CloudWatch logs to S3 Trusted entity: Kinesis Firehose Inline policy name: FirehosePolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Create Step Functions Role Create StepFunctionsRole Create role:\nTrusted entity: Step Functions Role name: StepFunctionsRole Description: Execution role for Incident Response Step Functions Add TWO inline policies:\nPolicy 1: LambdaInvokePolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-parse-findings-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-quarantine-iam-lambda\u0026#34; ] } ] } Policy 2: EC2AutoScalingPolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;autoscaling:DescribeAutoScalingInstances\u0026#34;, \u0026#34;autoscaling:DetachInstances\u0026#34;, \u0026#34;autoscaling:UpdateAutoScalingGroup\u0026#34;, \u0026#34;ec2:CreateSnapshot\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:DescribeVolumes\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Create EventBridge Role Create IncidentResponseStepFunctionsEventRole Role name: IncidentResponseStepFunctionsEventRole Description: Allows EventBridge to trigger Step Functions Trusted entity: EventBridge Inline policy name: StartStepFunctionsPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;states:StartExecution\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:REGION:ACCOUNT_ID:stateMachine:IncidentResponseStepFunctions\u0026#34; } ] } Create VPC Flow Logs Role Create FlowLogsIAMRole Create role:\nTrusted entity: EC2 (will edit trust policy) Role name: FlowLogsIAMRole Edit trust relationship to:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;vpc-flow-logs.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } Add inline policy: Policy name: FlowLogsPolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Create Glue Role Create GlueCloudWatchRole Role name: GlueCloudWatchRole Description: Allows Glue to access S3 and CloudWatch Logs Trusted entity: Glue Managed policies (attach 3): AWSGlueServiceRole CloudWatchLogsReadOnlyAccess AmazonS3FullAccess No inline policies needed "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.2-guardduty-etl/","title":"GuardDuty ETL Code","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.2-guardduty-etl/","title":"GuardDuty ETL Code","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.2-create-lambda-function/","title":"Lambda setup","tags":[],"description":"","content":"In this guide, you will setup a Lambda using Python to execute query using Athena service.\nCreate Lambda Function Open the Lambda Console\nNavigate to https://console.aws.amazon.com/lambda/ Or: AWS Management Console ‚Üí Services ‚Üí Lambda Create Function:\nClick the Create Function In the create setting use the following setting: Choose Author from scratch Name: dashboard-query Runtime: Python 3.12 Architecture: x86_64 Change default execution role: Use an existing role Choose dashboard-query-role Click Create Add code:\nIn the code editor copy and paste the codes below then click Deply: import boto3 import time import os import json athena = boto3.client(\u0026#39;athena\u0026#39;) RESOURCE_MAP = { \u0026#39;/logs/cloudtrail\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_cloudtrail\u0026#39; }, \u0026#39;/logs/guardduty\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_guardduty\u0026#39; }, \u0026#39;/logs/vpc\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;vpc_logs\u0026#39; }, \u0026#39;/logs/eni_logs\u0026#39;:{ \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;eni_flow_logs\u0026#39; } } OUTPUT_BUCKET_NAME = os.environ.get(\u0026#34;ATHENA_OUTPUT_BUCKET\u0026#34;) REGION = os.environ.get(\u0026#34;REGION\u0026#34;) OUTPUT_BUCKET = f\u0026#39;s3://{OUTPUT_BUCKET_NAME}/\u0026#39; def lambda_handler(event, context): print(\u0026#34;Received event:\u0026#34;, json.dumps(event)) resource_path = event.get(\u0026#39;resource\u0026#39;) config = RESOURCE_MAP.get(resource_path) if not config: return api_response(400, {\u0026#39;error\u0026#39;: f\u0026#39;Unknown resource path: {resource_path}\u0026#39;}) database_name = config[\u0026#39;db\u0026#39;] table_name = config[\u0026#39;table\u0026#39;] query_params = event.get(\u0026#39;queryStringParameters\u0026#39;, {}) or {} if config[\u0026#39;table\u0026#39;] == \u0026#39;processed_cloudtrail\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by eventtime desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;processed_guardduty\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by date desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;vpc_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;eni_flow_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp_str desc\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Querying DB: {database_name}, Table: {table_name}, Output: {OUTPUT_BUCKET}\u0026#34;) try: response = athena.start_query_execution( QueryString=query_string, QueryExecutionContext={\u0026#39;Database\u0026#39;: database_name}, ResultConfiguration={\u0026#39;OutputLocation\u0026#39;: OUTPUT_BUCKET} ) query_execution_id = response[\u0026#39;QueryExecutionId\u0026#39;] status = \u0026#39;RUNNING\u0026#39; while status in [\u0026#39;RUNNING\u0026#39;, \u0026#39;QUEUED\u0026#39;]: response = athena.get_query_execution(QueryExecutionId=query_execution_id) status = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;][\u0026#39;State\u0026#39;] if status in [\u0026#39;FAILED\u0026#39;, \u0026#39;CANCELLED\u0026#39;]: reason = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;].get(\u0026#39;StateChangeReason\u0026#39;, \u0026#39;Unknown\u0026#39;) return api_response(500, {\u0026#39;error\u0026#39;: f\u0026#39;Query Failed: {reason}\u0026#39;}) time.sleep(1) results = athena.get_query_results(QueryExecutionId=query_execution_id) return api_response(200, results) except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return api_response(500, {\u0026#39;error\u0026#39;: str(e)}) def api_response(code, body): return { \u0026#34;statusCode\u0026#34;: code, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET, OPTIONS\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps(body) } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/5.3.2-set-up-s3-buckets-policies/","title":"Set up S3 buckets policies","tags":[],"description":"","content":"In this section, you will configure the bucket policy for the primary log bucket to allow CloudTrail, GuardDuty, and CloudWatch Logs to write logs.\nConfigure Bucket Policy Navigate to the primary log bucket: In S3 Console, click on incident-response-log-list-bucket-ACCOUNT_ID-REGION Open the Permissions tab:\nClick on the \u0026ldquo;Permissions\u0026rdquo; tab Scroll to Bucket policy:\nScroll down to the \u0026ldquo;Bucket policy\u0026rdquo; section Click \u0026ldquo;Edit\u0026rdquo; Paste the bucket policy: Copy the following JSON policy Important: Replace ACCOUNT_ID and REGION with your actual values in the policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyGetBucketLocation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsGetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailAclCheck\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailWrite\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/AWSLogs/ACCOUNT_ID/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34;, \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo;\nVerify policy is saved: You should see the policy displayed in the Bucket policy section\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Summary Report: ‚ÄúAWS Cloud Mastery Series #2 ‚Äì DevOps on AWS‚Äù Event Objectives Introduce core AWS DevOps services and CI/CD pipelines. Explain Infrastructure as Code (IaC) concepts and common tooling. Cover containerization options on AWS. Demonstrate how to achieve monitoring and observability with AWS services. Speakers Truong Quang Tinh ‚Äì AWS Community Builder, Platform Engineer ‚Äì TymeX Bao Huynh ‚Äì AWS Community Builder Nguyen Khanh Phuc Thinh ‚Äì AWS Community Builder Tran Dai Vi ‚Äì AWS Community Builder Huynh Hoang Long ‚Äì AWS Community Builder Pham Hoang Quy ‚Äì AWS Community Builder Nghiem Le ‚Äì AWS Community Builder Dinh Le Hoang Anh ‚Äì Cloud Engineer Trainee, First Cloud AI Journey Key Highlights DevOps Mindset - Culture: Emphasis on collaboration across teams, high level of automation, continuous learning, and making decisions based on measurable outcomes.\n- DevOps Roles: Typical roles in a modern DevOps organization include DevOps Engineer, Cloud Engineer, Platform Engineer, and Site Reliability Engineer (SRE), each focusing on reliability, delivery speed, and operational excellence.\n- Success Metrics:\nHealthy, reliable deployments. Improved delivery agility and reduced lead time for changes. Overall system stability and resilience. Better end-user experience and performance. Clear evidence that technology investments provide business value. DO DON\u0026rsquo;T Start with fundamentals Stay in tutorial hell Learn by building real projects Copy-paste blindly Document everything Compare your progress to others Master one thing at a time Give up after failures Improve soft skills - Continuous Integration:\nDevelopers integrate changes frequently into a shared main branch, with automated builds and tests ensuring each commit keeps the codebase in a releasable state and enabling continuous delivery or deployment.\nInfrastructure as Code (IaC) - Benefits:\nIaC brings automation, repeatability, and scalability to infrastructure management. Teams can version-control environments, spin them up or tear them down on demand, and collaborate on infrastructure changes as code instead of relying on manual ClickOps.\nAWS CloudFormation AWS‚Äôs native IaC service that uses JSON/YAML templates to describe and provision full stacks of AWS resources in a predictable and auditable way.\n- Stack:\nA stack is a collection of AWS resources defined in a single template. Operations like create, update, and delete are executed at the stack level, making complex environments easier to manage.\n- CloudFormation Template:\nA declarative YAML/JSON file that defines resources, their configuration, and relationships. It acts as a blueprint that can be reused across environments (dev, test, prod).\n- How it works (high level):\nWrite a template that describes the target infrastructure. Store it locally or in S3 and create a stack from it. CloudFormation provisions, updates, or deletes resources to match the template. - Drift Detection:\nCloudFormation can detect configuration drift when resources have been changed outside of IaC. This helps teams either reconcile the template with reality or roll back unauthorized changes.\nAWS Cloud Development Kit (CDK) An open-source framework that lets you define CloudFormation stacks using real programming languages (TypeScript/JavaScript, Python, Java, C#/.NET, Go).\n- Construct:\nConstructs are the building blocks in CDK and represent one or more resources plus configuration. Three construct levels were explained:\nL1 constructs: Low-level, map 1:1 to CloudFormation resources for maximum control. L2 constructs: Higher-level, intent-based APIs that wrap common best practices and sensible defaults. L3 constructs: Opinionated ‚Äúpatterns‚Äù that compose multiple resources into complete architectures (for example, an API Gateway + Lambda + DynamoDB stack). AWS Amplify A platform focused on building and deploying web and mobile applications. Amplify uses CloudFormation behind the scenes to provision backend and hosting infrastructure, providing a higher-level developer experience with CLI and console workflows.\nTerraform A popular multi-cloud IaC tool where infrastructure is described in HashiCorp Configuration Language (HCL) and then planned and applied against one or more providers (AWS, Azure, GCP, etc.).\n- Strengths:\nMulti-cloud support with a consistent language and workflow. State tracking, enabling Terraform to understand changes between current and desired infrastructure definitions. How to Choose IaC Tools? - Criteria to consider:\nAre you targeting a single cloud (e.g., AWS-only) or multiple providers? Is your primary role closer to application development or platform/ops? How well does your chosen cloud and its ecosystem support the tool (docs, examples, official modules, support)? Container Services on AWS Dockerfile A Dockerfile describes how to build a container image: base image, dependencies, build steps, environment variables, and entrypoint. This ensures the application behaves consistently across environments that support Docker.\n- Images:\nImages are immutable blueprints built from a Dockerfile via layered file systems. They are used to run containers consistently in development, staging, and production.\n- Workflow:\nWrite Dockerfile ‚Üí build Docker image ‚Üí run containers locally or in AWS ‚Üí push the image to a registry such as Amazon ECR or Docker Hub.\nAmazon ECR A fully managed, secure, and scalable private container registry on AWS where teams can store, manage, and share container images.\n- Key features:\nImage scanning to detect vulnerabilities. Immutable tags to avoid accidental overwrites. Lifecycle policies to clean up old images. Encryption and IAM integration for secure access. Container Orchestration Container orchestrators manage container scheduling, scaling, and lifecycle:\nRestart failed containers. Scale out or in based on traffic or metrics. Balance traffic and place workloads across compute capacity efficiently. Kubernetes (K8s) Open source container orchestration platform that automates deployment, scaling, and self-healing of containerized applications.\n- Components:\nMaster (Control Plane): Manages the cluster state, scheduling, and API. Worker Nodes: Run application workloads inside pods. Pods: Smallest deployable unit, typically one or a small set of tightly coupled containers. Services: Stable endpoints and load balancing over sets of pods. ECS vs EKS Feature Amazon ECS (Elastic Container Service) Amazon EKS (Elastic Kubernetes Service) Core Technology AWS-native container orchestration Managed Kubernetes (open-source standard) Complexity Simpler and easier to operate More flexible but higher operational complexity Knowledge Required No Kubernetes knowledge required Requires Kubernetes concepts (pods, deployments, services, etc.) AWS Integration Deep integration with AWS services Standard Kubernetes integration, more ecosystem tooling Use Case / Benefits Fast deployments, low ops overhead Multi-cluster, portability, more customization Ecosystem / Community AWS-native tooling and community Large Kubernetes ecosystem and community Summary Great when you want managed, AWS-centric container platform Great when you need Kubernetes features or portability App Runner A fully managed service suitable for quickly deploying containerized web applications and APIs from source or container registries, ideal for smaller teams or workloads that want minimal infrastructure management.\nMonitoring \u0026amp; Observability CloudWatch Central service to monitor AWS resources and applications in near real-time. Provides metrics, logs, alarms, and dashboards to improve reliability and cost visibility. Integrates with other services (e.g., Auto Scaling, EventBridge) for automated responses. - CloudWatch Metrics:\nMetrics capture performance and health data from AWS services and on-prem workloads (with the CloudWatch Agent), and they can be wired into alarms, scaling policies, and DevOps workflows.\nAWS X-Ray - Distributed Tracing:\nX-Ray traces requests across microservices, visualizing call graphs and latency between components. This helps identify slow or failing segments in complex architectures.\n- Performance Insight:\nUsed for root-cause analysis of performance issues and errors, highlighting where time is spent and where failures occur, and providing support for real user monitoring scenarios.\nEvent Experience This event was especially relevant to our project because it aligned with our plan to move from ClickOps to IaC with AWS CDK, improving maintainability, repeatability, and collaboration around infrastructure. The additional details on CloudWatch and X-Ray also supported our monitoring and data visibility requirements.\nThe speakers also addressed several of our team‚Äôs questions:\nQ: Our project is currently ClickOps-based, and we want to migrate to CDK. Is there a tool that can scan existing infrastructure and convert it to CDK/CloudFormation?\nA: There is currently no tool that can reliably reverse-engineer full IaC from an existing environment, so the recommended path is to rebuild the infrastructure using IaC and gradually align the real environment with code.\nQ: X-Ray tracing looks similar to CloudTrail. How do they differ?\nA: X-Ray focuses on tracing application requests and service-to-service calls for performance and debugging, while CloudTrail focuses on auditing API calls and user/role activity in the AWS account.\nQ: Our project is built around GuardDuty findings. Any suggestions for reliably generating findings for demo scenarios?\nA: Port scanning is one way to trigger findings, and GuardDuty can also be configured with custom threat lists (malicious IPs/domains) to generate alerts when related activity is detected.\nThis was also the first time some speakers presented these topics:\nThe DevOps and IaC sections were delivered clearly and structured well. The Monitoring \u0026amp; Observability part showed some understandable nervousness but still provided useful, practical insight. Some event photos "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Continue recovering health while maintaining learning progress where possible. Start learning Amazon S3 and static website hosting. Review IAM, Organizations and security best practices when feeling better. Discuss project ideas with teammates when health allows. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Still in recovery period after surgery. Had to go to the hospital for wound cleaning and bandage change. Mostly resting at home, not able to sit or use the computer for a long time, no study activities done. 22/09/2025 22/09/2025 ‚Äì Tue Continued daily hospital visit for bandage change and wound check. Pain level still high, required to lie down most of the time. Only reviewed notes briefly on phone, no hands‚Äëon labs completed. 23/09/2025 23/09/2025 ‚Äì Wed Last day of intensive bandage change schedule at the hospital. Doctor allowed to start sitting up in short periods, but still unable to focus for long study sessions. Used the time to think about upcoming S3 lessons and project ideas, but no practical lab work yet. 24/09/2025 24/09/2025 ‚Äì Thu Health improved, could sit at the desk for short periods, still had to go for bandage change but started studying again. Began ‚ÄúKh·ªüi ƒë·∫ßu v·ªõi Amazon S3‚Äù: + Learnt basic concepts of Amazon S3 as an object storage service, its durability and common use cases. + Reviewed prerequisites for working with S3 and created an S3 bucket for the lab. + Enabled static website hosting on the S3 bucket and uploaded initial website files. + Configured Block Public Access settings to allow controlled public access for the website. 25/09/2025 25/09/2025 Gi·ªõi thi·ªáu Amazon S3 Chu·∫©n b·ªã B·∫≠t t√≠nh nƒÉng Static Website C·∫•u h√¨nh Block Public Access Fri Still needed daily bandage change but could sit longer, so continued S3 lab work. Continued ‚ÄúKh·ªüi ƒë·∫ßu v·ªõi Amazon S3‚Äù: + Configured object‚Äëlevel public access to serve website content. + Tested the static website from browser to verify configuration. + Studied how to accelerate static website using CloudFront (theory, no full setup due to health/time). + Practised Bucket Versioning, moving objects between folders/buckets and replicating objects to another region. + Reviewed cleanup steps and best practices for S3 security and cost. 26/09/2025 26/09/2025 C·∫•u h√¨nh Public Object Ki·ªÉm tra Website TƒÉng t·ªëc v·ªõi CloudFront Bucket Versioning Di chuy·ªÉn \u0026amp; sao ch√©p Object S3 Cross‚ÄëRegion Replication Cleanup \u0026amp; Best Practices Week 3 Achievements: Managed to balance health recovery with learning by gradually resuming study activities from Thursday onward. Gained foundational knowledge of Amazon S3, including buckets, objects, static website hosting and public access controls. Successfully hosted a simple static website on S3, tested public access and explored options to accelerate it with CloudFront. Practised S3 features such as Bucket Versioning, object movement, cross‚Äëregion replication and proper cleanup following best practices. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.3-setup-api-gateway/","title":"API Gateway Setup","tags":[],"description":"","content":"In this guide, you will setup an API Gateway to route api call from dashboard to Lambda.\nCreate API Gateway Open the API Gateway Console\nNavigate to https://console.aws.amazon.com/apigateway/ Or: AWS Management Console ‚Üí Services ‚Üí API Gateway Create API:\nClick Create API Choose REST API and click Build Use this setting for creation: Choose New API Name: dashboard-api API endpoint type: Regional Security policy: SecurityPolicy_TLS13_1_3_2025_09 Endpoint access mode: Basic IP address type: IPv4 Create Resources:\nEnable CORS for the root resource Click Create resource and name it logs Then click on /logs resource that just created and click Create Resource to create child resource of /logs Name it cloudtrail and enable CORS Repeat this three more times for eni_logs, guardduty and vpc Create methods:\nClick on /cloudtrail that just created and click Cretae method\nIn method creation, use this setting:\nMethod type: GET Intergration type: Lambda function Enable Lambda proxy intergration choose Buffered Lambda function: select your region search for dashboard-query and choose it Timout: 29000 Repeat this three more time for eni_logs, guardduty and vpc\nDeploy API:\nClick the Deploy API on the right corner In deploy API, use this setting: Stage: New stage Name: prod Click Deploy "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.3-cloudwatch-etl/","title":"CloudWatch ETL Code","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIG # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Extract VPC ID from file path vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Read and process file content content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Create flattened JSON record out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Add newline for JSONL format json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Send to Firehose in batches of 500 if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.3-cloudwatch-etl/","title":"CloudWatch ETL Code","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIG # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Extract VPC ID from file path vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Read and process file content content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Create flattened JSON record out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Add newline for JSONL format json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Send to Firehose in batches of 500 if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.3-create-iam-policy/","title":"Create IAM Policy","tags":[],"description":"","content":"Create IAM Quarantine Policy Create IrQuarantineIAMPolicy Navigate to IAM Console ‚Üí Policies ‚Üí Create policy\nPolicy JSON:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Policy name: IrQuarantineIAMPolicy Description: Deny-all policy for quarantining compromised IAM users "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/","title":"Create IAM Roles and Policies","tags":[],"description":"","content":"In this section, you will create 17 IAM roles with their associated policies for Lambda functions, Firehose streams, Step Functions, and other services.\nOverview of IAM Roles Lambda Execution Roles (9 roles):\nCloudTrailETLLambdaServiceRole GuardDutyETLLambdaServiceRole CloudWatchETLLambdaServiceRole CloudWatchENIETLLambdaServiceRole CloudWatchExportLambdaServiceRole ParseFindingsLambdaServiceRole IsolateEC2LambdaServiceRole QuarantineIAMLambdaServiceRole AlertDispatchLambdaServiceRole Service Roles (6 roles): 10. CloudTrailFirehoseRole 11. CloudWatchFirehoseRole 12. StepFunctionsRole 13. IncidentResponseStepFunctionsEventRole 14. FlowLogsIAMRole 15. GlueCloudWatchRole\nIAM Policy (1 policy): 16. IrQuarantineIAMPolicy\nContent Create Lambda Execution Roles Create Service Roles Create IAM Policy "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.5-processing-setup/5.5.3-create-lambda-function-etl-processing/","title":"Create Lambda Function - ETL Processing","tags":[],"description":"","content":"Create Lambda Functions - ETL Processing In this section, you will create 5 Lambda functions that process logs and send them to Kinesis Firehose or S3.\nincident-response-cloudtrail-etl Runtime: Python 3.12 Handler: CloudTrailETL.lambda_handler Role: CloudTrailETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: FIREHOSE_STREAM_NAME=cloudtrail-firehose-stream Code: cloudtrail-etl incident-response-guardduty-etl Runtime: Python 3.12 Handler: guardduty_etl.lambda_handler Role: GuardDutyETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: DESTINATION_BUCKET, S3_LOCATION_GUARDDUTY, DATABASE_NAME, TABLE_NAME_GUARDDUTY Code: guardduty-etl cloudwatch-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_etl.lambda_handler Role: CloudWatchETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-dns-firehose-stream Code: cloudwatch-etl cloudwatch-eni-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_eni_etl.lambda_handler Role: CloudWatchENIETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-flow-firehose-stream Code: cloudwatch-eni-etl cloudwatch-export-lambda Runtime: Python 3.12 Handler: cloudwatch_autoexport.lambda_handler Role: CloudWatchExportLambdaServiceRole Env: DESTINATION_BUCKET=incident-response-log-list-bucket-ACCOUNT_ID-REGION Code: cloudwatch-autoexport Configure CloudWatch Logs Subscription Filter Configure Subscription Filter Open the CloudWatch Console.\nIn the left navigation pane, select Log Management.\nClick on the centralized log group: /aws/incident-response/centralized-logs.\nCreate Subscription Filter:\nClick the \u0026ldquo;Subscription filters\u0026rdquo; tab. Click \u0026ldquo;Create Lambda subscription filter\u0026rdquo;. Configure Destination:\nDestination Lambda function: Select the function cloudwatch-export-lambda. Log format: Select \u0026ldquo;Other\u0026rdquo;. (This ensures the raw log data is passed efficiently for Lambda processing). Configure Log Format and Filter:\nSubscription filter name: Enter a descriptive name, e.g., VPC-Log-Export-Filter. Filter pattern: Leave this field blank. (Ensures all logs in the group are processed). Click \u0026ldquo;Start streaming\u0026rdquo;.\nConfigure S3 Event Notifications S3 Console ‚Üí incident-response-log-list-bucket-ACCOUNT_ID-REGION ‚Üí Properties ‚Üí Event notifications\nCreate 4 notifications with Event types/Object creation/‚úÖAll object create events:\nCloudTrailETLTrigger: Prefix AWSLogs/ACCOUNT_ID/CloudTrail/ ‚Üí Lambda incident-response-cloudtrail-etl VPCDNSLogsTrigger: Prefix exportedlogs/vpc-dns-logs/ ‚Üí Lambda cloudwatch-etl-lambda VPCFlowLogsTrigger: Prefix exportedlogs/vpc-flow-logs/ ‚Üí Lambda cloudwatch-eni-etl-lambda GuardDutyFindingsTrigger: Prefix AWSLogs/ACCOUNT_ID/GuardDuty/ ‚Üí Lambda incident-response-guardduty-etl "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.3-foundation-setup/","title":"Foundation Setup","tags":[],"description":"","content":"This initial Foundation Setup phase establishes the core prerequisites for the Auto Incident Response System, concentrating on the deployment of dedicated storage and essential security authorization. This mandates the creation of five secure Amazon S3 buckets for centralized log ingestion and processing, applying a necessary Bucket Policy for secure log delivery, and defining 17 IAM roles and a quarantine policy to enforce least-privilege access across all integrated AWS services.\nContent Set up Amazon S3 Bucket Configure S3 Bucket Policy for Primary Log Bucket Create IAM Roles and Policies "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.4-monitoring-setup/5.4.3-test-endpoint/","title":"Test the Interface Endpoint","tags":[],"description":"","content":"Get the regional DNS name of S3 interface endpoint From the Amazon VPC menu, choose Endpoints.\nClick the name of newly created endpoint: s3-interface-endpoint. Click details and save the regional DNS name of the endpoint (the first one) to your text-editor for later use.\nConnect to EC2 instance in \u0026ldquo;VPC On-prem\u0026rdquo; Navigate to Session manager by typing \u0026ldquo;session manager\u0026rdquo; in the search box\nClick Start Session, and select the EC2 instance named Test-Interface-Endpoint. This EC2 instance is running in \u0026ldquo;VPC On-prem\u0026rdquo; and will be used to test connectivty to Amazon S3 through the Interface endpoint we just created. Session Manager will open a new browser tab with a shell prompt: sh-4.2 $\nChange to the ssm-user\u0026rsquo;s home directory with command \u0026ldquo;cd ~\u0026rdquo;\nCreate a file named testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file to the same S3 bucket we created in section 3.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; This command requires the \u0026ndash;endpoint-url parameter, because you need to use the endpoint-specific DNS name to access S3 using an Interface endpoint. Do not include the leading \u0026rsquo; * \u0026rsquo; when copying/pasting the regional DNS name. Provide your S3 bucket name created earlier Now the file has been added to your S3 bucket. Let check your S3 bucket in the next step.\nCheck Object in S3 bucket Navigate to S3 console Click Buckets Click the name of your bucket and you will see testfile2.xyz has been added to your bucket "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - Achieve Excellence in Aftermarket Service with Syncron and AWS This blog explains how manufacturers can enhance their aftermarket services by implementing the Syncron Service Lifecycle Management (SLM) platform on AWS. You will learn why traditional, isolated operations often lead to inefficiencies and increased costs , and how Syncron‚Äôs SLM platform creates a connected business ecosystem by unifying data from parts, service, and warranty management. The article also explores the solution\u0026rsquo;s architecture, which leverages services like Amazon S3 and AWS Glue, and walks through customer use cases such as gaining instant access to data and building custom AI/ML models for price optimization.\nBlog 2 - Amazon Q Developer CLI supports image inputs in your terminal This blog introduces the powerful new capability of the Amazon Q Developer CLI to accept and analyze image inputs directly in the terminal. You will learn how this feature bridges the gap between visual design assets and functional code, streamlining development by reducing the manual, error-prone work of translating diagrams into implementation. The article also provides a hands-on guide with several practical use cases, demonstrating how to generate Terraform code from an architecture diagram, create a SQL schema from an ER diagram, transform a hand-drawn sketch into a formal design document, and build UI code from a simple screenshot.\nBlog 3 - Simulating partial failures with AWS Fault Injection Service This blog details an advanced chaos engineering technique for simulating partial, or localized, system failures using AWS Fault Injection Service (FIS). You will learn why testing for these non-total failures is critical for building truly resilient applications and how traditional fault injection methods often overlook this important scenario. The article also provides a complete, step-by-step walkthrough of the solution, guiding you on how to combine FIS with an Application Load Balancer (ALB) and an AWS Lambda function to inject controlled faults that impact only a percentage of traffic, all without requiring any changes to your application\u0026rsquo;s code.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Summary Report: ‚ÄúSecure Your Applications: AWS Perimeter Protection Workshop‚Äù Event Objectives Introduce Amazon CloudFront as a foundation for perimeter protection. Explain AWS WAF and application-layer protection patterns. Hands-on: Optimize a web application using CloudFront. Hands-on: Secure an internet-facing web application with WAF. Speakers Nguyen Gia Hung ‚Äì Head of Solution Architect Julian Ju ‚Äì Senior Edge Services Specialist Solutions Architect Kevin Lim ‚Äì Senior Edge Services Specialist GTM Key Highlights Amazon CloudFront Customer security needs and positioning Different customer profiles require different levels of protection:\nSmall website owners: Need simple, cost-effective protection against basic threats. Business users: Require broader coverage for DDoS, bots, and malicious traffic patterns. Scaling businesses / enterprises: Need advanced configuration such as origin failover, origin offload, and tight integration with WAF and Shield. CloudFront was positioned as the edge foundation that can cover all three, with predictable pricing, global presence, and tight integration with AWS security services.\nCloudFront Flat-Rate Pricing CloudFront now provides flat-rate plans that bundle CDN, WAF, DDoS protection, DNS, and storage under a single monthly charge:\nPlans:\nFree: 0 USD/month Pro: 15 USD/month Business: 200 USD/month Premium: 1000 USD/month Example usage envelopes:\nFree: 1M requests + 100 GB data Pro: 10M requests + 50 TB data Business: 125M requests + 50 TB data Premium: 500M requests + 50 TB data If you exceed the ‚Äúsoft limit‚Äù, CloudFront does not immediately charge overages; instead, performance can be throttled and alerts are raised so you can upgrade tiers or optimize usage.\nPerimeter protection with CloudFront Distributed defense: Attacks are absorbed at edge locations close to the attacker, rather than hitting your origin directly. AWS Shield Advanced integration: Provides visibility into infrastructure-layer DDoS events and access to the Shield Response Team (SRT) 24/7. Volumetric attack mitigation: STN proxy and global routing help mitigate SYN floods and other large-scale network attacks inline. Cost optimization with CloudFront Free data transfer from AWS services to CloudFront: Data going from many AWS origins to CloudFront typically has reduced or zero egress cost compared to direct internet egress.\nHTTP compression: Object compression can significantly reduce payload sizes (often ~80%), improving performance and reducing bandwidth usage.\nTLS optimizations:\nAutomatic TLS certificate issuance and renewal (ACM integration). Free HTTPS support with managed security policies for ciphers/TLS versions. Support for modern TLS (TLS 1.3, ECDSA certificates, and post-quantum‚Äìready options). Automatic redirect from HTTP to HTTPS at the edge. Upcoming mutual TLS: Ability to require client certificates for mutual authentication at the edge.\nOrigin cloaking:\nOrigin Access Control (OAC): Signs requests to S3, Lambda Function URLs, and other origins with short-lived credentials, preventing direct public access. Custom origins: Restrict access to CloudFront IP ranges and require a custom secret header. Content protection:\nSigned URLs / signed cookies to prevent direct hotlinking and copy-paste abuse. Caching \u0026amp; availability:\nCache content using TTL and serve from edge to reduce origin load. Serve stale content when origin is slow or temporarily unavailable to improve perceived uptime. Built-in origin failover to secondary origins when the primary is unhealthy. Graceful failure with custom error pages and cached error responses. Performance enhancements with CloudFront Multi-layer caching: Uses edge locations, Regional Edge Caches, and Origin Shield to collapse requests and increase cache hit ratio. Connection optimizations: Multiplexed connections to download assets in parallel. Persistent connections to origins to avoid repeated TCP handshakes. AWS global backbone: Traffic between edge and AWS origins stays on the AWS network, reducing latency and avoiding public internet congestion. Logic at the edge: CloudFront Functions and Lambda@Edge for redirects, URL rewrites, A/B testing, and geo/device-based routing. Implement rate limiting, API mocking, health checks, and custom error handling close to users. CloudFront common use cases Static websites and assets: High cache hit ratio yields large performance gains and lowers origin cost. Full website delivery: Combine performance, security, and high availability for dynamic + static content. API acceleration: Reuse long-lived connections and selectively cache responses to reduce latency. Media streaming: Serve large audiences at low latency and cost with HLS/DASH streaming from the edge. Large file downloads: Use range requests and edge caching for large binaries, often achieving significant cost savings. CloudFront best practices End-to-end visibility: Monitor real user metrics, internet-facing performance, and backend infrastructure. Maximize caching: Normalize cache keys, cache dynamic responses when safe, and cache error pages appropriately. Block unwanted traffic: Use WAF rules for malicious patterns, rate limiting, and API-level filtering. Offload logic to the edge: Handle CORS, redirects, and some cookie/header manipulation without hitting origin. Automatic failover: Combine Route 53 failover policies with CloudFront origin groups for resilient routing. AWS WAF \u0026amp; Application Protection Threats and business impact Key categories of threats:\nDenial-of-service and resource exhaustion. Exploits of application vulnerabilities (XSS, SQLi, path traversal, etc.). Malicious or abusive bot traffic. Consequences: data theft, credential compromise, spam/abuse, downtime, increased infrastructure cost, and reputational damage.\nSurge in bot activity There is a noticeable growth in bot traffic, including AI-powered bots and scrapers, which makes detection and mitigation more important and more nuanced than before.\nRoute 53 in perimeter protection Globally distributed DNS infrastructure. Built-in DDoS resilience and high availability. Often paired with CloudFront and WAF as the first entry point into the application stack. Infrastructure protection with AWS Shield At the edge:\nSYN proxy and packet validation. Filtering and scrubbing of volumetric attacks at scale. Automated routing policies to steer around unhealthy paths. At the border:\nTraffic filtering and resource-level detection. Health-based detection and targeted mitigation for protected resources. Application-layer protection with AWS WAF WAF is typically placed in front of CloudFront distributions or ALBs. Detects HTTP floods, known bad patterns, and suspicious IPs. Provides bot control (common bots vs evasive bots) and fraud control add-ons. Shield Advanced incident response Shield/Shield Advanced publishes metrics and alarms that can trigger incident workflows. 24/7 access to the Shield Response Team for escalations. Helps identify attack vectors, top contributors, and recommended mitigations. WAF configuration concepts Rules and rule groups: Compose managed and custom rules. Managed rules: Prebuilt, maintained by AWS or partners (e.g., OWASP top 10). Custom rules: Tailored to your application‚Äôs paths, headers, and specific patterns. COUNT mode first: Start with counting to observe and tune rules before enforcing BLOCK to reduce false positives. Labels: Tag requests with metadata from rules to drive more complex logic. Scope-down statements: Narrow rules to specific paths or conditions to reduce cost and unwanted matches. Web ACL / Protection Pack A Web ACL is the main WAF configuration object: rules, rule groups, and default action (allow/block). Associated to resources like CloudFront distributions, ALBs, or API Gateway. Logging and sampling options help review matches and fine-tune rules. WAF rules and DDoS at application layer Rules inspect attributes (IP, headers, URI, body) and then decide: Allow, Block, Count, or custom response. Rate-based rules track requests per IP (or other keys) and automatically throttle abusive traffic. Application-layer DDoS protection leverages these rules for automatic mitigation of HTTP floods. WAF labels \u0026amp; bot types Labels: Added by managed or custom rules to mark things like geo, IP reputation, bot/fraud category, or rule match. Common bots: Self-identifying bots (search engines, social platforms, libraries) that often follow standards. WAF can use signatures (headers, TLS fingerprint, IP reputation) to handle them. Evasive bots: Scrapers, credential stuffing tools, scanners that mimic real users and hide behind common headers. Countermeasures include client interrogation and behavioral analysis per session. CloudFront Hands-on: Perimeter Protection S3 static origin vs S3 behind CloudFront In the lab, we compared direct S3 website hosting with using CloudFront in front of S3:\nCloudFront served cached objects much faster than direct S3 access. Global edge locations and the AWS backbone improved latency versus direct public internet paths. Compression at the edge reduced object sizes, further improving load times. AWS WAF Hands-on: ‚ÄúStrengthen Your Web Application Defenses‚Äù During the WAF workshop, we created and tested rules to block:\nCross-Site Scripting (XSS). SQL Injection. Path traversal attacks. Server-side request/asset abuse patterns. Common and evasive bots. API misuse. A ‚Äúmystery‚Äù test scenario using an encrypted header value that needed a custom rule to block. Event Experience The workshop was very timely for our team, as we had just started configuring CloudFront the previous night. The flat-rate pricing model with included WAF is especially attractive for our use case because it simplifies both cost estimation and security setup.\nThe hands-on labs were engaging and practical, and Julian was particularly supportive throughout, frequently checking in and helping debug configuration issues. After the workshop, we had a chance to ask additional questions:\nQ: WAF can help control and block bot activity, but what about newer AI agents like Gemini‚Äôs browser integration, which acts through a visible browser rather than a headless client?\nA: For Gemini-style agents, traffic is still ultimately API-driven and can often be identified and mitigated at the HTTP level. Some agents, like certain Claude-based accessibility tools, may look almost identical to a real user and are not necessarily harmful, so the risk profile is different and may not require aggressive blocking in the short term. The event wrapped up with group photos and a Kahoot quiz; placing in the ranking and seeing a ‚Äúfull threat blocked‚Äù WAF dashboard during the lab gave a satisfying sense of end-to-end protection working as intended.\nSome event photos Event attendee group picture\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Complete Module 6 (Amazon RDS) Start on proposal Explore a non-AWS technology (Three.js) to avoid burnout Learn about ThreeJS Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Module 6 ‚Äì Amazon RDS (Part 1): + Reviewed relational database fundamentals in the context of managed services on AWS. + Learned the high-level overview and main benefits of Amazon RDS compared to self-managed databases on EC2 (managed backups, patching, scaling, Multi-AZ, read replicas). + Studied which database engines are supported on RDS (Aurora, MySQL, MariaDB, PostgreSQL, Oracle, SQL Server). + Compared when to use RDS versus DynamoDB, Redshift, Neptune, ElastiCache, and S3 for different workloads. 29/09/2025 29/09/2025 Amazon RDS ‚Äì Introduction Tue Module 6 ‚Äì Amazon RDS (Part 2): + Learned about RDS management features: automated backups, snapshots, maintenance windows, software patching, and event notifications via SNS. + Studied encryption at rest and in transit for RDS using AWS KMS and SSL, and how to create encrypted DB instances from encrypted snapshots. + Reviewed DB subnet groups and VPC design for RDS by placing DB instances in private subnets across multiple AZs. + Learned about main pricing components for RDS: instance hours, storage, IOPS, backup storage, and Multi-AZ. 30/09/2025 30/09/2025 Amazon RDS ‚Äì Management \u0026amp; Security Wed Module 6 ‚Äì Amazon RDS (Part 3): + Studied performance aspects such as storage types (gp2, Provisioned IOPS, magnetic) and their use cases. + Learned how Multi-AZ deployments work, typical failover scenarios, and how DNS endpoints are updated during failover. + Reviewed Read Replicas for scaling read workloads and basic high-availability and disaster recovery patterns across AZs and Regions. + Read about snapshots, restores, and migration options using Database Migration Service (DMS) and Schema Conversion Tool (SCT). 01/10/2025 01/10/2025 Amazon RDS ‚Äì Performance, Multi-AZ \u0026amp; Read Replicas Thu Three.js study: + Researched what Three.js is and how it builds on top of WebGL to render 3D graphics in the browser. + Learned core concepts: Scene, Camera, Renderer, Mesh, Geometry, Material, and basic lighting. + Followed introductory examples to render a simple rotating 3D object and experimented with camera controls. + Collected ideas on how Three.js could be used for interactive visualizations in the project. 02/10/2025 02/10/2025 Three.js Documentation Fri Joined the ‚ÄúAI-Driven Development Life Cycle: Reimagining Software Engineering‚Äù event. 03/10/2025 04/10/2025 Week 4 Achievements: Built a solid theoretical understanding of Amazon RDS, including engines, security, networking, Multi-AZ, and Read Replica patterns. Clarified RDS positioning compared to other AWS data services such as DynamoDB, Redshift, Neptune, ElastiCache, and S3. Took a healthy break from AWS-focused content by learning Three.js fundamentals and experimenting with basic 3D scenes for future project ideas. Continued project and learning activities by attending an AI-focused event and translating two technical blog posts. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.4-setup-cloudfront/","title":"Cloudfront Setup","tags":[],"description":"","content":"In this guide, you will setup a Cloudfront for cache, routing and web accessing.\nCreate Cloudfront Distribution Open the Cloudfront Console\nNavigate to https://console.aws.amazon.com/cloudfront/ Or: AWS Management Console ‚Üí Services ‚Üí Cloudfront Create Distribution:\nClick the Create distribution button In distribution creation, use this setting: Choose a plan: Free plan Name: Static Dashboard Website CloudFront Origin type: Amazom S3 S3 Origin: Choose the static-dashboard-bucket Keep the rest like default Enable security: Use this if you choose free plan Review and click Create distribution General setting:\nAfter creation complete, on your Cloudfront General tab click on Edit At the Default root object enter index.html Description: Static Dashboard Distribution Click Save change Create API Gateway origin:\nClick Origins on the menu tabs Then click Create origin In orogin creation, use this setting: Origin domain: choose dashboard-api Protocol: HTTPS only HTTPS port: 443 Minimum Origin SSL protocol: TLSv1.2 Origin path: /prod Click Create origin Create behaviors for API Gateway:\nClick Behaviors on the menu tabs Then click Create behavior In behavior creation, use this setting: Path pattern: /logs/* Origin and origin groups: choose dashboard-api Leave the rest setting like default Click Create behavior Update S3 policy to work with Cloudfront:\nClick Origins on the menu tabs, choose the s3-static-dashboard origin name Click Edit At Origin access controll section press Go to S3 bucket permissions Check if your S3 permission look like this, if don\u0026rsquo;t then copy and paste it to your S3 permission (Change the ACCOUNT_ID, ACCOUNT_REGION and CLOUDFRONT_ID to your): { \u0026#34;Version\u0026#34;: \u0026#34;2008-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PolicyForCloudFrontPrivateContent\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-static-dashboard-[ACCOUNT_ID]-[ACCOUNT_REGION]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::[ACCOUNT_ID]:distribution/[CLOUDFRONT_ID]\u0026#34; } } } ] } Click Save change Create error pages:\nClick Error pages on the menu tabs Click Create custom error page In custom error page creation, use this setting: HTTP error code: 403: Forbident Error caching minimum TTL: 300 Customize error response: Yes Response page path: /index.html HTTP Response code: 200: OK Repeat this for 404 code "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"CloudWatch ENI ETL Code","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # C·ªôt 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # C·ªôt 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # C·ªôt 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # C·ªôt 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duy·ªát qua c√°c file S3 g·ª≠i v·ªÅ for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Ch·ªâ x·ª≠ l√Ω file .gz if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # ƒê·ªçc n·ªôi dung content = read_gz(bucket, key) if not content: continue # Parse t·ª´ng d√≤ng log for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuy·ªÉn th√†nh JSON string v√† th√™m xu·ªëng d√≤ng (\\n) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # ƒê·∫©y sang Firehose (Batching 500 d√≤ng) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"CloudWatch ENI ETL Code","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # C·ªôt 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # C·ªôt 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # C·ªôt 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # C·ªôt 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duy·ªát qua c√°c file S3 g·ª≠i v·ªÅ for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Ch·ªâ x·ª≠ l√Ω file .gz if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # ƒê·ªçc n·ªôi dung content = read_gz(bucket, key) if not content: continue # Parse t·ª´ng d√≤ng log for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuy·ªÉn th√†nh JSON string v√† th√™m xu·ªëng d√≤ng (\\n) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # ƒê·∫©y sang Firehose (Batching 500 d√≤ng) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During my internship, I participated in seven events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AI-Driven Development Life Cycle: Reimagining Software Engineering\nDate \u0026amp; Time: 09:00, October 3rd, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS\nDate \u0026amp; Time: 08:30, November 15th, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AWS Cloud Mastery Series #2 - DevOps on AWS\nDate \u0026amp; Time: 08:30, November 17th, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: Secure Your Applications: AWS Perimeter Protection Workshop\nDate \u0026amp; Time: 08:30, November 19th, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: AWS Well-Architected ‚Äì Security Pillar Workshop\nDate \u0026amp; Time: 08:30, November 29th, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.4-monitoring-setup/","title":"Monitoring Setup","tags":[],"description":"","content":"This Monitoring Setup phase activates and configures the three core log sources for threat detection. It involves enabling CloudTrail for comprehensive management and data events, activating GuardDuty to export security findings to the primary S3 bucket, and setting up VPC Flow Logs on your network to send all traffic metadata to the dedicated CloudWatch Log Group. This ensures a constant, centralized stream of log data is available for processing and automated response.\nCreate CloudWatch Log Group Open CloudWatch Console ‚Üí Log Management ‚Üí Create log group Configure:\nLog group name: /aws/incident-response/centralized-logs Retention: 90 days KMS key: None Click \u0026ldquo;Create\u0026rdquo;\nEnable AWS CloudTrail Open CloudTrail Console ‚Üí Trail ‚Üí Create trail Trail attributes:\nTrail name: incident-responses-cloudtrail-ACCOUNT_ID-REGION Storage location: Use existing S3 bucket S3 bucket: Choose your incident-response-log-list-bucket-ACCOUNT_ID-REGION Log file SSE-KMS encryption: Disable Log file validation: Enabled Click next Choose log events:\nEvents Choose Management events, Data events Management events: All (Read + Write) Data events: S3 - Log all events Click next till step 4 and Create Trail Advanced event selectors: Exlcude log buckets:\nClick the Trail then scroll down to Data Event and click Edit Setup like picture with the under format: -arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\n-arn:aws:s3:::athena-query-results-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/\nSave change Enable Amazon GuardDuty Open GuardDuty Console ‚Üí Get Started ‚Üí Enable GuardDuty\nConfigure settings:\nFinding export frequency: Update CWE and S3 every 15 minutes S3 export: incident-response-log-list-bucket-ACCOUNT_ID-REGION KMS encryption: Choose or create KMS key Enable VPC Flow Logs Open VPC Console ‚Üí Your VPCs ‚Üí Select your VPC\nActions ‚Üí Create flow log\nConfigure:\nFilter: All Aggregation interval: 10 minutes Destination: CloudWatch Logs Log group: /aws/incident-response/centralized-logs IAM role: FlowLogsIAMRole Log format: Default Create flow log\nEnable VPC DNS Query Logging Configure Resolver Query Logging Open the Amazon Route 53 Console.\nIn the left navigation pane, select VPC Resolver -\u0026gt; Query logging.\nClick \u0026ldquo;Configure query logging\u0026rdquo;.\nConfigure:\nName: Enter a descriptive name, e.g., IR-DNS-Query-Log-Config. Destination for query logs: CloudWatch Logs log group Log group: Select \u0026ldquo;Existing log group\u0026rdquo; and choose: /aws/incident-response/centralized-logs Click \u0026ldquo;Configure query logging\u0026rdquo;.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.4-monitoring-setup/5.4.4-dns-simulation/","title":"On-premises DNS Simulation","tags":[],"description":"","content":"AWS PrivateLink endpoints have a fixed IP address in each Availability Zone where they are deployed, for the life of the endpoint (until it is deleted). These IP addresses are attached to Elastic Network Interfaces (ENIs). AWS recommends using DNS to resolve the IP addresses for endpoints so that downstream applications use the latest IP addresses when ENIs are added to new AZs, or deleted over time.\nIn this section, you will create a forwarding rule to send DNS resolution requests from a simulated on-premises environment to a Route 53 Private Hosted Zone. This section leverages the infrastructure deployed by CloudFormation in the Prepare the environment section.\nCreate DNS Alias Records for the Interface endpoint Navigate to the Route 53 management console (Hosted Zones section). The CloudFormation template you deployed in the Prepare the environment section created this Private Hosted Zone. Click on the name of the Private Hosted Zone, s3.us-east-1.amazonaws.com: Create a new record in the Private Hosted Zone: Record name and record type keep default options Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor (you saved when doing section 4.3) Click Add another record, and add a second record using the following values. Click Create records when finished to create both records. Record name: *. Record type: keep default value (type A) Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor The new records appear in the Route 53 console:\nCreate a Resolver Forwarding Rule Route 53 Resolver Forwarding Rules allow you to forward DNS queries from your VPC to other sources for name resolution. Outside of a workshop environment, you might use this feature to forward DNS queries from your VPC to DNS servers running on-premises. In this section, you will simulate an on-premises conditional forwarder by creating a forwarding rule that forwards DNS queries for Amazon S3 to a Private Hosted Zone running in \u0026ldquo;VPC Cloud\u0026rdquo; in-order to resolve the PrivateLink interface endpoint regional DNS name.\nFrom the Route 53 management console, click Inbound endpoints on the left side bar In the Inbound endpoints console, click the ID of the inbound endpoint Copy the two IP addresses listed to your text editor From the Route 53 menu, choose Resolver \u0026gt; Rules, and click Create rule: In the Create rule console: Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: Enter both IP addresses from your text editor (inbound endpoint addresses) and then click Submit You have successfully created resolver forwarding rule.\nTest the on-premises DNS Simulation Connect to Test-Interface-Endpoint EC2 instance with Session manager Test DNS resolution. The dig command will return the IP addresses assigned to the VPC Interface endpoint running in VPC Cloud (your IP\u0026rsquo;s will be different): dig +short s3.us-east-1.amazonaws.com The IP addresses returned are the VPC endpoint IP addresses, NOT the Resolver IP addresses you pasted from your text editor. The IP addresses of the Resolver endpoint and the VPC endpoint look similar because they are all from the VPC Cloud CIDR block.\nNavigate to the VPC menu (Endpoints section), select the S3 Interface endpoint. Click the Subnets tab and verify that the IP addresses returned by Dig match the VPC endpoint: Return to your shell and use the AWS CLI to test listing your S3 buckets: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Terminate your Session Manager session: In this section you created an Interface endpoint for Amazon S3. This endpoint can be reached from on-premises through Site-to-Site VPN or AWS Direct Connect. Route 53 Resolver outbound endpoints simulated forwarding DNS requests from on-premises to a Private Hosted Zone running the cloud. Route 53 inbound Endpoints recieved the resolution request and returned a response containing the IP addresses of the VPC interface endpoint. Using DNS to resolve the endpoint IP addresses provides high availability in-case of an Availability Zone outage.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Summary Report: ‚ÄúAWS Cloud Mastery Series #3 ‚Äì AWS Well-Architected: Security Pillar Workshop‚Äù Event Objectives AWS Cloud Club Introduction Pillar 1: Identity a\u0026amp; Access Management (IAM) Pillar 2: Detection \u0026amp; Continuous Monitoring Pillar 3: Infrastructure Protection Pillar 4: Data Protection Pillar 5: Incident Response Speakers Le Vu Xuan An ‚Äì AWS Cloud Club Captain, HCMUTE\nTran Duc Anh ‚Äì AWS Cloud Club Captain, SGU\nTran Doan Cong Ly ‚Äì AWS Cloud Club Captain, PTIT\nDanh Hoang Hieu Nghi ‚Äì AWS Cloud Club Captain, HUFLIT\nHuynh Hoang Long ‚Äì AWS Community Builder\nDinh Le Hoang Anh ‚Äì AWS Community Builder\nNguyen Tuan Thinh ‚Äì Cloud Engineer Trainee\nNguyen Do Thanh Dat ‚Äì Cloud Engineer Trainee\nVan Hoang Kha ‚Äì Cloud Security Engineer, AWS Community Builder\nThinh Lam ‚Äì FCJ Member\nViet Nguyen ‚Äì FCJ Member\nMendel Grabski (Long) ‚Äì Ex-Head of Security \u0026amp; DevOps, Cloud Security Solution Architect\nTinh Truong ‚Äì Platform Engineer at TymeX, AWS Community Builder\nKey Highlights AWS Cloud Club The session opened with an overview of AWS Cloud Clubs as student-led communities focused on cloud learning and peer support:\nHelp students explore and build real cloud skills through events, labs, and workshops. Provide opportunities to develop technical leadership (e.g., Cloud Club Captains). Enable networking with peers, AWS professionals, and broader tech communities. Cloud Clubs taking part in FCJA include:\nAWS Cloud Club HCMUTE AWS Cloud Club SGU AWS Cloud Club PTIT AWS Cloud Club HUFLIT Overall benefits emphasized: skill-building, a strong community, and career opportunities through visibility, mentorship, and practical experience.\nIdentity \u0026amp; Access Management (IAM) IAM was presented as the foundation of the Security Pillar, controlling who can do what in the AWS environment.\nCore responsibilities:\nManage identities (Users, Groups, Roles) and their permissions. Enforce both authentication and authorization across accounts and workloads. Best practices:\nApply the least privilege principle everywhere. Avoid using long-lived root access keys; remove them after setting up initial configuration. Minimize wildcards (\u0026quot;*\u0026quot;) in Actions/Resources; prefer scoped policies. Use Single Sign-On (SSO) and AWS Organizations for centralized, multi-account access control. Advanced IAM controls:\nService Control Policies (SCPs):\nSet the maximum permission boundary at the organization or OU level. Filter what accounts can do but never grant permissions by themselves. Permission boundaries:\nDefine the maximum effective permissions a user or role can receive from their identity policies. Useful for delegation scenarios where developers can create roles but must stay within guardrails. MFA comparison:\nTOTP (Time-based One-Time Password) FIDO2 (Fast Identity Online 2) Uses a shared secret and 6-digit codes Uses public-key cryptography Requires manual code entry Typically a tap or biometric factor Free to use (authenticator apps) May involve hardware token cost Easier backups and recovery Very strong security, strict/no recovery Credential rotation with Secrets Manager:\nUse a rotation Lambda to implement the 4-step cycle: createSecret ‚Üí setSecret ‚Üí testSecret ‚Üí finishSecret. Schedule rotations (for example, every 7 days) and send events to EventBridge for coordination. Rotate credentials without downtime and deprecate previous versions safely. Detection \u0026amp; Continuous Monitoring The second focus area centered on building multi-layer visibility and automating responses.\nMulti-layer security visibility:\nManagement events: API calls and console actions across all accounts (via CloudTrail). Data events: Fine-grained logging for S3 object access and Lambda invocations. Network activity: VPC Flow Logs for traffic patterns, allowed/denied connections. Organization-wide coverage: Aggregated logging across multiple accounts and regions. Alerting \u0026amp; automation with EventBridge:\nCloudTrail events feed into EventBridge to support near real-time event-driven responses. EventBridge rules route suspicious events to Lambda, SNS, SQS, or other targets. Cross-account routing enables a central security account to orchestrate detection and response workflows. Detection-as-Code:\nUse CloudTrail Lake or queryable logs to define reusable, SQL-like detection rules. Store rules in version control and deploy them via CI/CD for consistency. Set up organization-wide logging and detection using Infrastructure as Code so that all accounts adhere to the same baseline. Amazon GuardDuty GuardDuty was highlighted as an always-on, managed threat detection service.\nThree main data sources:\nData Source What It Monitors Example Finding CloudTrail events IAM actions and API calls Someone disables logging or creates high-privilege roles. VPC Flow Logs Network traffic to and from resources EC2 instance exfiltrating data to a command-and-control. DNS logs DNS queries from inside your environment Malware contacting suspicious or cryptomining domains. Extended protection plans:\nS3 Protection: Detects unusual object access patterns and scans uploads for malware. EKS Protection: Uses Kubernetes audit logs to detect abnormal cluster operations and correlates with S3 or other services. Malware Protection: Triggers scans on EBS volumes when compromise is suspected. RDS Protection: Monitors database login patterns to detect brute-force attempts. Lambda Protection: Observes network behavior from Lambda functions to catch data exfiltration and beaconing. Runtime Monitoring: With an agent on EC2/EKS/ECS Fargate, monitors processes, file activity, system calls, and privilege escalation attempts. Compliance and standards:\nGuardDuty and related services can help enforce:\nAWS Foundational Security Best Practices. CIS AWS Foundations Benchmark. PCI DSS, NIST and other frameworks (via Security Hub integration). Compliance-as-code setup:\nUse CloudFormation (or other IaC) to deploy GuardDuty, Security Hub, and related configuration. Security Hub runs checks against standard baselines across S3, EC2, RDS, etc. Findings flow into a central account to support audits and continuous compliance. Network Security Controls The network layer section organized threats and controls:\nAttack vectors: Ingress attacks: DDoS, SQL injection, direct scanning. Egress attacks: Data exfiltration, DNS tunneling. Lateral movement: East-west traffic between resources after compromise. Core components:\nSecurity Groups (SGs):\nStateful, instance-level firewalls. Only allow rules; anything not explicitly allowed is denied. Network ACLs (NACLs):\nStateless, subnet-level filters. Ordered rules that can explicitly ALLOW or DENY. Useful as an extra layer or for broad deny rules. Transit Gateway SG referencing:\nAllows referencing SGs from TGW-attached VPCs to simplify rule management for shared services. Route 53 Resolver:\nDirects DNS queries to private hosted zones, VPC DNS, or the public internet, supporting split-horizon and centralized DNS patterns. AWS Network Firewall:\nHandles deep packet inspection, egress filtering, and segmentation. Can enforce domain or protocol-based rules and integrate with threat intel (e.g., GuardDuty findings) for automated blocking. Data Protection \u0026amp; Governance Encryption with KMS:\nData is encrypted using data keys, which are themselves wrapped by Customer Managed Keys (CMKs). KMS policies and condition keys control when and by whom encryption/decryption operations can occur. Certificate management (ACM):\nIssues free public certificates for many AWS-integrated endpoints. Manages renewals automatically, typically 60 days before expiry. DNS validation is recommended for automation and stability. Secrets management:\nAWS Secrets Manager eliminates hardcoded secrets in apps and pipelines. Supports automatic rotation via Lambda using the four-step cycle (create, set, test, finish). Service-level security:\nS3 \u0026amp; DynamoDB APIs: Must be accessed over HTTPS; bucket policies can enforce aws:SecureTransport = true. RDS: Requires the client to trust AWS root CAs. SSL/TLS can be enforced (for example, rds.force_ssl=1 on PostgreSQL). Incident Response \u0026amp; Prevention Prevention best practices:\nPrefer temporary credentials (STS, IAM roles) over long-lived keys. Do not expose S3 buckets or other services directly to the internet if unnecessary. Place sensitive workloads in private subnets behind controlled entry points. Use Infrastructure as Code for all environments, so rebuilds and audits are easier. Introduce ‚Äúdouble gates‚Äù for risky changes: code review plus pipeline approval. Incident response lifecycle:\nPreparation: Document runbooks, practice scenarios, define roles. Detection \u0026amp; Analysis: Use GuardDuty, Security Hub, and logs to identify and investigate incidents. Containment: Isolate resources, revoke or rotate credentials, restrict network access. Eradication \u0026amp; Recovery: Remove the root cause, rebuild or restore from known-good states. Post-incident: Conduct retrospectives, update runbooks, and strengthen controls. Event Experience The workshop was highly relevant to our team‚Äôs project on Automated Incident Response and Forensics, especially the parts on GuardDuty, detection pipelines, and incident handling patterns.\nQ: Our project relies on GuardDuty findings for triggering automation, but we‚Äôre seeing up to ~5 minutes delay between an incident and the corresponding finding. Is there any way to significantly reduce this latency?\nA: The 5-minute delay is generally expected, because GuardDuty needs time to analyze large volumes of signals and correlate them into high-confidence findings. To improve responsiveness, you can complement GuardDuty with third-party tools (for example, more real-time anomaly detection) and build additional detections around CloudTrail or other telemetry for earlier signals, then enrich with GuardDuty when it arrives.\nAfter the session, Mr. Mendel Grabski spent additional time discussing our project and offered guidance and support, which was valuable for shaping next steps and potential integrations.\nSome event photos Picture of all attendees\nGroup picture with speakers Mendel Grabski and Van Hoang Kha\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Continue building and planning the workshop proposal. Explore workflow automation with n8n and basic Messenger bot development. Learn Auto Scaling and monitoring (CloudWatch) for AWS workloads. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Researched n8n as a workflow automation tool (self-hosted alternative to tools like Zapier). Learned about core concepts: workflows, triggers, nodes, credentials, and executions. Deployed n8n locally using Docker (basic docker-compose setup) and created simple test workflows (HTTP trigger, timers, basic data transformation). 06/10/2025 06/10/2025 n8n Documentation Tue Followed the tutorial video to build a Messenger bot using n8n and Facebook: + Set up a Facebook app and page for the bot. + Configured webhook and tokens so that messages from Messenger are sent to n8n. + Built a simple reply flow in n8n to handle incoming messages and send responses back to Messenger. + Tested the bot end-to-end from Messenger on phone/desktop. 07/10/2025 07/10/2025 Messenger bot tutorial Wed Translated three assigned blog posts for the workshop materials and documentation, focusing on accuracy of technical terminology and style. 08/10/2025 08/10/2025 Blog1 Blog2 Blog3 Thu Auto Scaling workshop ‚Äì ‚ÄúFCJ Management with Auto Scaling Group‚Äù: + Reviewed the overall architecture and prerequisites for deploying the FCJ Management application. + Studied how to create a Launch Template based on an existing FCJ Management AMI. + Learned how to configure an Elastic Load Balancer to distribute traffic across application instances. + Learned the steps to create and configure an Auto Scaling Group, scaling policies, and how to test scaling and failover. 09/10/2025 09/10/2025 FCJ Management with Auto Scaling Group Fri AWS CloudWatch Workshop: + Studied the overall purpose of Amazon CloudWatch for monitoring metrics, logs, and events across AWS resources and applications. + Reviewed preparatory steps for enabling CloudWatch in an account. + Learned how CloudWatch Metrics work and what kinds of default and custom metrics can be collected. + Studied CloudWatch Logs and how applications can send logs for centralized analysis. + Learned how to configure CloudWatch Alarms and Dashboards, and noted cleanup steps for lab resources. 10/10/2025 10/10/2025 AWS CloudWatch Workshop Week 5 Achievements: Learned the basics of n8n, deployed it with Docker, and successfully connected it to Facebook Messenger to build a simple bot. [web:0] Translated three technical blogs, improving both technical understanding and written communication for the workshop. [web:0] Gained theoretical understanding of deploying the FCJ Management application using Launch Templates, Load Balancer, and Auto Scaling Group on AWS. [web:1] Built foundational knowledge of Amazon CloudWatch, including metrics, logs, alarms, and dashboards for monitoring AWS workloads. [web:1] "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"CloudWatch Autoexport Code","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"CloudWatch Autoexport Code","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/5.7.5-setup-cognito/","title":"Cognito Setup","tags":[],"description":"","content":"In this guide, you will create a Cognito user pool for dashboard login.\nCreate Cognito User Pool Open the Amazon Cognito Console\nNavigate to https://console.aws.amazon.com/cognito/ Or: AWS Management Console ‚Üí Services ‚Üí Cognito Create user pool:\nClick Create user pool In user pool creation, use this setting: Application type: Single-page application (SPA) Application name: dashboard-user-pool-client Options for sign-in identifiers: Email and Username Self-registration: Enable self-registration Required attributes for sign-up: email Add a return URL: Go to Cloudfront, choose the one that you just created and copy the Distribution domain name and paste it here (Example: https://d2bvvvpr6s4eyd.cloudfront.net) Click Create user directory After create, scroll down and click Go to overview User pool App clients configuration:\nSelect App clients on the left menu panel Choose dashboard-user-pool-client In App client information section, click Edit Change the setting like the image below: Click Save change Managed login pages configuration:\nIn Managed login pages configuration section, click Edit Click Add sign-out URL at Allowed sign-out URLs section Copy the URL on the callbacks URL and paste to Allowed sign-out URLs Scroll down to OpenID Connect scopes add Profile to the scopes Click Save change Create a user:\nOn the left menu panel, select User option Click Create user Enter your user information Click Create user "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.5-processing-setup/","title":"Processing Setup","tags":[],"description":"","content":"This Processing Setup phase establishes the core data pipeline for structuring raw logs and preparing them for queryable analysis. It mandates the deployment of three Kinesis Data Firehose streams for buffering and delivering CloudTrail and VPC logs to target S3 buckets. Concurrently, you will configure the AWS Glue Database and four Athena tables via DDL to make the structured data queryable. This pipeline relies on five ETL Lambda functions triggered by S3 Event Notifications to perform the necessary data transformation upon log arrival.\nContent Create Kinesis Data Firehose Delivery Streams Create AWS Glue Database and Tables Create Lambda Functions - ETL Processing "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/","title":"Workshop","tags":[],"description":"","content":"AWS Auto Incident Response System Setup Overview This guide provides a complete, step-by-step procedure for deploying our automated incident response and forensic system in AWS. This system leverages CloudTrail, GuardDuty, VPC Flow Logs, Kinesis Firehose, Glue, Athena, and Lambda functions orchestrated by AWS Step Functions to automatically detect, analyze, and quarantine compromised resources like EC2 instances and IAM users. Futher log forensics capacity is added by setting up a Security Dashboard hosted on S3 and accessed via CloudFront and Cognito, query log using API Gateway and Lambda.\nContent Overview Prerequisites Phase 1: Foundation Setup Phase 2: Monitoring Setup Phase 3: Processing Setup Phase 4: Automation Setup Phase 5: Dashboard Setup Verify Use CDK Cleanup Appendices "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Discuss about proposal and workshop. Learn Blender and make my own 3D model. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Learned Blender basics for 3D modeling. Followed beginner tutorials to understand the interface, object manipulation, modifiers, and basic lighting/rendering. Created a first 3D product and exported the final render. Final product: Blender render. 13/10/2025 13/10/2025 - 3 Team meeting. Revised workshop proposal: focused on using GuardDuty for intrusion detection instead of a custom Lambda function due to the need for a large dataset and extensive development time. Redrew AWS architecture: added GuardDuty replacing CloudWatch Alarm. Wrote a draft of the proposal outlining basic functions and providing a rough cost estimate. 14/10/2025 14/10/2025 ‚Äì 4 Team meeting. Revised workshop proposal: + Incorporated the use of EventBridge. + Recalculated costs by reducing the EC2 instance type and active hours. Updated AWS architecture diagram to include the EventBridge icon and connections. 15/10/2025 15/10/2025 ‚Äì 5 Updated AWS architecture: + Rearranged icons for clearer connections. + Moved SSM inside the Region group. + Added public subnet group for the EC2 instance. Installed Amazon Q for enhanced proposal analytics. Revised workshop proposal: recalculated cost using AWS Pricing Calculator. 16/10/2025 16/10/2025 - 6 Family matters. No study or workshop work completed on this day. 17/10/2025 17/10/2025 ‚Äì Week 6 Achievements: Made significant progress on the workshop proposal and architecture, iterating on design, cost optimization, and tooling (GuardDuty, EventBridge, Amazon Q, AWS Pricing Calculator). Successfully prepared and deployed proposal materials and worklog updates to GitHub Pages. Learned Blender fundamentals and completed a first 3D product render as a side skill. Managed priorities between project work, study planning, and family responsibilities during the week. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.6-automation-setup/","title":"Automation Setup","tags":[],"description":"","content":"Phase 4: Automation Setup Create Isolation Security Group EC2 Console ‚Üí Security Groups ‚Üí Create security group Name: IR-Isolation-SG Description: Denies all inbound and outbound traffic for compromised instances VPC: Select your VPC Inbound rules: None (deny all) Outbound rules: Remove default (deny all) Create and note Security Group ID (e.g., sg-0078026b70389e7b3) Create SNS Topic SNS Console ‚Üí Create topic Type: Standard, Name: IncidentResponseAlerts Access policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AWSEvents_IncidentResponseAlert_Target0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;SNS:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; } ] } Create Lambda Functions - Incident Response ir-parse-findings-lambda Handler: parse_findings.lambda_handler Role: ParseFindingsLambdaServiceRole Code: parse-findings ir-isolate-ec2-lambda Handler: isolate_ec2.lambda_handler Role: IsolateEC2LambdaServiceRole Env: ISOLATION_SG_ID=sg-XXXXXXX (from step 12) Code: isolate-ec2 ir-quarantine-iam-lambda Handler: quarantine_iam.lambda_handler Role: QuarantineIAMLambdaServiceRole Env: QUARANTINE_POLICY_ARN=arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy Code: quarantine-iam ir-alert-dispatch Handler: alert_dispatch.lambda_handler Role: AlertDispatchLambdaServiceRole Env: SENDER_EMAIL, RECIPIENT_EMAIL, SLACK_WEBHOOK_URL Add SNS trigger: Topic IncidentResponseAlerts Code: alert-dispatch Update SNS Topic Subscription SNS Console ‚Üí IncidentResponseAlerts ‚Üí Subscriptions Verify: Protocol=AWS Lambda, Endpoint=ir-alert-dispatch, Status=Confirmed Create Step Functions State Machine Step Functions Console ‚Üí Create state machine Type: Standard, Name: IncidentResponseStepFunctions Definition: Step Functions Definition Role: StepFunctionsRole Create Create EventBridge Rule EventBridge Console ‚Üí Rules ‚Üí Create rule Name: IncidentResponseAlert Event pattern: { \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;] } Targets (2): SNS topic: IncidentResponseAlerts Step Functions: IncidentResponseStepFunctions with role IncidentResponseStepFunctionsEventRole Configure Athena Workgroup Athena Console ‚Üí Workgroups ‚Üí primary ‚Üí Edit Query result location: s3://athena-query-results-ACCOUNT_ID-REGION/ Save "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.6-parse-findings/","title":"Parse Findings Code","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.6-parse-findings/","title":"Parse Findings Code","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at [Company/Organization Name] from [start date] to [end date], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in [briefly describe the main project or task], through which I improved my skills in [list skills: programming, analysis, reporting, communication, etc.].\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ‚òê ‚úÖ ‚òê 2 Ability to learn Ability to absorb new knowledge and learn quickly ‚òê ‚úÖ ‚òê 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ‚òê ‚úÖ ‚òê 4 Sense of responsibility Completing tasks on time and ensuring quality ‚òê ‚úÖ ‚òê 5 Discipline Adhering to schedules, rules, and work processes ‚òê ‚úÖ ‚òê 6 Progressive mindset Willingness to receive feedback and improve oneself ‚òê ‚úÖ ‚òê 7 Communication Presenting ideas and reporting work clearly ‚òê ‚úÖ ‚òê 8 Teamwork Working effectively with colleagues and participating in teams ‚úÖ ‚òê ‚òê 9 Professional conduct Respecting colleagues, partners, and the work environment ‚òê ‚úÖ ‚òê 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ‚òê ‚úÖ ‚òê 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ‚òê ‚úÖ ‚òê 12 Overall General evaluation of the entire internship period ‚òê ‚úÖ ‚òê Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Learn how to build a secure serverless static website with SSL on AWS. Build a simple front-end that calls API Gateway and Lambda in a serverless architecture. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Serverless ‚Äì SSL S3 Static Website: + Studied the overall architecture for hosting a static website on S3 with HTTPS using ACM, Route 53, and CloudFront. + Reviewed the preparation steps and prerequisites for the workshop. + Learned how ACM is used to provision and manage SSL/TLS certificates for CloudFront. + Reviewed how Route 53 hosted zones and custom domains are used to route traffic to the CloudFront distribution. 20/10/2025 20/10/2025 Serverless ‚Äì SSL S3 Static Website Tue Serverless ‚Äì Build Frontend to call API Gateway (Part 1): + Reviewed the overall architecture: static front-end in S3/CloudFront calling API Gateway, Lambda, and DynamoDB. + Studied the introduction and requirements of the workshop. + Deployed the front-end application according to the workshop instructions. + Verified that the static front-end is accessible and ready to be wired to the API. 21/10/2025 21/10/2025 Serverless ‚Äì Build Frontend to call API Gateway Wed Serverless ‚Äì Build Frontend to call API Gateway (Part 2): + Reviewed how the Lambda function and DynamoDB table are used behind API Gateway. + Studied and configured API Gateway routes and integrations for the workshop. + Tested the API with Postman and then from the front-end, confirming end-to-end communication. + Reviewed cleanup steps to remove API Gateway, Lambda, and related resources after testing. 22/10/2025 22/10/2025 Serverless ‚Äì Build Frontend to call API Gateway Thu Team meeting: quick AWS services revision and discussion about proposal changes. Updated AWS architecture to add AWS Detective. Revised proposal to include AWS Detective and a post-workshop CDK plan. Configured EventBridge rules to react to GuardDuty findings, sending SNS emails to team members and triggering a simple Lambda function. Drafted an idea for a simple S3-hosted data graphing page using API Gateway, Lambda, and Athena for forensics data. 23/10/2025 23/10/2025 EventBridge, SNS, Lambda, Detective docs Fri Tried AWS Card Clash with team members to review AWS services and their use in architectures. Reviewed AWS services knowledge for the mid-term by generating quizzes with an LLM based on given requirements. 24/10/2025 24/10/2025 AWS Card Clash Week 7 Achievements: Learned how to host a secure, SSL-enabled static website on S3 using ACM, Route 53, and CloudFront. Built an understanding of serverless web architectures where a static front-end calls API Gateway, Lambda, and DynamoDB. Advanced the workshop proposal and architecture with AWS Detective and automated incident handling using EventBridge, SNS, and Lambda. Strengthened AWS services knowledge through AWS Card Clash and structured revision for the mid-term. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.7-dashboard-setup/","title":"Dashboard Setup","tags":[],"description":"","content":"This guide will show you how to setup the security dashboard. The security dashboard will be using S3 to contain the web files and folder, Lambda to query data using Athena, API Gateway to routing api to Lambda and Cloudfront to caching and access to the web using it\u0026rsquo;s URL.\nContent Setup S3 Setup Lambda Setup API Gateway Setup Cloudfront Setup Cognito "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.7-isolate-ec2/","title":"Isolate EC2 Code","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.7-isolate-ec2/","title":"Isolate EC2 Code","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don‚Äôt understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? What do you think the company should improve for future interns? If recommending to a friend, would you suggest they intern here? Why or why not? Suggestions \u0026amp; Expectations It would be great if the company could arrange an additional water corner (for example, a shared water dispenser or filtered water area) so that everyone can easily grab a drink during work, especially on long days or workshop days. It would be helpful if the AWS Cloud Mastery series (or similar orientation sessions) could be scheduled earlier in the internship, so interns can gain a clearer big-picture view and shape their projects from the beginning. In the future, I would be very happy to have the chance to continue participating in or supporting the next FCJ cohorts, as well as contributing more to the program‚Äôs community activities. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Review AWS knowledge. Complete FCJ Mid-Term exam. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Rewatched FCJ Bootcamp study videos - Completed the AWS Cloud Essentials Quiz - Deep dived in AWS Services previously learnt and compared similar services to eachother - Checked out some AWS Architected Labs to better understand each of the main pillars - Successfully export log streams to S3 - Succesfully created trail on CloudTrail to track S3 and Lambda activities - AWS Architecture: + Researched how to incoporate AWS Step Functions into workshop\u0026rsquo;s architecture, rather than using only one Lambda for all IR actions + Considered using AWS Kinesis Data Firehose for continous log stream to S3 27/10/2025 27/10/2025 AWS Cloud Essentials Quiz AWS Well Architected Lab 3 - Created 500 AWS Flashcards together with team members for learning 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Studied for Midterm Exam. 29/10/2025 29/10/2025 Introduction to Research for Essay Writing 5 - Practiced using AWS Certified Cloud Practitioner notes by other learners online: Did 5 practice tests - Practiced using AWS Certified Solutions Architect Associate practice questions: Practiced 40 questions 30/10/2025 30/10/2025 AWS Certified Cloud Practitioner notes AWS Certified Solutions Architect Associate practice 6 - Participated in FCJ Midterm Exam 31/10/2025 31/10/2025 Week 8 Achievements: FCJ Midterm Exam:\nCompleted extensive practice by taking five AWS Certified Cloud Practitioner practice tests and answering 40 AWS Certified Solutions Architect Associate practice questions.\nCollaborated with team members to create 500 AWS Flashcards for concentrated learning.\nCompleted the AWS Cloud Essentials Quiz and rewatched FCJ Bootcamp study videos.\nSuccessfully participated in the FCJ Midterm Exam.\nReviewed key AWS services and the AWS Well-Architected Labs to understand the main pillars.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.8-quarantine-iam/","title":"Quarantine IAM Code","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Ki·ªÉm tra n·∫øu policy ƒë√£ ƒë∆∞·ª£c g√°n attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.8-quarantine-iam/","title":"Quarantine IAM Code","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Ki·ªÉm tra n·∫øu policy ƒë√£ ƒë∆∞·ª£c g√°n attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.8-use-cdk/","title":"Use CDK","tags":[],"description":"","content":"Congratulations on completing this workshop! In this workshop, you learned architecture patterns for accessing Amazon S3 without using the Public Internet.\nBy creating a gateway endpoint, you enabled direct communication between EC2 resources and Amazon S3, without traversing an Internet Gateway. By creating an interface endpoint you extended S3 connectivity to resources running in your on-premises data center via AWS Site-to-Site VPN or Direct Connect. clean up Navigate to Hosted Zones on the left side of Route 53 console. Click the name of s3.us-east-1.amazonaws.com zone. Click Delete and confirm deletion by typing delete. Disassociate the Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. Open the CloudFormation console and delete the two CloudFormation Stacks that you created for this lab: PLOnpremSetup PLCloudSetup Delete S3 buckets Open S3 console Choose the bucket we created for the lab, click and confirm empty. Click delete and confirm delete. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.8-verify-setup/","title":"Verify Setup","tags":[],"description":"","content":"After all the setup phase, please refer to the checklist to ensure complete resources creation\nVerify Setup Complete Verification Checklist:\nIncident Response and Forensics:\n‚úÖ S3 Buckets: All 5 created with versioning/encryption ‚úÖ IAM Roles: All 17 roles with correct policies ‚úÖ CloudTrail: Logging enabled ‚úÖ GuardDuty: Enabled with S3 export ‚úÖ VPC Flow Logs: Active ‚úÖ Lambda Functions: All 9 deployed ‚úÖ Firehose Streams: All 3 active ‚úÖ Glue Tables: All 4 created ‚úÖ S3 Events: All 4 triggers configured ‚úÖ SNS Topic: Created with subscription ‚úÖ Step Functions: Active ‚úÖ EventBridge Rule: Enabled with 2 targets Security Dashboard:\n‚úÖ S3 Buckets: Bucket is created with dashboard file stored and enabled hosting ‚úÖ Query Lambda: Lambda is created with the appropriate roles ‚úÖ API Gateway: API Gateway is created with the correct API and resources ‚úÖ CloudFront: Distribution is created with API and S3 origins configured ‚úÖ Cognito: Linked to CloudFront distribution and created user in user pool End-to-End Test\nGenerate sample GuardDuty findings: 1.1 GuardDuty Console ‚Üí Settings ‚Üí Generate sample findings (200+ findings) or 1.2 Trigger single finding via CloudShell (Dectector Id is in GuardDuty Console ‚Üí Settings ) aws guardduty create-sample-findings --detector-id [$dectector-id] --finding-types \u0026#34;Recon:EC2/PortProbeUnprotectedPort\u0026#34; Monitor workflow: Check EventBridge, SNS, Step Functions, Lambda logs Verify alerts: Check email and Slack Query data in Athena: "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Support friends‚Äô game project with 3D scene and video for the main menu. Learn cost and usage analysis using AWS Glue and Amazon Athena. Start designing the dashboard for the workshop. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Family funeral. Spent the entire day with family and funeral arrangements, no study or project work done. 03/11/2025 03/11/2025 ‚Äì Tue Helped a group of friends interning at another company with their game project (main menu scene): + Designed and blocked out a 3D main menu scene for the game. + Set up camera angles and basic lighting suitable for a main menu background. + Iterated on composition to match the game‚Äôs visual style. 04/11/2025 04/11/2025 ‚Äì Wed Continued work on the main menu scene and video: + Refined details in the 3D scene (environment, props, lighting). + Recorded and exported a video sequence of the main menu scene to be used as the game‚Äôs menu background. + Shared the final assets and video with the game team. 05/11/2025 05/11/2025 3D \u0026amp; video outputs Thu Learned AWS Glue \u0026amp; Athena Cost and Usage Analysis lab: + Reviewed the workshop flow for analyzing cost and usage reports using Glue and Athena. + Studied how Glue Crawlers build tables from cost and usage data in S3. + Reviewed how Athena queries are used to analyze cost and performance across services. 06/11/2025 06/11/2025 AWS Glue \u0026amp; Athena ‚Äì Cost and Usage Analysis Fri Designed the first version of the custom dashboard in Figma: + Sketched layout ideas for showing GuardDuty findings, cost trends, and IR workflow status. + Defined a color palette and typography consistent with AWS/cloud themes. + Created wireframes and initial high-fidelity screens that can later be implemented as an S3-hosted dashboard. 07/11/2025 07/11/2025 - Week 9 Achievements: Managed a difficult week by prioritizing family during a funeral while still contributing to friends‚Äô game project. Created a 3D main menu scene and background video for a friend‚Äôs game, delivering usable assets for their internship project. Gained conceptual understanding of how to use AWS Glue and Amazon Athena to analyze cost and usage data. Designed the initial Figma dashboard layout, preparing UI/UX foundations for the workshop‚Äôs custom dashboard. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.9-alert-dispatch/","title":"Alert Dispatch Code","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # severity_num = finding.get(\u0026#39;severity\u0026#39;, 0) # if severity_num \u0026gt;= 7.0: # severity = \u0026#34;üî¥ HIGH\u0026#34; # elif severity_num \u0026gt;= 4.0: # severity = \u0026#34;üü† MEDIUM\u0026#34; # else: # severity = \u0026#34;üîµ LOW\u0026#34; # title = finding.get(\u0026#39;title\u0026#39;, \u0026#39;N/A\u0026#39;) # description = finding.get(\u0026#39;description\u0026#39;, \u0026#39;N/A\u0026#39;) # account_id = finding.get(\u0026#39;accountId\u0026#39;, \u0026#39;N/A\u0026#39;) # region = finding.get(\u0026#39;region\u0026#39;, \u0026#39;N/A\u0026#39;) # finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;N/A\u0026#39;) # message_text = ( # f\u0026#34;üö® *GuardDuty Finding* üö®\\n\\n\u0026#34; # f\u0026#34;*Severity:* {severity}\\n\u0026#34; # f\u0026#34;*Account:* {account_id}\\n\u0026#34; # f\u0026#34;*Region:* {region}\\n\u0026#34; # f\u0026#34;*Title:* {title}\\n\u0026#34; # f\u0026#34;*Description:* {description}\\n\\n\u0026#34; # f\u0026#34;*Finding Type:* `{finding_type}`\u0026#34; # ) # payload = {\u0026#39;chat_id\u0026#39;: chat_id, \u0026#39;text\u0026#39;: message_text, \u0026#39;parse_mode\u0026#39;: \u0026#39;Markdown\u0026#39;} # if thread_id: # payload[\u0026#39;message_thread_id\u0026#39;] = thread_id # try: # req = urllib.request.Request( # TELEGRAM_URL, # data=json.dumps(payload).encode(\u0026#39;utf-8\u0026#39;), # headers={\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;} # ) # with urllib.request.urlopen(req) as response: # logger.info(\u0026#34;Telegram response: \u0026#34; + response.read().decode(\u0026#39;utf-8\u0026#39;)) # except Exception as e: # logger.error(f\u0026#34;TELEGRAM FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;üî¥ HIGH\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;üü† MEDIUM\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;üîµ LOW\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;üö® {sev} ‚Äì {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;üö® GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Severity:*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Region:*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Description:*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Account:* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Type:* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;üö® GuardDuty Alert: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Account ID:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Region:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Type:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Finding ID:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Generated by AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.9-cleanup/","title":"Clean up","tags":[],"description":"","content":"Congratulations on completing this workshop! In this workshop, you learned architecture patterns for accessing Amazon S3 without using the Public Internet.\nBy creating a gateway endpoint, you enabled direct communication between EC2 resources and Amazon S3, without traversing an Internet Gateway. By creating an interface endpoint you extended S3 connectivity to resources running in your on-premises data center via AWS Site-to-Site VPN or Direct Connect. clean up Navigate to Hosted Zones on the left side of Route 53 console. Click the name of s3.us-east-1.amazonaws.com zone. Click Delete and confirm deletion by typing delete. Disassociate the Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. Open the CloudFormation console and delete the two CloudFormation Stacks that you created for this lab: PLOnpremSetup PLCloudSetup Delete S3 buckets Open S3 console Choose the bucket we created for the lab, click and confirm empty. Click delete and confirm delete. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.9-use-cdk/","title":"Use CDK","tags":[],"description":"","content":"Overview We have provided CDK stack to create all of the infrastructure required for this workshop.\nTo get the files please go to this Github Link and clone or download all the files to a folder\nSetup Guide Before deploying the CDK stack, you must configure your local environment to authenticate with your AWS account using the AWS Command Line Interface (CLI).\nInstall the AWS CLI.\nObtain Credentials: You need an Access Key ID and a Secret Access Key from an IAM user with deployment permissions.\nRun the Configuration Command: Open your terminal and execute aws configure.\n$ aws configure When prompted, enter your credentials and desired settings. The Default region name should match the region where you plan to deploy the stack (e.g., ap-southeast-1):\nPrompt Example Value AWS Access Key ID AKIA... AWS Secret Access Key wJalr... Default region name ap-southeast-1 Default output format json Verify Configuration: Test your setup by fetching your user identity. A successful output confirms you are authenticated.\n$ aws sts get-caller-identity Prerequisites Ensure the following tools and services are installed and configured on your system:\nPython 3.8+ and pip: Required for executing the CDK application and building Lambda function assets. Node.js and npm: Required for running the AWS CDK CLI and building the React dashboard. AWS CDK Toolkit: Install the CDK CLI globally: $ npm install -g aws-cdk Set Up Python Environment The infrastructure definition is written in Python. A dedicated virtual environment is used to manage project dependencies.\nCreate the Virtual Environment:\n$ python -m venv .venv Activate the Virtual Environment:\nOperating System Command macOS / Linux source .venv/bin/activate Windows (Command Prompt) .venv\\Scripts\\activate.bat Windows (PowerShell) .venv\\Scripts\\Activate.ps1 Install Python Dependencies:\n$ pip install -r requirements.txt Step to build the dashboard In the project folder location, check inside the react folder. If the dist folder already exists, you do not need to build. Otherwise, please follow the steps below. If you are on cmd use this command to move to react folder:\n$ cd react And use this command to list all content in react:\n$ ls Prerequisites Ensure you have Node.js and npm installed. You can check the current version by running:\n$ npm --version If the command is not recognized, please download and install Node.js from nodejs.org\nInstall dependencies Run the following command to install all necessary libraries:\n$ npm install Build the Project After the installation is complete, run the build command:\n$ npm run build Upon completion, a dist folder will be generated containing index.html and the assets folder.\nConfigure Deployment Context The stack utilizes context variables. These variables are read from cdk.context.json or provided via command-line flags.\nVariable Name Description Required if functionality is desired Default Value (in cdk.context.json) vpc_ids A list of VPC IDs for Flow Logs and DNS Query Logging. Yes [] alert_email A list of email addresses for alert notifications (requires SES). Yes [] sender_email The verified SES sender email address. Yes (if alert_email is set) \u0026quot;\u0026quot; slack_webhook_url The Slack webhook URL for sending alerts. No \u0026quot;\u0026quot; Example\n{ \u0026#34;vpc_ids\u0026#34;: [ \u0026#34;vpc-a1b2c3d4e5f6g7h8i\u0026#34; ], \u0026#34;alert_email\u0026#34;: [ \u0026#34;admin@example.com\u0026#34; ], \u0026#34;sender_email\u0026#34;: \u0026#34;alerts@your-domain.com\u0026#34;, \u0026#34;slack_webhook_url\u0026#34;: \u0026#34;\u0026#34; } Deploy the Stacks Before processing further, if inside the /react folder, enter this command to go back to the main folder:\n$ cd.. CDK Bootstrapping: If you have not used the AWS CDK in your target AWS account and region previously, run the bootstrap command once to provision necessary resources (e.g., S3 deployment bucket).\n$ cdk bootstrap (Optional) Synthesize and Diff: Review the proposed CloudFormation changes before deployment:\n$ cdk synth --all $ cdk diff --all Execute Deployment: Run the deployment command and approve any requested IAM security changes when prompted.\n$ cdk deploy --all The deployment is complete when the CDK CLI reports success for the stack: AwsIncidentResponseAutomationCdkStack and DashboardCdkStack\nIMPORTANT NOTE: After the deployment is complete, you should verify the email in SES. Create a user in Cognito to be able to log in to the Dashboard. Access the Security Group and remove the default outbound rule from the QuarantineSecurityGroup "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Test static web hosting with S3 and CloudFront. Set up a real domain and CI/CD flow for the React-based dashboard. Explore audio modding for World of Tanks using Wwise. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Built a basic test website to validate S3 static hosting and CloudFront: + Created an S3 bucket configured for static website hosting. + Deployed a simple HTML/CSS site to S3. + Set up a CloudFront distribution pointing to the S3 bucket to test global delivery and caching. 10/11/2025 10/11/2025 AWS S3 \u0026amp; CloudFront docs Tue Purchased a domain from Porkbun and connected it to the site: + Registered a custom domain and configured DNS records. + Pointed the domain to the CloudFront distribution. Started implementing the dashboard as a React application to later deploy on S3/CloudFront. 11/11/2025 11/11/2025 Porkbun docs, React docs Wed Uploaded the React dashboard project to GitHub and set up automation: + Pushed the dashboard source code to a GitHub repository. + Configured a GitHub Actions workflow to build the React app on push. + Automated upload of build artifacts to the S3 bucket and CloudFront cache invalidation after each deployment. 12/11/2025 12/11/2025 GitHub Actions docs, AWS CLI / SDK docs Thu Researched how to mod audio for World of Tanks using Wwise: + Read through the Wwise modding guide and World of Tanks mod documentation. + Studied the required folder structure, banks, and sound event workflow. + Took notes on how to package and load custom audio mods into the game. 13/11/2025 13/11/2025 Wwise mods creation PDF World of Tanks Wwise mods page Fri Completed and published a World of Tanks audio mod built with Wwise: + Finalized sound banks and configuration following the modding guides. + Tested the mod in-game to ensure sounds loaded and played correctly. + Published the finished mod on the official WGMods portal: Released mod. 14/11/2025 14/11/2025 - Week 10 Achievements: Successfully set up a simple S3 + CloudFront static website and then attached a custom Porkbun domain to it. Built and automated deployment for a React-based dashboard using GitHub Actions, S3, and CloudFront invalidation. Completed and released a World of Tanks audio mod using Wwise, including in-game testing and publishing on WGMods. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.10-cleanup/","title":"Cleanup","tags":[],"description":"","content":"Congratulations on completing this workshop! In this workshop, you have created an Automated Incident Response and Forensics System and familiarized with Lambda, Step Functions, EventBridge, Glue, Athena, CloudFront, Cognito, S3 Buckets\nCleanup Guide: Cleanup Guide for Manual Infrastructure Setup Clean Guide for CDK Setup "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.10-cleanup/5.10.1-manual-cleanup/","title":"Manual Cleanup","tags":[],"description":"","content":"Clean up (Manual Infrastructure Setup) Phase 1: Automation and Monitoring Cleanup The goal here is to stop all active processes and delete the monitoring and core automation resources (EventBridge, Step Functions, SNS, GuardDuty, Flow Logs, CloudTrail).\n1. Delete Incident Response Automation 1.1 Delete EventBridge Rule\nGo to EventBridge Console ‚Üí Rules. Select the rule: IncidentResponseAlert. Click \u0026ldquo;Delete\u0026rdquo;. 1.2 Delete Step Functions State Machine\nGo to Step Functions Console ‚Üí State Machines. Select the State Machine: IncidentResponseStepFunctions. Click \u0026ldquo;Delete\u0026rdquo;. 1.3 Delete SNS Topic and Subscription\nGo to SNS Console ‚Üí Topics ‚Üí IncidentResponseAlerts. First, delete the subscription associated with ir-alert-dispatch. Then, delete the topic itself by clicking \u0026ldquo;Delete topic\u0026rdquo;. 1.4 Delete GuardDuty Detector\nGo to GuardDuty Console ‚Üí Settings ‚Üí General. Click \u0026ldquo;Suspend\u0026rdquo; to stop processing, then click \u0026ldquo;Disable GuardDuty\u0026rdquo; (or \u0026ldquo;Delete detector\u0026rdquo;). 1.5 Disable VPC Flow Logs\nGo to VPC Console ‚Üí VPC Flow Logs. Select the flow log created (associated with YOUR_VPC_ID). Click \u0026ldquo;Delete flow log\u0026rdquo;. 1.6 Delete CloudTrail Trail\nGo to CloudTrail Console ‚Üí Trails. Select the trail: incident-responses-cloudtrail-ACCOUNT_ID-REGION. Click \u0026ldquo;Delete\u0026rdquo;. Phase 2: Lambda and Compute Cleanup 2. Delete All Lambda Functions (9 Functions) Go to the Lambda Console and delete the following functions:\nincident-response-cloudtrail-etl incident-response-guardduty-etl cloudwatch-etl-lambda cloudwatch-eni-etl-lambda cloudwatch-export-lambda ir-parse-findings-lambda ir-isolate-ec2-lambda ir-quarantine-iam-lambda ir-alert-dispatch 3. Delete Isolation Security Group Go to EC2 Console ‚Üí Security Groups. Find and select the Security Group: IR-Isolation-SG (using ID sg-XXXXXXX). Click \u0026ldquo;Delete security group\u0026rdquo;. 4. Delete CloudWatch Log Groups Go to the CloudWatch Console ‚Üí Log Groups and delete:\nThe centralized log group: /aws/incident-response/centralized-logs. Any associated Lambda log groups for the 9 deleted functions (e.g., /aws/lambda/ir-parse-findings-lambda). Phase 3: Processing and Data Lake Cleanup 5. Delete Kinesis Data Firehose Streams Go to the Kinesis Console ‚Üí Delivery Streams and delete:\ncloudtrail-firehose-stream vpc-dns-firehose-stream vpc-flow-firehose-stream 6. Delete AWS Glue Tables and Database 6.1 Delete Glue Tables\nGo to Glue Console ‚Üí Tables. Select and delete: security_logs.processed_cloudtrail, security_logs.processed_guardduty, security_logs.vpc_logs, and security_logs.eni_flow_logs. 6.2 Delete Glue Database\nGo to Glue Console ‚Üí Databases. Select the database: security_logs and click \u0026ldquo;Delete\u0026rdquo;. 7. Delete IAM Roles and Policies 7.1 Delete IAM Policies\nGo to IAM Console ‚Üí Policies. Delete the custom managed policy: IrQuarantineIAMPolicy. Note: Inline policies created in the setup will be deleted automatically when the corresponding role is deleted. 7.2 Delete IAM Roles\nGo to IAM Console ‚Üí Roles. Delete the following 17 roles: Lambda Execution Roles: CloudTrailETLLambdaServiceRole, GuardDutyETLLambdaServiceRole, CloudWatchETLLambdaServiceRole, CloudWatchENIETLLambdaServiceRole, CloudWatchExportLambdaServiceRole, ParseFindingsLambdaServiceRole, IsolateEC2LambdaServiceRole, QuarantineIAMLambdaServiceRole, AlertDispatchLambdaServiceRole. Service Roles: CloudTrailFirehoseRole, CloudWatchFirehoseRole, StepFunctionsRole, IncidentResponseStepFunctionsEventRole, FlowLogsIAMRole, GlueCloudWatchRole. Phase 4: S3 Bucket Cleanup (Data Deletion) 8. Empty and Delete S3 Buckets This is the final step to ensure all storage charges are stopped.\nBucket Name Purpose incident-response-log-list-bucket-ACCOUNT_ID-REGION Primary Log Source (CloudTrail/GuardDuty/Exported CW) processed-cloudtrail-logs-ACCOUNT_ID-REGION Firehose Destination for CloudTrail logs processed-cloudwatch-logs-ACCOUNT_ID-REGION Firehose Destination for VPC DNS/Flow logs processed-guardduty-findings-ACCOUNT_ID-REGION ETL Destination for GuardDuty logs athena-query-results-ACCOUNT_ID-REGION Athena Query Results Storage Go to the S3 Console. For each of the 5 buckets: Click on the bucket name. Go to the \u0026ldquo;Objects\u0026rdquo; tab. Click \u0026ldquo;Empty\u0026rdquo; to clear all data. You must confirm the permanent delete by typing permanently delete. Go back to the S3 bucket list, select the bucket, and click \u0026ldquo;Delete\u0026rdquo;. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Steps Functions Definition ASL Code","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Steps Functions Definition ASL Code","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Refine and connect project components (dashboard, API, data layer). Prepare for infrastructure-as-code using AWS CDK. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Joined the AWS Cloud Mastery Series #2 ‚Äì DevOps on AWS. Gained valuable insights into using CloudFormation and CDK for managing infrastructure. Received mentor recommendations about demo strategy for the project and wrote up event experience notes. 17/11/2025 17/11/2025 Event Summary and Experience Tue Set up API Gateway and a simple Lambda function to test calling APIs from the dashboard: + Created a REST API in API Gateway with a Lambda proxy integration. + Implemented a basic Lambda handler returning test JSON data. + Wired the React dashboard to call the API endpoint and verified end-to-end connectivity. 18/11/2025 18/11/2025 Lambda proxy integration in API Gateway Wed Updated the Lambda function to query data using Athena: + Implemented a Lambda that submits Athena queries and polls for completion. + Configured output location for Athena query results in S3. + Verified that Lambda can return query results to the dashboard via API Gateway. 19/11/2025 19/11/2025 How to query Athena from Lambda Thu Refined the external architecture around the dashboard: + Removed Route 53 from the architecture for this phase and focused on CloudFront as the main entry point. + Tested connectivity and flow between CloudFront, API Gateway, and Lambda. + Updated diagrams and notes to reflect the simplified routing path. 20/11/2025 20/11/2025 - Fri Researched AWS CDK in preparation for codifying the architecture: + Reviewed how to install and bootstrap AWS CDK. + Studied basic concepts: App, Stack, Constructs, and how to define infrastructure in code. + Looked at examples of defining API Gateway, Lambda, and S3/CloudFront resources using CDK. 21/11/2025 23/11/2025 AWS CDK GitHub AWS CDK Developer Guide Week 11 Achievements: Learned CDK and CloudFormation concepts from AWS Cloud Mastery Series #2 and gathered demo strategy feedback from mentors. Successfully connected the React dashboard to a REST API built with API Gateway and Lambda, verifying proxy integration and basic JSON responses. Implemented a Lambda function capable of running Athena queries and returning results, enabling data-driven views in the dashboard. Simplified and validated the external architecture by testing the flow CloudFront ‚Üí API Gateway ‚Üí Lambda without Route 53, and prepared to codify this in AWS CDK. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/5.11-appendices/","title":"Appendices","tags":[],"description":"","content":"Appendices Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/5-workshop/5.11-appendices/","title":"Appendices","tags":[],"description":"","content":"Appendices Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: Optimize Athena queries and dashboard performance. Improve dashboard UI/UX and deployment pipeline. Begin defining the dashboard infrastructure with AWS CDK. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Joined the team GitHub organization instead of creating a new one, and organized repositories for the dashboard and backend services. Cleaned up repo structure and permissions to prepare for future collaboration. 24/11/2025 24/11/2025 - Tue Applied partition projection to Athena tables to optimize queries: + Reviewed existing partitions and table definitions for cost/performance data. + Configured partition projection properties on the Athena table to reduce metadata lookups. + Tested queries before and after partition projection to confirm faster planning and lower scanned data. 25/11/2025 25/11/2025 Athena partition projection Wed Improved the dashboard UI: + Refined layout for key panels (threats, IR workflow status, cost metrics). + Adjusted color palette, typography, and spacing for better readability. + Polished charts/cards to make the data easier to scan during demos. 26/11/2025 26/11/2025 - Thu Migrated dashboard repository from GitHub to GitLab and set up GitLab CI: + Imported the existing React dashboard project into GitLab. + Created a .gitlab-ci.yml pipeline to build the project and deploy static files to S3. + Added steps to invalidate the CloudFront distribution after each successful deployment. 27/11/2025 27/11/2025 GitLab CI/CD to S3 \u0026amp; CloudFront Fri Started writing AWS CDK code for the dashboard stack: + Created a new CDK app and stack dedicated to the dashboard. + Defined S3 bucket resources for static hosting of the dashboard. + Added initial IAM policies required for deployment and access to the bucket (to be expanded later). 28/11/2025 30/11/2025 AWS CDK Developer Guide Week 12 Achievements: Organized code collaboration by joining the existing GitHub organization and structuring repos for the project. Improved Athena performance by enabling partition projection on key tables, reducing query planning overhead and scanned data. Enhanced the dashboard‚Äôs UI for readability and demo readiness, and migrated its deployment pipeline from GitHub to GitLab CI with S3 + CloudFront. Bootstrapped an AWS CDK stack for the dashboard, starting with S3 and IAM definitions to move towards full infrastructure-as-code. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/1-worklog/1.13-week13/","title":"Week 13 Worklog","tags":[],"description":"","content":"Week 13 Objectives: Complete the project and submit.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material Mon Continued writing AWS CDK for the dashboard backend and edge layer: + Extended the existing CDK app to define Lambda functions used by the dashboard APIs. + Added CloudFront distribution configuration for serving the dashboard and routing API paths. + Defined API Gateway resources and integrations with Lambda in CDK. 01/12/2025 01/12/2025 CDK Lambda + API tutorial Tue Added Amazon Cognito into the architecture to support login for the dashboard: + Designed where Cognito user pool fits between the front-end and API Gateway. + Reviewed authentication flow and how tokens will be used to protect APIs. + Updated the architecture diagram to include Cognito and adjusted notes for future implementation. 02/12/2025 02/12/2025 Amazon Cognito user pools Wed Tested CDK deployment and debugged issues: + Ran cdk synth and cdk deploy for the dashboard-related stacks. + Fixed logical and permission errors (IAM policies, missing environment variables, incorrect references). + Re-deployed until the CloudFront, API Gateway, and Lambda resources worked as expected. 03/12/2025 03/12/2025 - Thu Merged stacks from team members and tested combined deployment: + Pulled CDK stacks from other members in the organization. + Integrated their stacks (ETL, IR workflow, security components) with the dashboard stack. + Deployed the combined app and validated that all stacks work together without conflicts. 04/12/2025 04/12/2025 - Fri Family matters. 05/12/2025 05/12/2025 ‚Äì Week 13 Achievements: Extended the CDK codebase to define Lambda, CloudFront, and API Gateway resources for the dashboard path end-to-end. Designed and documented the integration of Amazon Cognito into the architecture to support authenticated access to the dashboard. Successfully deployed and debugged CDK stacks, then merged multiple team stacks into a single deployable application. Managed time between project delivery and family responsibilities at the end of the week. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/tags/","title":"Tags","tags":[],"description":"","content":""}]