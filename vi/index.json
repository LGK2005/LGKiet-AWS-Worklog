[{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Báo cáo sự kiện: “AI-Driven Development Life Cycle: Reimagining Software Engineering” Mục tiêu sự kiện Thảo luận về cách Generative AI đang thay đổi quy trình phát triển phần mềm hiện đại. Giới thiệu mô hình AI-Driven Development Life Cycle (AI-DLC) và các ý tưởng chính. Demo thực tế Kiro và Amazon Q Developer trong các tình huống phát triển phần mềm. Diễn giả Toan Huynh – Specialist SA, PACE My Nguyen – Sr. Prototyping Architect, Amazon Web Services – ASEAN Nội dung chính Chủ đề trung tâm của buổi chia sẻ là AI-DLC – một mô hình trong đó AI hỗ trợ điều phối vòng đời phát triển (lên kế hoạch, phân rã công việc, gợi ý kiến trúc), trong khi kỹ sư vẫn là người chịu trách nhiệm cuối cùng cho việc review, ra quyết định và quản trị. – AI-DLC – Ý tưởng cốt lõi:\nAI-DLC đặt con người ở trung tâm: AI đóng vai trò cộng tác viên, giúp tăng năng suất lập trình viên, rút ngắn vòng lặp phát triển từ hàng tuần/tháng xuống còn vài ngày hoặc vài giờ.\n– Quy trình AI-DLC:\nLuồng làm việc mang tính lặp, xen kẽ giữa bước của AI (đề xuất kế hoạch, triển khai thay đổi, trả lời câu hỏi) và bước của con người (làm rõ yêu cầu, duyệt kế hoạch), đảm bảo AI chỉ thực thi sau khi hướng đi đã được con người xác nhận.\n– Các giai đoạn AI-DLC:\nVòng đời được chia thành ba pha – Inception, Construction và Operation – mỗi pha bổ sung thêm ngữ cảnh cho pha tiếp theo:\nInception: Thu thập bối cảnh, làm rõ ý định thông qua User Story, tổ chức các Units of Work. Construction: Thực hiện Domain Modeling, sinh và kiểm thử code, bổ sung thành phần kiến trúc, deploy bằng IaC và test tự động. Operation: Chạy hệ thống ở môi trường production, xử lý sự cố và vận hành runtime. – Những “nỗi đau” mà AI-DLC cố gắng giải quyết:\nScaling AI development: Các công cụ code AI hiện tại dễ “đuối” khi hệ thống trở nên phức tạp hơn. Thiếu khả năng kiểm soát: Khó giám sát và điều phối nhiều AI agent một cách có cấu trúc. Chất lượng code: Khó giữ chất lượng production khi đi từ PoC lên hệ thống thật nếu thiếu khung làm việc rõ ràng. Phần chuyên sâu: Kiro – AI IDE từ prototype đến production Kiro là một IDE định hướng AI, được xây dựng quanh ý tưởng AI-DLC và nhấn mạnh cách tiếp cận “spec-driven development” (phát triển dựa trên đặc tả). – Spec-driven Development:\nTừ một prompt cấp cao (ví dụ: “xây một app chat kiểu Slack”), Kiro tạo ra các artifact có cấu trúc như:\nrequirements.md (yêu cầu), design.md (kiến trúc và thiết kế), tasks.md (danh sách công việc). Cách tiếp cận này chuyển workflow từ kiểu “code theo cảm hứng” sang quy trình có đặc tả cụ thể, dễ truy vết. Developer làm việc với các file spec như nguồn sự thật chính.\n– Agentic Workflows trong Kiro:\nCác agent của Kiro thực thi dựa trên spec, còn developer vẫn là người điều khiển:\nImplementation Plan: Kiro sinh ra một kế hoạch triển khai cụ thể với các task/subtask (ví dụ: “thêm API đăng ký/đăng nhập”, “triển khai middleware JWT”), và map từng task về requirement ban đầu để dễ đối chiếu. Agent Hooks: Hook kích hoạt agent khi có sự kiện như “save file”, tự động hóa các việc nền như sinh tài liệu, viết unit test, tinh chỉnh hiệu năng. Các ý chính rút ra – AI cho sản phẩm “gần mức production”:\nBằng cách sinh thiết kế chi tiết (data flow, API contract…) và test trước khi viết code, Kiro giúp output do AI sinh ra gần với chất lượng production hơn, thay vì chỉ là prototype dùng tạm.\n– Kiểm soát thông qua artifact:\nDeveloper điều khiển hệ thống chủ yếu bằng việc chỉnh sửa và phê duyệt các artifact – yêu cầu, thiết kế, kế hoạch công việc – thay vì ngồi viết từng dòng triển khai, trong khi AI agent chịu trách nhiệm phần thực thi.\nLiên hệ với công việc bản thân Sử dụng Amazon Q Developer / công cụ tương tự: Có thể áp dụng AI coding assistant vào bài tập và project cá nhân để xử lý những phần lặp lại/boilerplate, tập trung thời gian cho phần ý tưởng và kiến trúc. Tập trung vào phần giá trị cao: Chuyển các việc lặt vặt cho AI, dành thời gian cho Domain Modeling và Architectural Design – những phần vẫn cần tư duy và quyết định của con người trong pha Construction. Cảm nhận về sự kiện Buổi AI-Driven Development Life Cycle: Reimagining Software Engineering mang lại một bức tranh rất rõ về hướng đi tương lai của ngành phát triển phần mềm. Generative AI được trình bày không chỉ như một công cụ hỗ trợ viết code, mà còn như “động cơ” có thể điều phối một phần lớn vòng đời phát triển. Nội dung đi từ lý thuyết AI-DLC cho đến demo trực tiếp với Amazon Q Developer và Kiro. Phần demo Kiro ấn tượng nhất: từ một prompt ngắn có thể mở rộng thành một kế hoạch phát triển đầy đủ, có thể chạy và kiểm tra được ngay trong IDE.\nBài học rút ra Những vấn đề về scale, kiểm soát hành vi AI và chất lượng code cho thấy một quy trình có cấu trúc, có con người kiểm chứng như AI-DLC là rất thực tế và cần thiết. Một vài hình ảnh sự kiện "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lâm Gia Kiệt\nSố điện thoại: 0886659957\nEmail: lamgiakiet2005@gmail.com\nTrường: Trường Đại học FPT Thành Phố Hồ Chí Minh\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.1-week1/","title":"Nhật ký tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1 Kết nối và làm quen với các anh chị, mentor trong FCJ. Tìm hiểu cảm giác và môi trường làm việc văn phòng. Học những kiến thức cơ bản về AWS, giao diện Console và CLI. Học cách sử dụng AWS Pricing Calculator để ước tính chi phí. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai - Đọc nội quy thực tập. - Tạo tài khoản AWS mới. - Tìm hiểu tổng quan AWS là gì. - Hoàn thành Module 1 Lab 1 (tạo tài khoản AWS và quản lý user groups). - Hoàn thành Module 1 Lab 7 (tạo budget để quản lý chi phí sử dụng dịch vụ). - Lab 7-3 (Usage Budget) không thực hiện được do lỗi dropdown Usage Type không hiển thị dữ liệu. - Hoàn thành Module 1 Lab 9 (tìm hiểu AWS Support, các gói hỗ trợ, lợi ích và cách tạo yêu cầu hỗ trợ). 08/09/2025 08/09/2025 Tạo tài khoản AWS mới Bật MFA cho tài khoản AWS Tạo nhóm Admin và user Admin Xác thực tài khoản AWS Khám phá AWS Management Console Tạo và quản lý case hỗ trợ Ba - Tìm hiểu tổng quan về AWS Budgets và tầm quan trọng của quản lý chi phí trên AWS. - Học 4 loại budget chính: Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. - Thực hành tạo Cost Budget để nhận cảnh báo khi chi phí vượt ngưỡng. - Thực hành tạo Usage Budget để theo dõi mức sử dụng của một số dịch vụ (ví dụ: giờ chạy EC2). - Phân biệt RI Budget và Savings Plans Budget, hiểu cách chúng giúp tối ưu chi phí dài hạn. - Ôn lại best practices khi đặt ngưỡng cảnh báo và cấu hình người nhận thông báo. 09/09/2025 09/09/2025 Bắt đầu với AWS Budget Tạo Cost Budget Tạo Usage Budget Tạo RI Budget Tạo Savings Plans Budget Tư - Tìm hiểu tổng quan về AWS Identity and Access Management (IAM). - Học các khái niệm cốt lõi: IAM User, IAM Group, IAM Role, IAM Policy. - Thực hành tạo IAM Group và IAM User cho quyền admin. - Gán và kiểm thử IAM Policy theo nguyên tắc least privilege (ít quyền nhất cần thiết). - Tạo IAM Role để cấp quyền tạm thời thay vì dùng credential dài hạn. - Thực hành switch role giữa các tài khoản và kiểm tra quyền truy cập. - Ôn lại các best practices bảo mật với IAM như dùng CloudTrail để giám sát và dọn dẹp user/role không còn dùng. 10/09/2025 10/09/2025 Giới thiệu IAM Tạo IAM Group và IAM User Tạo IAM Role Chuyển đổi IAM Role Năm - Tìm hiểu tổng quan Amazon Virtual Private Cloud (VPC) và vai trò của VPC trong kiến trúc mạng trên AWS. - Học các thành phần chính của VPC: Subnet, Route Table, Internet Gateway, NAT Gateway, VPN Gateway. - Tìm hiểu bảo mật mạng với Security Group và Network ACL. - Thực hành triển khai EC2 vào public và private subnet. - Học và thực hành thiết lập kết nối Site-to-Site VPN giữa on-premises và AWS VPC. - Ôn lại best practices trong việc chia subnet, phân tầng mạng và giám sát lưu lượng với VPC Flow Logs. 11/09/2025 11/09/2025 Giới thiệu Amazon VPC Network Security với Security Group và NACL Triển khai EC2 Instance Thiết lập AWS Site-to-Site VPN Sáu - Tìm hiểu tổng quan về Amazon Elastic Compute Cloud (Amazon EC2) và các use case phổ biến. - Ôn lại các yêu cầu trước khi dùng EC2: key pair, security group, cấu hình mạng. - Thực hành tạo EC2 Windows và kết nối qua RDP. - Thực hành tạo EC2 Linux và kết nối qua SSH. - Thử các thao tác EC2 cơ bản: start, stop, reboot, đổi instance type, quản lý volume. - Triển khai ứng dụng mẫu AWS User Management trên cả EC2 Linux và Windows bằng Node.js. - Ôn lại cách quản lý chi phí và sử dụng EC2, dọn dẹp tài nguyên sau khi lab để tránh phát sinh thêm chi phí. 12/09/2025 12/09/2025 Giới thiệu Amazon EC2 Các bước chuẩn bị Khởi tạo Windows instance Khởi tạo Linux instance Amazon EC2 cơ bản Triển khai ứng dụng Node.js trên EC2 Kết quả đạt được trong tuần 1 Xây dựng và bảo vệ thành công một tài khoản AWS mới, bao gồm bật MFA, tạo user/admin IAM và làm quen với quy trình hỗ trợ của AWS. Nắm được nền tảng quản lý chi phí trên AWS thông qua việc tạo và kiểm thử nhiều loại AWS Budgets với cảnh báo qua email. Củng cố kiến thức về bảo mật và quản trị truy cập với IAM (user, group, role, policy) theo nguyên tắc least privilege. Thiết kế và vận hành được mạng cơ bản trên AWS với Amazon VPC, gồm public/private subnet, security group, NACL và kết nối Site-to-Site VPN. Triển khai và quản lý được EC2 Windows và Linux, biết cách kết nối RDP/SSH và thực hiện các thao tác vận hành thường gặp. Triển khai thành công ứng dụng quản lý người dùng mẫu trên EC2 và luyện thói quen dọn dẹp tài nguyên sau lab để kiểm soát chi phí. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Triển khai kiến trúc hướng sự kiện với Amazon DynamoDB bởi Aman Dhingra, Jack Le Bon và Lee Hannigan | ngày 25 tháng 9 năm 2025 | trong Advanced (300), Amazon DynamoDB, Amazon EventBridge, AWS Lambda, Serverless, Technical How-to\nEvent-driven architectures﻿ là lựa chọn phổ biến của khách hàng để tích hợp các dịch vụ AWS khác nhau và các hệ thống không đồng nhất. Những kiến trúc này có thể giúp giảm chi phí, mở rộng và thất bại các thành phần một cách độc lập, đồng thời hỗ trợ xử lý song song. Đối với các ứng dụng sử dụng DynamoDB, một số có thể cần các chức năng Time-to-Live﻿ (TTL) nâng cao hơn, trong khi những ứng dụng khác yêu cầu khả năng kích hoạt các hành động downstream﻿, chẳng hạn như gửi email nhắc nhở cho các sự kiện được quản lý bởi ứng dụng. Dù bạn cần loại bỏ dữ liệu ngay lập tức hay kiểm soát chính xác việc lên lịch các sự kiện tương lai, kiến trúc hướng sự kiện có thể giúp bạn đạt được những mục tiêu này một cách hiệu quả.\nTrong loạt bài ba phần này, chúng tôi khám phá các cách tiếp cận để triển khai các patterns﻿ sự kiện nâng cao cho các ứng dụng được hỗ trợ bởi DynamoDB. Dưới đây là cái nhìn sơ lược về các chủ đề chúng tôi sẽ đề cập:\nPhần 1: Tận dụng Amazon EventBridge Scheduler để loại bỏ dữ liệu chính xác – Khám phá cách sử dụng EventBridge Scheduler để quản lý và loại bỏ dữ liệu từ DynamoDB một cách hiệu quả với độ chính xác gần thời gian thực.\nPhần 2: Sử dụng Global Secondary Index chuyên dụng để quản lý dữ liệu nghiêm ngặt – Tìm hiểu về việc tạo Global Secondary Index (GSI) chuyên biệt để kiểm soát chính xác việc loại bỏ và quản lý dữ liệu.\nPhần 3: Triển khai Amazon EventBridge Scheduler để lên lịch sự kiện chi tiết – Khám phá cách EventBridge Scheduler có thể cho phép lên lịch chi tiết các sự kiện downstream﻿, cho phép quản lý sự kiện tương lai chính xác.\nTrong bài viết này (Phần 1), chúng tôi tập trung vào việc cải thiện chức năng TTL bản địa của DynamoDB bằng cách triển khai loại bỏ dữ liệu gần thời gian thực sử dụng EventBridge Scheduler, giảm thời gian điển hình để xóa các items﻿ hết hạn từ vài ngày xuống dưới một phút.\nDynamoDB Time-to-Live: Chức năng bản địa và Hạn chế Time to Live﻿ (TTL), một chức năng bản địa trong DynamoDB, cho phép bạn định nghĩa thời gian hết hạn cụ thể cho các items﻿ trong bảng. Khi TTL được kích hoạt và một attribute﻿ hết hạn được đặt cho một item﻿, DynamoDB tự động loại bỏ item﻿ đó khỏi bảng khi thời gian hết hạn được đạt tới. Tính năng này thường được sử dụng để quản lý dữ liệu có thời gian sống hạn chế, chẳng hạn như records﻿ session﻿ tạm thời, thông tin được cache﻿, hoặc dữ liệu nhạy cảm thời gian khác. Với TTL, bạn có thể tự động hóa quá trình dọn dẹp dữ liệu, tối ưu hóa quản lý dữ liệu, chi phí và hiệu quả lưu trữ.\nĐể sử dụng TTL bản địa, bạn phải kích hoạt nó trên bảng và chỉ định một attribute﻿ sẽ chứa thời gian hết hạn cho mỗi item﻿. Attribute﻿ này phải ở định dạng thời gian Unix epoch﻿. TTL bản địa không tiêu thụ write throughput﻿ trên bảng của bạn và không phát sinh chi phí bổ sung trừ trường hợp global tables﻿, nơi việc xóa TTL trên vùng nguồn không phát sinh chi phí, nhưng việc xóa được replicate﻿ sang các bảng replica﻿ khác tiêu thụ write throughput﻿.\nTuy nhiên, mặc dù tính năng TTL bản địa hiệu quả trong việc tự động hết hạn các items﻿, độ trễ vốn có lên đến vài ngày trước khi xóa có thể không phù hợp với yêu cầu quản lý dữ liệu hoặc tuân thủ của mọi ứng dụng. Sự khác biệt này trở nên đặc biệt liên quan đối với các hệ thống yêu cầu loại bỏ dữ liệu nhanh chóng và chính xác, chẳng hạn như các nền tảng thương mại điện tử cần cập nhật hàng tồn kho nhanh chóng hoặc các session﻿ người dùng động yêu cầu theo dõi thời gian thực chính xác. Item﻿ sẽ tiếp tục xuất hiện trong kết quả query﻿ cho đến khi việc xóa được thực hiện. Một entry﻿ sẽ xuất hiện trong bất kỳ change stream﻿ nào được cấu hình khi việc xóa xảy ra.\nTổng quan Giải pháp: TTL Gần Thời gian Thực với EventBridge Scheduler Để giải quyết những trường hợp sử dụng nhạy cảm thời gian này, chúng ta có thể tích hợp EventBridge Scheduler để thực thi việc loại bỏ items﻿ kịp thời trong vòng 1-2 phút, cung cấp một giải pháp ngay lập tức và có thể dự đoán hơn cho các ứng dụng yêu cầu hết hạn dữ liệu nhanh chóng.\nLợi ích của TTL Gần Thời gian Thực Độ chính xác gần thời gian thực: Đảm bảo dữ liệu không còn cần thiết được loại bỏ kịp thời, điều này quan trọng đối với các ứng dụng như thương mại điện tử nơi mức hàng tồn kho chính xác là quan trọng để ngăn chặn bán quá mức hoặc bán thiếu sản phẩm.\nTrải nghiệm người dùng nâng cao: Loại bỏ ngay lập tức dữ liệu session﻿ hết hạn đảm bảo người dùng tương tác với thông tin hiện tại nhất, cung cấp trải nghiệm tốt hơn và ngay lập tức.\nThông báo kịp thời: Hỗ trợ thực thi bất kỳ quy trình phụ thuộc nào dựa vào việc hết hạn dữ liệu, chẳng hạn như timeout﻿ session﻿ hoặc quyền truy cập tạm thời, được thực thi chính xác khi cần thiết.\nTối ưu hóa sử dụng tài nguyên: Kịp thời giải phóng không gian lưu trữ bằng cách loại bỏ dữ liệu hết hạn, giảm chi phí liên quan đến lưu trữ thông tin lỗi thời.\nQuản lý dữ liệu được cải thiện: Chỉ dữ liệu liên quan và hiện tại được giữ lại, đơn giản hóa quản lý dữ liệu và làm cho việc duy trì tính toàn vẹn dữ liệu dễ dàng hơn.\nKiến trúc Giải pháp Sơ đồ sau minh họa kiến trúc giải pháp của chúng tôi:\nGiải pháp chứa các thành phần chính sau:\nAmazon DynamoDB – Cơ sở dữ liệu NoSQL phân tán, serverless﻿, được quản lý hoàn toàn này được thiết kế để chạy các ứng dụng hiệu suất cao ở bất kỳ quy mô nào. Bảng phải chứa một attribute﻿ cho biết thời gian hết hạn item﻿.\nDynamoDB Streams – Chức năng bản địa này ghi lại một chuỗi theo thứ tự thời gian các sửa đổi cấp item﻿ trong Bảng DynamoDB của bạn. Những sửa đổi này bao gồm các hoạt động Insert﻿, Update﻿ và Delete﻿.\nAWS Lambda – Dịch vụ tính toán serverless﻿ này cho phép bạn chạy mã mà không cần cung cấp hoặc quản lý servers﻿.\nAmazon EventBridge Scheduler – Scheduler﻿ serverless﻿ này cho phép bạn tạo, chạy và quản lý các tasks﻿ từ một dịch vụ được quản lý tập trung.\nCách thức Hoạt động Đối với mỗi item﻿ DynamoDB có giá trị TTL, chúng ta liên kết một one-time invocation﻿ schedule﻿ trong EventBridge Scheduler. One-time invocation﻿ được lên lịch để kích hoạt cùng lúc với giá trị TTL của DynamoDB Item.\nMỗi schedule﻿ phải bao gồm một target﻿ để được sử dụng khi schedule﻿ được gọi. Chúng ta sẽ sử dụng Universal Target﻿ để gọi trực tiếp DynamoDB DeleteItem API﻿, loại bỏ item﻿ khỏi bảng. Tích hợp trực tiếp với DynamoDB hiệu quả về chi phí hơn so với việc gọi Lambda để thực hiện việc xóa.\nLuồng hoạt động như sau:\nKhi một record﻿ được thêm, sửa đổi hoặc loại bỏ khỏi bảng DynamoDB, một stream record﻿ được tạo trong DynamoDB Stream liên quan.\nDynamoDB Stream gọi một function﻿ Lambda xử lý stream event﻿.\nFunction﻿ Lambda trích xuất primary key﻿ và giá trị TTL của item﻿, sau đó tạo, cập nhật hoặc xóa schedule﻿ EventBridge tương ứng.\nEventBridge Schedule được cấu hình để gọi DynamoDB DeleteItem API tại thời gian TTL được chỉ định, loại bỏ item﻿ khỏi bảng.\nSchedule﻿ tự động xóa chính nó sau khi hoàn thành thành công.\nEventBridge Schedule liên quan đến một item﻿ được đặt để kích hoạt tại thời gian TTL item﻿ được chỉ định. Các schedule﻿ có ngày trong tương lai thường sẽ kích hoạt trong vòng một phút từ thời gian schedule﻿ khi không sử dụng tính năng flexible time window﻿.\nĐiều kiện Tiên quyết Trước khi triển khai giải pháp này, bạn nên có:\nTài khoản AWS – Truy cập vào tài khoản AWS đang hoạt động để kiểm tra giải pháp\nKiến thức cơ bản DynamoDB – Hiểu biết nền tảng về các khái niệm DynamoDB\nFunctions﻿ Lambda – Quen thuộc với Lambda để xử lý các events﻿ DynamoDB Streams\nKiến thức cơ bản EventBridge – Kiến thức cơ bản về EventBridge để thiết lập scheduler rules﻿\nThành thạo AWS CLI hoặc console﻿ – Để cấu hình dịch vụ và giám sát logs﻿. Chúng tôi sử dụng AWS Management Console trong suốt bài viết này.\nCác Bước Triển khai Đầu tiên, bạn tạo một bảng DynamoDB với DynamoDB Streams được kích hoạt:\nTrên DynamoDB console, chọn Tables trong navigation pane﻿.\nChọn Create table.\nĐối với Table name, nhập tên cho bảng mới của bạn (chẳng hạn: TTL-table).\nĐối với Partition key, nhập PK làm tên và chọn String làm loại.\nĐối với Sort key, nhập SK làm tên và chọn String làm loại.\nĐể tất cả các cấu hình khác ở mặc định và chọn Create table.\nChọn Tables trong navigation pane﻿ và mở chi tiết bảng của bạn.\nTrên tab Exports and streams, dưới DynamoDB stream details, chọn Turn on.\nTrong wizard﻿ Turn on DynamoDB stream, chọn New and old images, sau đó chọn Turn on stream. Bây giờ bạn sẽ thấy chi tiết DynamoDB stream, với \u0026ldquo;Stream Status\u0026rdquo; được đặt thành \u0026ldquo;On\u0026rdquo;. Hãy chắc chắn ghi chú \u0026ldquo;Latest stream ARN\u0026rdquo;, bạn sẽ cần nó sau này. Điều này sẽ kích hoạt DynamoDB Streams trên bảng để hiển thị cả trạng thái cũ và mới của các items﻿ trong stream records﻿, vì vậy bạn có thể quản lý các cập nhật về giá trị TTL của items﻿. Tiếp theo, chúng ta tạo function﻿ Lambda được gọi bởi DynamoDB Stream.\nCấu hình Quyền IAM EventBridge Scheduler cần quyền thích hợp để gọi DynamoDB DeleteItem API. Tạo một role﻿ IAM với trust policy﻿ sau:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;scheduler.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } } Và đính kèm một policy﻿ với các quyền sau:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:\\[REGION\\_NAME\\]:\\[ACCOUNT\\_ID\\]:table/\\[TABLE\\_NAME\\]\u0026#34; } } Ghi chú ARN cho role﻿ này, vì chúng ta sẽ cần nó sau này.\nTạo Lambda function\nLambda function có trách nhiệm cấu hình EventBridge Scheduler để thực hiện việc xóa chọn lọc các item cụ thể từ DynamoDB table:\nTrên Lambda console, chọn mục Functions trong menu điều hướng.\nChọn Create function.\nChọn Author from scratch.\nVới trường Function name, nhập tên (ví dụ: DDBStreamTriggerEventScheduler).\nChọn một Runtime. Bài viết sử dụng Python 3.11, nhưng bạn có thể chọn bất kỳ runtime nào quen thuộc.\nThêm vào Lambda execution role hai policy IAM là AWSLambdaDynamoDBExecutionRole và một inline policy có quyền scheduler:CreateSchedule.\nChọn Create function.\nBấm vào tab Configuration của Lambda Function và chọn bảng Permissions.\nTrong phần Execution role, nhấn vào Role name liên kết. Tên này thường có dạng như YourLambdaFunctionName-Role-abc.\nChọn Add permissions, sau đó chọn Create inline policy\nChuyển từ giao diện Visual sang JSON và thêm chính sách sau, cấp quyền cho Lambda function truy cập DynamoDB Stream (nhớ nhập ARN DynamoDB Stream đã note trước đó) và tạo, cập nhật, xóa EventBridge Schedules:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBStreamAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;[Your DynamoDB Stream ARN]\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBListStreams\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:ListStreams\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;EventBridgeSchedulerAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;scheduler:CreateSchedule\u0026#34;, \u0026#34;scheduler:UpdateSchedule\u0026#34;, \u0026#34;scheduler:DeleteSchedule\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:scheduler:*:*:schedule/default/dynamodb_ttl_*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;PassRoleToScheduler\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;iam:PassRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: \u0026#34;scheduler.amazonaws.com\u0026#34; } } } ] } Chọn Next.\nNhập Policy name, ví dụ: AWSLambdaToEventBridgeScheduler.\nChọn Create policy.\nQuay lại DynamoDB console, chọn Tables ở menu và chọn bảng vừa tạo (TTL-Table).\nChuyển sang tab Exports and streams.\nỞ vùng Trigger, nhấn Create trigger.\nTại phần AWS Lambda function details, chọn Lambda function vừa tạo (DDBStreamTriggerEventScheduler).\nChọn Create trigger.\nQuay lại Lambda console, chọn Functions ở menu, tìm và chọn Lambda function vừa tạo.\nTại tab Code của Lambda function, thêm mã code phù hợp.\nCode Mẫu Lambda Function (Python)\nimport json import datetime import boto3 import os import logging logger = logging.getLogger() logger.setLevel(logging.INFO) ROLE_ARN = os.environ.get(\u0026#39;SCHEDULER_ROLE_ARN\u0026#39;) TABLE_NAME = os.environ.get(\u0026#39;DYNAMODB_TABLE_NAME\u0026#39;) TIMEZONE = os.environ.get(\u0026#39;TIMEZONE\u0026#39;, \u0026#39;UTC\u0026#39;) scheduler_client = boto3.client(\u0026#39;scheduler\u0026#39;) def lambda_handler(event, context): try: if not event.get(\u0026#39;Records\u0026#39;): logger.error(\u0026#34;No records found in the event\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;No records found in the event\u0026#39;) } for record in event[\u0026#39;Records\u0026#39;]: process_record(record) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;DynamoDB near-real time TTL operations completed successfully.\u0026#39;) } except Exception as e: logger.error(f\u0026#34;Error processing event: {str(e)}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps(f\u0026#39;Error: {str(e)}\u0026#39;) } def process_record(record): try: event_name = record.get(\u0026#39;eventName\u0026#39;) if event_name == \u0026#34;INSERT\u0026#34;: handle_insert(record) elif event_name == \u0026#34;MODIFY\u0026#34;: handle_modify(record) elif event_name == \u0026#34;REMOVE\u0026#34;: handle_remove(record) else: logger.warning(f\u0026#34;Unhandled event type: {event_name}\u0026#34;) except Exception as e: logger.warning(f\u0026#34;Error processing record: {str(e)}\u0026#34;) raise def handle_insert(record): keys = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;Keys\u0026#39;] pk = keys[\u0026#39;PK\u0026#39;][\u0026#39;S\u0026#39;] sk = keys[\u0026#39;SK\u0026#39;][\u0026#39;S\u0026#39;] ttl_value = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;][\u0026#39;ttl\u0026#39;][\u0026#39;N\u0026#39;] epoch_dt = datetime.datetime.fromtimestamp(int(ttl_value)) logger.info(f\u0026#34;Creating schedule for item {pk}#{sk} with TTL at {epoch_dt}\u0026#34;) scheduler_client.create_schedule( ActionAfterCompletion=\u0026#34;DELETE\u0026#34;, FlexibleTimeWindow={\u0026#34;Mode\u0026#34;: \u0026#34;OFF\u0026#34;}, Name=f\u0026#34;dynamodb_ttl_{pk}_{sk}\u0026#34;, ScheduleExpression=f\u0026#34;at({epoch_dt.strftime(\u0026#39;%Y-%m-%dT%H:%M:%S\u0026#39;)})\u0026#34;, ScheduleExpressionTimezone=TIMEZONE, Target={ \u0026#34;RoleArn\u0026#34;: ROLE_ARN, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:scheduler:::aws-sdk:dynamodb:deleteItem\u0026#34;, \u0026#34;Input\u0026#34;: json.dumps({\u0026#34;Key\u0026#34;: {\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: pk}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: sk}}, \u0026#34;TableName\u0026#34;: TABLE_NAME}) } ) def handle_modify(record): if \u0026#39;OldImage\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;] or \u0026#39;NewImage\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;]: return if \u0026#39;ttl\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;][\u0026#39;OldImage\u0026#39;] or \u0026#39;ttl\u0026#39; not in record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;]: return keys = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;Keys\u0026#39;] pk = keys[\u0026#39;PK\u0026#39;][\u0026#39;S\u0026#39;] sk = keys[\u0026#39;SK\u0026#39;][\u0026#39;S\u0026#39;] old_ttl = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;OldImage\u0026#39;][\u0026#39;ttl\u0026#39;][\u0026#39;N\u0026#39;] new_ttl = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;][\u0026#39;ttl\u0026#39;][\u0026#39;N\u0026#39;] if old_ttl != new_ttl: epoch_dt = datetime.datetime.fromtimestamp(int(new_ttl)) logger.info(f\u0026#34;Updating schedule for item {pk}#{sk} with new TTL at {epoch_dt}\u0026#34;) try: scheduler_client.update_schedule( Name=f\u0026#34;dynamodb_ttl_{pk}_{sk}\u0026#34;, FlexibleTimeWindow={\u0026#34;Mode\u0026#34;: \u0026#34;OFF\u0026#34;}, ScheduleExpression=f\u0026#34;at({epoch_dt.strftime(\u0026#39;%Y-%m-%dT%H:%M:%S\u0026#39;)})\u0026#34;, ScheduleExpressionTimezone=TIMEZONE, Target={ \u0026#34;RoleArn\u0026#34;: ROLE_ARN, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:scheduler:::aws-sdk:dynamodb:deleteItem\u0026#34;, \u0026#34;Input\u0026#34;: json.dumps({\u0026#34;Key\u0026#34;: {\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: pk}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: sk}}, \u0026#34;TableName\u0026#34;: TABLE_NAME}) } ) except scheduler_client.exceptions.ResourceNotFoundException: handle_insert(record) def handle_remove(record): keys = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;Keys\u0026#39;] pk = keys[\u0026#39;PK\u0026#39;][\u0026#39;S\u0026#39;] sk = keys[\u0026#39;SK\u0026#39;][\u0026#39;S\u0026#39;] logger.info(f\u0026#34;Deleting schedule for item {pk}#{sk}\u0026#34;) try: scheduler_client.delete_schedule(Name=f\u0026#39;dynamodb_ttl_{pk}_{sk}\u0026#39;) except scheduler_client.exceptions.ResourceNotFoundException: pass Chọn Deploy để cập nhật mã function mới nhất.\nCuối cùng, thêm tên DynamoDB table và ARN của EventBridge Scheduler role vào biến môi trường của Lambda Function. Vào tab Configuration và phần Environment variables.\nChọn Edit.\nChọn Add environment variable rồi nhập:\nKey: DYNAMODB_TABLE_NAME\nValue: Tên bảng của bạn (ví dụ TTL-Table)\nChọn Add environment variable một lần nữa, rồi nhập:\nKey: SCHEDULER_ROLE_ARN\nValue: ARN của scheduler role đã ghi chú trước đó (dạng arn:aws:iam::****:role/eventbridge_scheduler_role)\nChọn Save Kiểm tra Giải pháp Bạn có thể kiểm tra giải pháp bằng cách thêm các items﻿ vào bảng DynamoDB của bạn với giá trị TTL. Dưới đây là ví dụ tạo 10 items﻿ mẫu với giá trị TTL sử dụng AWS CLI:\n#!/bin/bash TABLE=\u0026#34;TTL-Table\u0026#34; for PK_VALUE in {1..10}; do ISO_TIMESTAMP_PLUS_3_MINS=$(date -v+3M -u +\u0026#34;%Y-%m-%dT%H:%M:%S\u0026#34;) aws dynamodb put-item --table-name $TABLE \\ --item \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;StaticSK\u0026#34;}, \u0026#34;REMINDER_TIMESTAMP\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$ISO_TIMESTAMP_PLUS_3_MINS\u0026#39;\u0026#34;}, \u0026#34;email\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;abc@example.com\u0026#34;}, \u0026#34;ATTR_1\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;This is a static attribute\u0026#34;}}\u0026#39; done Bạn có thể điều hướng đến tab Monitoring của nhóm lịch trình EventBridge để xem các lệnh xóa đang được thực thi. Schedule sẽ kích hoạt các thao tác vào một thời điểm cụ thể; bạn có thể quan sát các lần kích hoạt này bằng cách xem chỉ số InvocationAttemptCount. Trong trường hợp của chúng tôi, các lần kích hoạt là các lệnh xóa được thực hiện đối với bảng DynamoDB. Để xem danh sách tất cả các chỉ số có sẵn cho một nhóm lịch trình, hãy tham khảo Monitoring Amazon EventBridge Scheduler with Amazon CloudWatch﻿. Cân nhắc Chi phí Chi phí của việc sử dụng phương pháp này cho 1,000,000 mục TTL được ước tính trong bảng sau đây cùng với so sánh với việc sử dụng chức năng DynamoDB gốc. Mỗi mục DynamoDB có kích thước dưới 1KB và được lưu trữ trong bảng sử dụng chế độ on-demand tại vùng us-east-1. Các tầng miễn phí không được xem xét trong phân tích này.\nTTL gần thời gian thực TTL DynamoDB bản địa DynamoDB Stream $0 (DynamoDB streams miễn phí khi được tiêu thụ bởi Lambda) - Lambda EventBridge Scheduler $1 - DynamoDB Delete $0.63 - Tổng Chi phí $1.63 $0 Hạn chế Giới hạn trên cho giải pháp này liên quan đến hạn mức tốc độ yêu cầu của EventBridge Scheduler. Các yêu cầu CreateSchedule, UpdateSchedule và DeleteSchedule mặc định đều có giới hạn tối đa là 1.000 yêu cầu mỗi giây đối với hầu hết các khu vực. Các giới hạn này có thể điều chỉnh được. Nếu giới hạn này bị vượt quá, EventBridge Scheduler sẽ từ chối mọi yêu cầu cho thao tác đó trong khoảng thời gian còn lại. Dead-Letter Queue - DLQ có thể được sử dụng để bắt và thực hiện lại các lần thực thi thất bại.\nEventBridge Scheduler cũng áp dụng một giới hạn điều tiết (throttle limit) đối với lượt gọi mục tiêu (target invocations) đồng thời, mặc định là 1.000 lượt gọi mỗi giây ở hầu hết các khu vực. Điều này đề cập đến tốc độ mà các schedule payloads được gửi đến các mục tiêu của chúng. Nếu giới hạn này bị vượt quá, các lượt gọi sẽ không bị hủy bỏ mà bị điều tiết (throttled), nghĩa là chúng sẽ bị trì hoãn và được xử lý sau. Hạn mức (quota) này có thể điều chỉnh và có thể mở rộng lên đến hàng chục nghìn lượt gọi mỗi giây.\nCuối cùng, một giới hạn trên khác đối với giải pháp này sẽ là hạn mức thực thi đồng thời (concurrent executions quota) có sẵn cho các Lambda function của bạn, mặc định là 1.000 mỗi giây cho mỗi tài khoản. Đây là một giới hạn quan trọng cần xem xét, đặc biệt nếu bạn có các Lambda function khác đang chạy trong cùng một tài khoản. Nếu bạn đạt đến giới hạn đồng thời (concurrency limit), function của bạn sẽ bị điều tiết (throttled). Giới hạn này có thể được tăng lên.\nDọn dẹp Nếu bạn tạo môi trường kiểm tra để theo dõi bài viết này, hãy chắc chắn:\nXóa DynamoDB table\nXóa﻿ Lambda function\nXóa EventBridge schedule\nXóa bất kỳ roles﻿ IAM nào được tạo trong quá trình này\nXóa bất kỳ tài nguyên nào khác bạn đã tạo để kiểm tra giải pháp\nKết luận Trong bài viết này, chúng tôi đã khám phá cách bạn có thể sử dụng Amazon EventBridge Scheduler để triển khai TTL gần thời gian thực cho DynamoDB, giảm thời gian xóa một item﻿ sau khi TTL hết hạn từ vài ngày xuống thường dưới 1-2 phút.\nGiải pháp serverless﻿ này thu hẹp khoảng cách giữa khả năng tích hợp sẵn của DynamoDB và nhu cầu loại bỏ items﻿ ngay lập tức, có kiểm soát. Mặc dù nó phát sinh một số chi phí bổ sung so với chức năng TTL bản địa, nó giải quyết hiệu quả nhu cầu loại bỏ dữ liệu nhanh chóng và đáng tin cậy.\nCách tiếp cận này có thể mở rộng đến hàng tỷ records﻿ xóa TTL hoạt động, với thời gian xóa tăng lên khi việc xóa đồng thời mở rộng vượt quá giới hạn gọi EventBridge Scheduler.\nTrong Phần 2, chúng tôi sẽ đi sâu hơn vào việc triển khai loại bỏ dữ liệu nghiêm ngặt trong DynamoDB sử dụng Global Secondary Index. Loạt bài kết thúc với Phần 3, nơi chúng tôi sẽ sử dụng Amazon EventBridge Scheduler để lên lịch sự kiện chi tiết. Những patterns﻿ hướng sự kiện này sẽ giúp bạn tự động hóa các quy trình chính, duy trì dữ liệu chính xác và đáp ứng các yêu cầu ứng dụng chính xác với nỗ lực thủ công tối thiểu.\nVề các tác giả\nLee Hannigan Lee Hannigan là Chuyên gia giải pháp DynamoDB cao cấp (Sr. DynamoDB Specialist Solutions Architect) làm việc tại Donegal, Ireland. Anh có chuyên môn sâu rộng về các hệ thống phân tán (distributed systems), cùng nền tảng vững chắc về các công nghệ dữ liệu lớn (big data) và phân tích (analytics technologies). Trong vai trò Chuyên gia giải pháp DynamoDB, Lee xuất sắc trong việc hỗ trợ khách hàng thiết kế, đánh giá và tối ưu hóa khối lượng công việc (workloads) sử dụng các khả năng của DynamoDB. Aman Dhingra Aman Dhingra là Chuyên gia giải pháp DynamoDB cao cấp (Sr. DynamoDB Specialist Solutions Architect) làm việc tại Dublin, Ireland. Anh có đam mê về các hệ thống phân tán (distributed systems) và nền tảng chuyên sâu về dữ liệu lớn \u0026amp; phân tích (big data \u0026amp; analytics). Aman là tác giả của cuốn \u0026ldquo;Amazon DynamoDB – The Definitive Guide\u0026rdquo; và hỗ trợ khách hàng trong việc thiết kế, đánh giá và tối ưu hóa khối lượng công việc vận hành trên Amazon DynamoDB. Jack Le Bon Jack Le Bon là Kiến trúc sư giải pháp (Solutions Architect) làm việc tại London, chuyên hỗ trợ các khách hàng thuộc lĩnh vực truyền thông và giải trí (Media \u0026amp; Entertainment). Là thành viên của nhóm chuyên về công nghệ không máy chủ (Serverless speciality group) tại AWS, Jack giúp khách hàng thiết kế và triển khai kiến trúc hướng sự kiện (event-driven architectures) sử dụng các công nghệ Serverless. Jack tập trung vào hỗ trợ các tổ chức xây dựng kiến trúc hiệu quả, giúp họ tập trung vào hoạt động kinh doanh cốt lõi thay vì quản lý hạ tầng. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Triển khai kiến trúc hướng sự kiện với Amazon DynamoDB – Phần 3 bởi Lee Hannigan và Aman Dhingra | vào ngày 25 tháng 9 năm 2025 | trong Advanced (300), Amazon DynamoDB, Amazon EventBridge, AWS Lambda, Serverless, Technical How-to\nỞ Phần 1, chúng ta đã tìm hiểu cách sử dụng Amazon EventBridge Scheduler để xóa dữ liệu tự động trong Amazon DynamoDB một cách chính xác. Phần 2 đã thảo luận cách sử dụng global secondary index (GSI) để quản lý dữ liệu nghiêm ngặt trong DynamoDB. Bài viết này tập trung vào việc sử dụng EventBridge Scheduler để lập lịch sự kiện chi tiết dựa trên dữ liệu ghi vào DynamoDB.\nTrong toàn bộ chuỗi bài, chúng tôi kiểm tra các chiến lược quản lý dữ liệu trong DynamoDB. Bài này chuyển sang mẫu hướng sự kiện để lên lịch hành động downstream tin cậy trong tương lai bằng EventBridge Scheduler. Một lợi thế của cách tiếp cận này là khả năng kích hoạt các sự kiện downstream quan trọng về thời gian, như gửi thông báo nhắc nhở các cuộc hẹn, hết hạn ưu đãi, hoặc gia hạn đăng ký. Ví dụ, khi đăng ký của người dùng sắp hết hạn, EventBridge Scheduler có thể kích hoạt một sự kiện gọi AWS Lambda kèm chi tiết item DynamoDB liên quan. Lambda này sau đó có thể dùng Amazon Simple Email Service (Amazon SES) để gửi thông báo kịp thời tới người dùng.\nKiến trúc này giúp người dùng nhận được nhắc nhở đúng lúc, cải thiện trải nghiệm và tăng mức độ tương tác. EventBridge Scheduler linh hoạt cho phép kiểm soát chính xác thời gian thông báo, đáp ứng nhiều bài toán kinh doanh khác nhau.\nTổng quan giải pháp Giải pháp này trình diễn cách sử dụng Amazon DynamoDB Streams và AWS Lambda để tự động lên lịch hành động trong tương lai dựa trên việc ghi item vào DynamoDB. Bằng cách nhận stream records từ các lần ghi, một hàm Lambda được kích hoạt để tạo các lịch chi tiết theo thời gian qua Amazon EventBridge Scheduler. Những lịch này sau đó có thể gọi các dịch vụ downstream như Amazon SES để gửi email nhắc nhở, Amazon Simple Queue Service (Amazon SQS), AWS Step Functions hoặc các dịch vụ AWS khác, cho phép quy trình hướng sự kiện có tính mở rộng, tin cậy cao.\nSơ đồ sau minh họa kiến trúc giải pháp.\nMột trường hợp phổ biến cho mẫu này là lập lịch các sự kiện trong tương lai như nhắc nhở cuộc hẹn, hết hạn ưu đãi, hoặc gia hạn đăng ký với độ tin cậy cao. EventBridge Scheduler cho phép lập lịch hành động một lần hoặc lặp lại dựa trên thuộc tính lưu trong các item DynamoDB. Luồng hoạt động như sau:\nGhi dữ liệu – Khi một item được ghi lên DynamoDB table, một bản ghi stream ứng sẽ được tạo trong DynamoDB stream được liên kết của nó.\nKích hoạt – Bản ghi stream này, riêng lẻ hoặc trong batch, sẽ kích hoạt một AWS Lambda function.\nTạo lịch – Lambda function dùng EventBridge Scheduler để lên lịch trong tương lai. Lịch bao gồm timestamp chính xác và dữ liệu item liên quan.\nKích hoạt mục tiêu – Đến thời gian đã định, EventBridge Scheduler gọi mục tiêu cấu hình, ví dụ gửi email với Amazon SES, đưa message vào SQS, hoặc bắt đầu thực thi Step Functions.\nKiến trúc này được thiết kế để mở rộng theo dữ liệu, cho phép lập lịch logic chính xác mà không làm phức tạp mô hình dữ liệu DynamoDB hoặc cần polling liên tục. Hãy tham khảo các bước áp dụng giải pháp.\nYêu cầu trước Trước khi áp dụng giải pháp hướng sự kiện, bạn cần phải có các yêu cầu sau:\nTài khoản AWS – Truy cập một tài khoản AWS đang hoạt động.\nKiến thức cơ bản về DynamoDB – Hiểu về khái niệm DynamoDB: bảng, item, thuộc tính, thao tác CRUD cơ bản là cần thiết để cấu hình và quản lý cơ sở dữ liệu một cách hiệu quả.\nLambda functions – Thành thạo Lambda vì bạn sẽ tạo và triển khai Lambda function để xử lý sự kiện Amazon DynamoDB Streams và tạo lịch qua EventBridge Scheduler.\nEventBridge Scheduler – Kiến thức cơ bản về Amazon EventBridge là cần thiết cho việc cấu hình EventBridge Scheduler rule để gọi API cụ thể.\nAmazon SES – Kiến thức cơ bản về Amazon SES và xác thực email người gửi. Để tạo và xác thực địa chỉ email, xem tại Creating and verifying identities in Amazon SES.\nThành thạo AWS CLI hoặc console – Thành thạo dùng AWS Command Line Interface (AWS CLI) hoặc AWS Management Console cho việc cấu hình dịch vụ, tạo resource và giám sát log.\nTạo bảng DynamoDB Hoàn thành các bước sau để tạo DynamoDB table:\nỞ DynamoDB console, chọn Tables ở thanh điều hướng.\nChọn Create table.\nVói tên Table, nhập tên table của bạn.\nVới Partition key, nhập PK làm tên, chọn kiểu String làm kiểu dữ liệu.\nVới Sort key, nhập SK làm tên, chọn kiểu String làm kiểu dữ liệu.\nĐể mặc định các cấu hình khác, chọn Create table. Bảng sẽ tạo sau vài giây.\nVào lại Tables, mở bảng vừa tạo.\nTrong mục DynamoDB stream details, chọn Turn on.\nChọn New and old images, sau đó chọn Turn on stream. Điều này sẽ cho phép Luồng DynamoDB trên bảng hiển thị cả trạng thái cũ và mới của các mục trong bản ghi stream, để bạn có thể quản lý các cập nhật giá trị Time to Live (TTL) của các item.\nTạo Lambda function Hoàn thành các bước sau để tạo Lambda function:\nVào console Lambda, chọn Functions.\nChọn Create function.\nChọn Author from scratch.\nĐối với Function name, hãy nhập tên (ví dụ: DDBStreamTriggerEventScheduler).\nChọn Runtime Node.js mới nhất.\nĐối với vai trò dịch vụ Lambda mà bạn đã gắn vào function, hãy thêm chính sách được quản lý AWS Identity and Access Management (IAM) AWSLambdaDynamoDBExecutionRole và một chính sách nội tuyến có quyền lên lịch: CreateSchedule.\nChọn Create function.\nSau khi tạo Lambda function, chọn Add trigger để cấu hình event source mapping cho bảng DynamoDB.\nChọn DynamoDB làm source.\nĐối với DynamoDB table, hãy nhập ARN cho Appointment-Table.\nĐể mặc định các cấu hình còn lại, chọn Add để tạo trigger.\nỞ tab Code của Lambda function, thay code mặc định bằng đoạn mã Node.js sau. Đảm bảo cập nhật phần giữ chỗ với các giá trị thích hợp—chẳng hạn như thay thế ses-verified-email@example.com bằng địa chỉ email Amazon SES đã được xác minh của bạn. Ngoài ra, hãy đảm bảo rằng vai trò IAM mà EventBridge Scheduler sử dụng có quyền ses:SendEmail. import { SchedulerClient, CreateScheduleCommand } from \u0026#34;@aws-sdk/client-scheduler\u0026#34;; const client = new SchedulerClient({ region: \u0026#34;eu-west-1\u0026#34; }); export const handler = async (event) =\u0026gt; { try { for (const record of event.Records) { let params = { eventID: record.eventID, sequenceNumber: record.dynamodb.SequenceNumber, email: record.dynamodb.NewImage.email.S, subject: \u0026#34;Time for your appointment\u0026#34;, reminderTS: record.dynamodb.NewImage.REMINDER_TIMESTAMP.S, // Expects ISO format }; params.body = \u0026#34;This is the email body, you have a reminder\u0026#34;; await scheduleEmail(params); } return { statusCode: 200, body: JSON.stringify(\u0026#39;Complete\u0026#39;), }; } catch (error) { console.error(\u0026#34;Error processing event: \u0026#34;, error); return { statusCode: 500, body: JSON.stringify({ message: \u0026#39;Error processing event\u0026#39;, error: error.message }), }; } }; const scheduleEmail = async (params) =\u0026gt; { try { const sesParams = { Destination: { ToAddresses: [params.email] }, Message: { Body: { Text: { Data: params.body } }, Subject: { Data: params.subject }, }, Source: \u0026#34;ses-verified-email@example.com\u0026#34;, }; const target = { RoleArn: \u0026#34;arn:aws:iam::YOUR_ACCOUNT_ID:role/YourSchedulerRole\u0026#34;, Arn: \u0026#34;arn:aws:scheduler:::aws-sdk:ses:sendEmail\u0026#34;, Input: JSON.stringify(sesParams), }; const schedulerInput = { Name: `Appointment_Reminder_${params.eventID}`, FlexibleTimeWindow: { Mode: \u0026#34;OFF\u0026#34; }, ActionAfterCompletion: \u0026#34;DELETE\u0026#34;, Target: target, ScheduleExpression: `at(${params.reminderTS})`, ClientToken: params.sequenceNumber, }; const command = new CreateScheduleCommand(schedulerInput); const result = await client.send(command); return result; } catch (error) { console.error(\u0026#34;Error scheduling email: \u0026#34;, error); throw new Error(`Failed to schedule email: ${error.message}`); } }; Chọn Deploy để triển khai code mới nhất. Mẹo: Để cải thiện độ tin cậy và khả năng theo dõi, bạn có thể định cấu hình Dead Letter Queues (DLQ) tại hai điểm trong kiến ​​trúc này. Trước tiên, bạn có thể thêm DLQ vào Lambda function sử dụng từ DynamoDB stream, thao tác này ghi lại mọi lỗi xảy ra trong khi xử lý bản ghi stream hoặc tạo lịch trình, chẳng hạn như lỗi đầu vào hoặc lỗi quyền hạn. Thứ hai, bạn có thể định cấu hình DLQ như một phần của EventBridge Scheduler target. Điều này ghi lại các lỗi xảy ra tại thời điểm thực thi, chẳng hạn như nếu Amazon SES không gửi được email hoặc dịch vụ đích không khả dụng. Việc sử dụng cả hai DLQ cho phép bạn theo dõi, phân tích và thử lại các lỗi trong toàn bộ vòng đời lập kế hoạch và phân phối.\nSinh dữ liệu mẫu để kiểm tra giải pháp Chạy lệnh AWS CLI sau để mô phỏng hoạt động ghi vào DynamoDB table của bạn. Vòng lặp này chèn 10 items mẫu vào bảng, mỗi mục có một khóa phân vùng duy nhất (PK) và một khóa sắp xếp tĩnh (SK). Mỗi mục bao gồm REMINDER_TIMESTAMP được đặt thành 3 phút kể từ thời điểm hiện tại và địa chỉ email kiểm tra. Những lần ghi này sẽ kích hoạt DynamoDB Stream, luồng này gọi Lambda function của bạn để lên lịch gửi email nhắc nhở thông qua EventBridge Scheduler. Hãy nhớ thay thế abc@example.com bằng địa chỉ email hợp lệ, đã được xác minh trong Amazon SES để quan sát toàn bộ quy trình của giải pháp.\n#!/bin/bash TABLE=\u0026#34;Appointment-Table\u0026#34; for PK_VALUE in {1..10}; do ISO_TIMESTAMP_PLUS_3_MINS=$(date -v+3M -u +\u0026#34;%Y-%m-%dT%H:%M:%S\u0026#34;) aws dynamodb put-item --table-name $TABLE \\ --item \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;StaticSK\u0026#34;}, \u0026#34;REMINDER_TIMESTAMP\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$ISO_TIMESTAMP_PLUS_3_MINS\u0026#39;\u0026#34;}, \u0026#34;email\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;abc@example.com\u0026#34;}, \u0026#34;ATTR_1\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;This is a static attribute\u0026#34;}}\u0026#39; done Để theo dõi các email nhắc nhở đang được gửi, hãy điều hướng đến Monitoring tab của EventBridge schedule group. Bạn có thể xem các sự kiện được EventBridge Scheduler gọi vào một thời điểm cụ thể bằng cách xem số liệu InvocationAttemptCount. Trong trường hợp của chúng ta, lời gọi là các email nhắc nhở cuộc hẹn tới người dùng thông qua Amazon SES. Để có danh sách tất cả số liệu có sẵn cho một schedule group, tham khảo Monitoring Amazon EventBridge Scheduler with Amazon CloudWatch.\nDọn dẹp Nếu bạn dựng môi trường test theo bài viết, nhớ xoá DynamoDB table, Lambda function, EventBridge schedule và các resource khác đã tạo để tiết kiệm chi phí.\nTóm tắt Trong bài viết này, chúng ta đã được trình bày cách dùng EventBridge Scheduler để lập lịch sự kiện chi tiết dựa trên dữ liệu ghi ở DynamoDB. Giải pháp này cho phép bạn thực hiện các hành động chính xác, kịp thời dựa trên dấu thời gian được lưu trữ trong DynamoDB items khi bạn muốn gửi thông báo có giới hạn thời gian hoặc gọi các downstream jobs.\nTrong loạt bài gồm ba phần này, chúng ta đã khám phá cách mở rộng các khả năng gốc của Amazon DynamoDB bằng cách sử dụng các mẫu kiến ​​trúc hướng sự kiện được điều chỉnh cho phù hợp với nhu cầu trong thế giới thực:\nPhần 1: Giới thiệu giải pháp TTL gần real-time, dùng EventBridge Scheduler xóa item quá hạn bằng độ chính xác cao hơn TTL gốc.\nPhần 2: Trình bày cách xây dựng giải pháp quản lý dữ liệu nghiêm ngặt bằng cách sử dụng sharded global secondary index (GSI), EventBridge Scheduler và Lambda để truy vấn định kỳ và loại bỏ các bản ghi đã hết hạn.\nPhần 3: Tập trung vào việc sử dụng DynamoDB Streams và EventBridge Scheduler để lên lịch các hành động xuôi dòng trong tương lai dựa trên dữ liệu được ghi vào DynamoDB table, chẳng hạn như gửi email nhắc nhở cho các cuộc hẹn sắp tới.\nĐể tìm hiểu sâu hơn và khám phá thêm best practice thiết kế với DynamoDB, EventBridge tại tài liệu Amazon DynamoDB và tài liệu Amazon EventBridge.\nVề các tác giả\nLee Hannigan Lee Hannigan là Chuyên gia giải pháp DynamoDB cao cấp (Sr. DynamoDB Specialist Solutions Architect) làm việc tại Donegal, Ireland. Anh có chuyên môn sâu rộng về các hệ thống phân tán (distributed systems), cùng nền tảng vững chắc về các công nghệ dữ liệu lớn (big data) và phân tích (analytics technologies). Trong vai trò Chuyên gia giải pháp DynamoDB, Lee xuất sắc trong việc hỗ trợ khách hàng thiết kế, đánh giá và tối ưu hóa khối lượng công việc (workloads) sử dụng các khả năng của DynamoDB. Aman Dhingra Aman Dhingra là Chuyên gia giải pháp DynamoDB cao cấp (Sr. DynamoDB Specialist Solutions Architect) làm việc tại Dublin, Ireland. Anh có đam mê về các hệ thống phân tán (distributed systems) và nền tảng chuyên sâu về dữ liệu lớn \u0026amp; phân tích (big data \u0026amp; analytics). Aman là tác giả của cuốn \u0026ldquo;Amazon DynamoDB – The Definitive Guide\u0026rdquo; và hỗ trợ khách hàng trong việc thiết kế, đánh giá và tối ưu hóa khối lượng công việc vận hành trên Amazon DynamoDB. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.1-create-iam-role-and-policy-for-lambda/","title":"Cài đặt IAM Role và Policy cho Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt IAM Role và Policy cho Lambda.\nTạo IAM Role cho Lambda Mở IAM Console\nĐiều hướng tới https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Services → IAM Create Role:\nChọn tùy chọn Role trên menu bên trái. Sau đó nhấn Create role. Chọn trusted entity:\nTrusted entity type: AWS Service Use case: Lambda Nhấn \u0026ldquo;Next\u0026rdquo; Đính kèm permissions policies:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập dashboard-query-role Description: Nhập Execution role for Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AthenaActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;athena:StartQueryExecution\u0026#34;, \u0026#34;athena:GetQueryExecution\u0026#34;, \u0026#34;athena:GetQueryResults\u0026#34;, \u0026#34;athena:StopQueryExecution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;GlueCatalogRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:GetDatabase\u0026#34;, \u0026#34;glue:GetDatabases\u0026#34;, \u0026#34;glue:GetTable\u0026#34;, \u0026#34;glue:GetTables\u0026#34;, \u0026#34;glue:GetPartitions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3SourceAndResultAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::vel-athena-results\u0026#34;, \u0026#34;arn:aws:s3:::vel-athena-results/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty/*\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted/*\u0026#34; ] } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập lambda-query-policy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.1-setup-s3/","title":"Cài đặt S3 Bucket cho Dashboard","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một S3 để chứa các file web và folder. Quan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu (ví dụ: us-east-1) trong tất cả tên bucket.\nTên Bucket static-dashboard-bucket-ACCOUNT_ID-REGION - Lưu trữ các file web và folder đã build\nHướng dẫn tạo Bucket Mở Amazon S3 Console\nĐiều hướng tới https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo;\nCài đặt tạo Bucket:\nGiữ các cài đặt như mặc định: Bucket name: Nhập static-dashboard-bucket-ACCOUNT_ID-REGION Ví dụ: static-dashboard-bucket-123456789012-us-east-1 Ownership: ACLs disabled Block Public Access: Block all public access Bucket versioning: Disable Tags (Tùy chọn): Thêm nếu bạn muốn Encryption: SSE-S3 Bucket key: Enable Nhấn Create bucket Xác minh tạo bucket:\nBạn sẽ thấy một thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 bucket của bạn Tải lên files và folder:\nTruy cập Github để lấy nội dung web và tải lên S3 "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.9-alert-dispatch/","title":"Mã Alert Dispatch","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # ... (Code commented out, keeping as is or translating if needed, but it is commented out so skipping detailed translation for brevity unless enabled) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;🔴 CAO (HIGH)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;🟠 TRUNG BÌNH (MEDIUM)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;🔵 THẤP (LOW)\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;🚨 {sev} – {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;🚨 GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mức độ (Severity):*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Khu vực (Region):*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mô tả (Description):*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Tài khoản (Account):* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Loại (Type):* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH (CAO)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM (TRUNG BÌNH)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW (THẤP)\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;🚨 Cảnh báo GuardDuty: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Tài khoản:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Khu vực:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Loại:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Phát hiện:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Được tạo bởi AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.1-cloudtrail-etl/","title":"Mã CloudTrail ETL","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.1-cloudtrail-etl/","title":"Mã CloudTrail ETL","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.1-create-kinesis-data-firehose/","title":"Tạo Kinesis Data Firehose","tags":[],"description":"","content":"Tạo Kinesis Data Firehose Delivery Streams Tạo cloudtrail-firehose-stream Mở Kinesis Console → Delivery streams → Create delivery stream\nCấu hình:\nSource: Direct PUT Destination: Amazon S3 Stream name: cloudtrail-firehose-stream S3 bucket: processed-cloudtrail-logs-ACCOUNT_ID-REGION Prefix: processed-cloudtrail/date=!{timestamp:yyyy-MM-dd}/ Error prefix: processed-cloudtrail/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ Buffer size: 10 MB Buffer interval: 300 seconds Compression: GZIP IAM role: CloudTrailFirehoseRole Create delivery stream\nTạo vpc-dns-firehose-stream Stream name: vpc-dns-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: vpc-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: vpc-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) Tạo vpc-flow-firehose-stream Stream name: vpc-flow-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: eni-flow-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: eni-flow-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.1-create-lambda-excecution-roles/","title":"Tạo Lambda Execution Roles","tags":[],"description":"","content":"Tạo CloudTrailETLLambdaServiceRole Mở IAM Console:\nĐiều hướng đến https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Nhấn \u0026ldquo;IAM\u0026rdquo; Điều hướng đến Roles:\nỞ thanh bên trái, nhấn \u0026ldquo;Roles\u0026rdquo; Nhấn \u0026ldquo;Create role\u0026rdquo;\nChọn trusted entity:\nTrusted entity type: Chọn \u0026ldquo;AWS service\u0026rdquo; Use case: Chọn \u0026ldquo;Lambda\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu vào ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập CloudTrailETLLambdaServiceRole Description: Nhập Execution role for CloudTrail ETL Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau (thay thế ACCOUNT_ID và REGION): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/cloudtrail-firehose-stream\u0026#34; } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập CloudTrailETLPolicy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm Tạo các Lambda Roles còn lại Làm theo quy trình tương tự cho mỗi role dưới đây (các bước 3-11):\nGuardDutyETLLambdaServiceRole\nRole name: GuardDutyETLLambdaServiceRole Description: Execution role for GuardDuty ETL Lambda function Managed policy: AWSLambdaBasicExecutionRole Inline policy name: GuardDutyETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kms:REGION:ACCOUNT_ID:key/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:CreatePartition\u0026#34;, \u0026#34;glue:GetPartition\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:catalog\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:database/security_logs\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:table/security_logs/processed_guardduty\u0026#34; ] } ] } CloudWatchETLLambdaServiceRole\nRole name: CloudWatchETLLambdaServiceRole Description: Execution role for VPC DNS logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-dns-firehose-stream\u0026#34; } ] } CloudWatchENIETLLambdaServiceRole\nRole name: CloudWatchENIETLLambdaServiceRole Description: Execution role for VPC Flow logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchENIETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-flow-firehose-stream\u0026#34; } ] } CloudWatchExportLambdaServiceRole\nRole name: CloudWatchExportLambdaServiceRole Description: Execution role for CloudWatch log export Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchExportPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateExportTask\u0026#34;, \u0026#34;logs:DescribeExportTasks\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34;, \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } ParseFindingsLambdaServiceRole\nRole name: ParseFindingsLambdaServiceRole Description: Execution role for parsing GuardDuty findings Managed policy: AWSLambdaBasicExecutionRole Không cần inline policy IsolateEC2LambdaServiceRole\nRole name: IsolateEC2LambdaServiceRole Description: Execution role for isolating compromised EC2 instances Managed policy: AWSLambdaBasicExecutionRole Inline policy name: IsolateEC2Policy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeInstances\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } QuarantineIAMLambdaServiceRole\nRole name: QuarantineIAMLambdaServiceRole Description: Execution role for quarantining compromised IAM users Managed policy: AWSLambdaBasicExecutionRole Inline policy name: QuarantineIAMPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:AttachUserPolicy\u0026#34;, \u0026#34;iam:ListAttachedUserPolicies\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::ACCOUNT_ID:user/*\u0026#34;, \u0026#34;arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy\u0026#34; ] } ] } AlertDispatchLambdaServiceRole\nRole name: AlertDispatchLambdaServiceRole Description: Execution role for dispatching alerts via SNS/SES/Slack Managed policy: AWSLambdaBasicExecutionRole Inline policy name: AlertDispatchPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:REGION:ACCOUNT_ID:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.1-set-up-s3-buckets/","title":"Thiết lập S3 buckets","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 5 S3 buckets phục vụ làm nền tảng cho hệ thống Phản hồi Sự cố Tự động (Auto Incident Response system).\nQuan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu của bạn (ví dụ: us-east-1) trong tất cả các tên bucket.\nTên Bucket incident-response-log-list-bucket-ACCOUNT_ID-REGION - Bucket thu thập log chính processed-cloudtrail-logs-ACCOUNT_ID-REGION - Lưu trữ CloudTrail logs đã xử lý athena-query-results-ACCOUNT_ID-REGION - Lưu trữ kết quả truy vấn Athena processed-cloudwatch-logs-ACCOUNT_ID-REGION - Lưu trữ CloudWatch logs đã xử lý processed-guardduty-findings-ACCOUNT_ID-REGION - Lưu trữ GuardDuty findings đã xử lý Hướng dẫn tạo Bucket Mở Amazon S3 Console Truy cập https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo; Cấu hình chung: Bucket name: Nhập incident-response-log-list-bucket-ACCOUNT_ID-REGION Ví dụ: incident-response-log-list-bucket-123456789012-us-east-1 AWS Region: Chọn region mục tiêu của bạn (ví dụ: US East (N. Virginia) us-east-1) Object Ownership:\nGiữ mặc định: ACLs disabled (recommended) Cài đặt Block Public Access cho bucket này:\nChọn \u0026ldquo;Block all public access\u0026rdquo; Đảm bảo tất cả 4 tùy chọn phụ đều được chọn: ✓ Block public access to buckets and objects granted through new access control lists (ACLs) ✓ Block public access to buckets and objects granted through any access control lists (ACLs) ✓ Block public access to buckets and objects granted through new public bucket or access point policies ✓ Block public and cross-account access to buckets and objects through any public bucket or access point policies Bucket Versioning:\nChọn \u0026ldquo;Enable\u0026rdquo; Tags (tùy chọn):\nThêm tags nếu muốn Ví dụ: Key=Purpose, Value=IncidentResponse Mã hóa mặc định (Default encryption):\nEncryption type: Chọn \u0026ldquo;Server-side encryption with Amazon S3 managed keys (SSE-S3)\u0026rdquo; Bucket Key: Giữ mặc định (Enabled) Cài đặt nâng cao (Advanced settings):\nGiữ nguyên tất cả mặc định Nhấn \u0026ldquo;Create bucket\u0026rdquo;\nXác minh tạo bucket:\nBạn sẽ thấy thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 buckets của bạn Lặp lại các bước 2-10 cho 4 buckets còn lại:\nprocessed-cloudtrail-logs-ACCOUNT_ID-REGION athena-query-results-ACCOUNT_ID-REGION processed-cloudwatch-logs-ACCOUNT_ID-REGION processed-guardduty-findings-ACCOUNT_ID-REGION Xác minh tất cả 5 buckets đã được tạo:\nĐiều hướng đến S3 Console Bạn sẽ thấy tất cả 5 buckets được liệt kê "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan","tags":[],"description":"","content":"Các thành phần hệ thống Phản hồi sự cố và Điều tra số tự động (Auto Incident Response and Forensics) là một kiến trúc sử dụng các dịch vụ tự động hóa để thu thập, xử lý và tự động phản hồi các phát hiện bảo mật, giảm thiểu thời gian cần thiết cho sự can thiệp của con người và hỗ trợ nhân viên bảo mật trong việc trực quan hóa và phân tích log. Hệ thống này được xây dựng dựa trên AWS Security Services (CloudTrail, GuardDuty, VPC Flow Logs, CloudWatch) đưa dữ liệu vào một Data Lake tập trung (S3/Glue/Athena) để phân tích. Tự động hóa cốt lõi được điều khiển bởi AWS EventBridge rules kích hoạt AWS Step Functions workflows, sau đó thực thi AWS Lambda functions để thực hiện các hành động cách ly và cảnh báo. Tổng quan về Workshop Trong workshop này, bạn sẽ triển khai một hệ thống đa giai đoạn để đạt được tự động hóa bảo mật từ đầu đến cuối. Bao gồm:\nThiết lập nền tảng (Foundation Setup): Tạo các S3 buckets và IAM roles chuyên dụng để hỗ trợ tất cả các dịch vụ. Thiết lập giám sát (Monitoring Setup): Kích hoạt và cấu hình các log bảo mật chính (CloudTrail, GuardDuty, VPC Flow Logs) để chuyển dữ liệu đến điểm thu thập log trung tâm. Thiết lập xử lý (Processing Setup): Triển khai Kinesis Firehose, Lambda ETLs, và Glue/Athena tables để chuyển đổi log thô thành một security data lake dễ dàng truy vấn. Thiết lập tự động hóa (Automation Setup): Tạo Isolation Security Group, SNS Topic, Incident Response Lambda Functions, và Step Functions State Machine thực thi các hành động cách ly tự động khi GuardDuty phát hiện các vấn đề. Thiết lập Dashboard (Dashboard Setup): Lưu trữ một giao diện web tĩnh dựa trên S3 an toàn được tăng tốc bởi CloudFront và bảo vệ bởi Cognito để cung cấp cho các nhà phân tích khả năng trực quan hóa thời gian thực của dữ liệu điều tra (forensic data) và khả năng truy vấn trực tiếp qua API Gateway. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Triển khai kiến trúc hướng sự kiện với Amazon DynamoDB – Phần 2﻿ bởi Aman Dhingra và Lee Hannigan | vào ngày 25 tháng 9 năm 2025 | trong Advanced (300), Amazon DynamoDB, Amazon EventBridge, AWS Lambda, Serverless, Technical How-to\nTrong bài đăng trước﻿ (Phần 1﻿) của loạt bài này, chúng tôi đã thảo luận về cách bạn có thể sử dụng﻿ Amazon EventBridge Scheduler để quản lý loại bỏ dữ liệu chính xác trong﻿ Amazon DynamoDB. Trong bài đăng này﻿ (Phần 2﻿), chúng tôi khám phá một phương pháp khác sử dụng﻿ global secondary indexes (GSIs) để xử lý các yêu cầu Time to Live (TTL) chi tiết﻿.\nKhi xử lý các ứng dụng thông lượng cao, việc kiểm soát chính xác về thời hạn dữ liệu là quan trọng. Sự trзадержка tự nhiên trong tính năng TTL gốc của DynamoDB có thể không luôn đáp ứng nhu cầu của các ứng dụng yêu cầu loại bỏ dữ liệu ngay lập tức. Bằng cách sử dụng GSIs, chúng ta có thể tạo ra một hệ thống phản hồi tốt hơn phù hợp với các yêu cầu thời gian thực của ứng dụng.\nTổng quan giải pháp﻿ Sử dụng GSI cho trường hợp sử dụng này cho phép bạn truy vấn hiệu quả dữ liệu đủ điều kiện để loại bỏ theo các khoảng thời gian phù hợp với nhu cầu cụ thể của bạn. Giải pháp này có thể cung cấp độ chi tiết gần thời gian thực, tương tự như phương pháp EventBridge Scheduler trước đó. Bằng cách thiết lập một sharded GSI với thuộc tính TTL làm sort key, chúng ta có thể định kỳ truy vấn và loại bỏ các mục hết hạn với độ chính xác gần 1 phút﻿.\nSơ đồ sau đây minh họa kiến trúc giải pháp﻿.\nEventBridge Scheduler kích hoạt một Lambda function theo lịch trình đã định﻿.\nLambda function truy vấn GSI để lấy các mục được đánh dấu để xóa﻿.\nLambda function xóa các mục đã lấy từ bảng DynamoDB﻿.\nNhu cầu về sharding﻿ Để quản lý hiệu quả thông lượng ghi và đọc cao﻿, sharding GSI là cần thiết. Sharding phân phối tải trên nhiều partition, ngăn chặn bất kỳ partition đơn lẻ nào trở thành nút thắt cổ chai và gây ra throttling. Điều này có thể đạt được bằng cách thêm hậu tố ngẫu nhiên hoặc được tính toán vào các giá trị partition key. Bằng cách ngẫu nhiên hóa partition key, các ghi được phân bổ đều hơn trên không gian partition key, cải thiện tính song song và thông lượng tổng thể.\nTuy nhiên, truy vấn dữ liệu hết hạn yêu cầu thực hiện truy vấn cho từng shard trong phạm vi. Cách tiếp cận này đảm bảo rằng tất cả các partition có thể được kiểm tra để tìm các mục hết hạn, nhưng nó đòi hỏi nhiều truy vấn để bao phủ tất cả các shard.\nSố lượng shard được tính toán dựa trên thông lượng ghi đỉnh dự kiến của bảng cơ sở bằng công thức sau﻿:\nnumber of shards = (peak write capacity units (WCU) / 1000) + buffer Bao gồm buffer trong tính toán của bạn được khuyến nghị để đảm bảo bạn có đủ shard để tránh throttling trên bảng DynamoDB. Buffer cũng cung cấp phân phối bổ sung để xử lý các đỉnh bất ngờ trong thông lượng ghi, duy trì hiệu suất và độ tin cậy của ứng dụng.\nNếu về lâu dài WCU đỉnh dự kiến của bạn tăng, bạn có thể trước tiên sửa đổi Lambda function để truy vấn các shard bổ sung, và sau đó cập nhật ứng dụng để tăng số lượng shard khi ghi dữ liệu vào bảng. Lambda có thể truy vấn các shard không tồn tại trong GSI mà không gặp vấn đề.\nLựa chọn primary key cho GSI﻿ Khi chọn key cho GSI của bạn, partition key GSI_PK sẽ được tạo bằng một shard ngẫu nhiên, với phạm vi được xác định bởi tính toán trước đó để đảm bảo phân phối tải đều. Sort key sẽ là thuộc tính TTL của bạn, có thể được biểu diễn bằng số epoch hoặc định dạng thời gian chuỗi. Sự kết hợp này cho phép truy vấn hiệu quả các mục dựa trên thời gian hết hạn, trong khi partition key được chia sẻ giúp phân phối các hoạt động ghi và đọc trên nhiều partition, tối ưu hóa hiệu suất tổng thể và khả năng mở rộng của bảng DynamoDB.\nTối ưu chi phí﻿ Indexing Duy trì GSI hiệu quả bao gồm việc sử dụng﻿ KEYS_ONLY projection và đảm bảo index﻿ là sparse. Bằng cách sử dụng﻿ KEYS_ONLY, GSI chỉ lưu trữ các thuộc tính primary key và các thuộc tính index key, giảm đáng kể chi phí lưu trữ và thông lượng. Ngoài ra, làm cho GSI sparse có nghĩa nó chỉ bao gồm các mục có thuộc tính TTL. Việc lập chỉ mục có chọn lọc này đảm bảo rằng chỉ các mục liên quan, những mục có thời gian hết hạn, được bao gồm trong GSI, tối ưu hóa thêm hiệu suất và sử dụng tài nguyên. Điều này không chỉ nâng cao hiệu quả truy vấn mà còn giúp quản lý chi phí bằng cách giữ cho index gọn và tập trung vào các mục yêu cầu quản lý TTL.\nMô hình dữ liệu mẫu﻿ Mô hình dữ liệu ví dụ sau được thiết kế để xử lý quản lý trạng thái session trong môi trường thông lượng cao, nơi các session yêu cầu quản lý TTL chi tiết. Bằng cách chia sẻ GSI, chúng tôi phân phối tải ghi trên bốn shard để xử lý hiệu quả thông lượng đỉnh 3.000 WCU, với số lượng shard được chọn để bao gồm dung lượng buffer bổ sung vượt quá đỉnh dự kiến. Mỗi mục session bao gồm thuộc tính TTL để đảm bảo hết hạn kịp thời, và partition key của GSI (GSI_PK) là định danh shard ngẫu nhiên để cho phép truy vấn và xóa chính xác các session hết hạn, duy trì hiệu suất tối ưu và tính toàn vẹn dữ liệu﻿.\nVí dụ sau cho thấy﻿ SessionTable mà chúng tôi đã tạo bằng﻿ NoSQL Workbench:\nVí dụ sau cho thấy TTL GSI của chúng tôi﻿.\nVới mô hình dữ liệu này, bây giờ chúng ta có thể truy vấn từng shard bằng GSI, áp dụng điều kiện trên thuộc tính timestamp TTL để xác định các bản ghi cũ hơn thời gian hiện tại. Điều này cho phép chúng ta tìm và loại bỏ hiệu quả các session hết hạn.\nĐiều kiện tiên quyết﻿ Trước khi đi sâu vào triển khai giải pháp TTL tùy chỉnh, bạn nên có các điều kiện tiên quyết sau﻿:\nAWS account – Truy cập vào một﻿ AWS account hoạt động﻿\nDynamoDB basics – Hiểu biết cơ bản về﻿ DynamoDB concepts, bao gồm bảng, mục, thuộc tính và các hoạt động CRUD cơ bản, là cần thiết để cấu hình và quản lý cơ sở dữ liệu hiệu quả﻿\nSharding – Hiểu biết cơ bản về﻿ sharding techniques cho DynamoDB﻿\nLambda functions – Bạn nên quen thuộc với﻿ AWS Lambda, vì bạn sẽ tạo và triển khai các Lambda function để truy vấn DynamoDB và chạy logic TTL tùy chỉnh﻿\nEventBridge basics – Kiến thức cơ bản về﻿ Amazon EventBridge là cần thiết để thiết lập﻿ EventBridge Scheduler rules để gọi Lambda function theo các khoảng thời gian cụ thể﻿\nAWS CLI hoặc thành thạo console﻿ – Để cấu hình dịch vụ và giám sát log. Chúng tôi sử dụng﻿ AWS Management Console trong suốt bài đăng này﻿.\nTạo bảng DynamoDB với GSI﻿ Bước đầu tiên của chúng tôi là tạo bảng DynamoDB với﻿ Amazon DynamoDB Streams được bật. Hoàn thành các bước sau﻿:\nTrên console DynamoDB, chọn﻿ Tables trong navigation pane﻿.\nChọn﻿ Create table.\nVới Table name, nhập tên cho bảng mới của bạn﻿.\nVới Partition key, nhập PK làm tên và chọn﻿ String làm kiểu﻿.\nVới Sort key, nhập SK làm tên và chọn﻿ String làm kiểu﻿.\nVới Table settings, chọn﻿ Customize settings. Tùy chọn﻿ Customize settings cũng cho phép bạn định nghĩa secondary index trên bảng, bật/tắt deletion protection, chuyển đổi kiểu mã hóa và thêm resource tag khi tạo bảng.\nVới Read/write capacity settings, đảm bảo﻿ On-demand được chọn﻿.\nCuộn xuống phần﻿ Secondary indexes.\nChọn﻿ Create global index.\nVới Partition key, nhập GSI_PK làm tên và chọn﻿ String làm kiểu﻿.\nCho﻿ Sort key, nhập TTL làm tên và chọn﻿ String làm kiểu﻿.\nVới﻿ Index name, nhập tên cho index mới của bạn﻿.\nVới Attribute projections, chọn﻿ Only keys.\nChọn﻿ Create index.\nĐể tất cả cấu hình khác mặc định và chọn﻿ Create table. Tạo Lambda﻿ function Tiếp theo, chúng tôi cấu hình Lambda function sẽ được gọi bởi EventBridge Scheduler. Lambda function này chịu trách nhiệm lấy các mục đủ điều kiện để xóa và xóa những mục đó. Hoàn thành các bước sau:\nTrên console Lambda, chọn﻿ Functions trong navigation pane﻿.\nChọn﻿ Create function.\nChọn﻿ Author from scratch.\nVới Function name, nhập tên (ví dụ, StrictDataManagement)﻿.\nVới Runtime, chọn﻿ Python 3.12.\nThêm policy cho phép hàm đọc từ GSI và ghi vào bảng﻿:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ReadFromGSI\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/\u0026lt;table-name\u0026gt;\u0026#34;, \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/\u0026lt;table-name\u0026gt;/index/\u0026lt;gsi-name\u0026gt;\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;WriteToTable\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/\u0026lt;table-name\u0026gt;\u0026#34; } ] } Chọn﻿ Create function. Trên tab﻿ Code của Lambda function, thay thế mã Lambda function bằng mã sau. Thay đổi các hằng số﻿, SHARDS, TABLE_NAME, và﻿ INDEX_NAME để phù hợp với yêu cầu cụ thể của bạn﻿: import boto3 from datetime import datetime # Constants SHARDS = 4 TABLE_NAME = \u0026#39;TTL-Table\u0026#39; INDEX_NAME = \u0026#39;TTL-index\u0026#39; dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(TABLE_NAME) def lambda_handler(event, context): current_time = datetime.now().replace(second=0, microsecond=0).isoformat() for shard in range(SHARDS): shard_key = str(shard) query_and_delete_expired_items(shard_key, current_time) def query_and_delete_expired_items(shard_key, current_time): last_evaluated_key = None while True: # Print for logging purposes print(f\u0026#34;Checking shard {shard_key} at {current_time}\u0026#34;) query_kwargs = { \u0026#39;IndexName\u0026#39;: INDEX_NAME, \u0026#39;KeyConditionExpression\u0026#39;: \u0026#39;GSI_PK = :shard AND #ttl \u0026lt; :current_time\u0026#39;, \u0026#39;ExpressionAttributeValues\u0026#39;: { \u0026#39;:shard\u0026#39;: shard_key, \u0026#39;:current_time\u0026#39;: current_time }, \u0026#39;ExpressionAttributeNames\u0026#39;: { \u0026#39;#ttl\u0026#39;: \u0026#39;TTL\u0026#39; } } if last_evaluated_key: query_kwargs[\u0026#39;ExclusiveStartKey\u0026#39;] = last_evaluated_key response = table.query(**query_kwargs) items_to_delete = response.get(\u0026#39;Items\u0026#39;, []) if items_to_delete: delete_expired_items(items_to_delete) last_evaluated_key = response.get(\u0026#39;LastEvaluatedKey\u0026#39;) if not last_evaluated_key: break def delete_expired_items(items): with table.batch_writer() as batch: for item in items: batch.delete_item( Key={ \u0026#39;PK\u0026#39;: item[\u0026#39;PK\u0026#39;], \u0026#39;SK\u0026#39;: item[\u0026#39;SK\u0026#39;] } ) Chọn﻿ Deploy để triển khai mã hàm mới nhất﻿. Hàm﻿ delete_expired_items sử dụng﻿ Boto3 batch_writer để thực hiện xóa hàng loạt cho hiệu quả. Tuy nhiên﻿, batch_writer không hỗ trợ﻿ ConditionExpression, có nghĩa là không có cách nào để kiểm tra xem một mục vẫn đủ điều kiện để xóa tại thời điểm ghi. Điều này có thể rủi ro trong các trường hợp sử dụng mà giá trị TTL có thể đã thay đổi giữa lần đọc ban đầu và nỗ lực xóa. Để tránh vô tình xóa các mục không còn hết hạn, được khuyến nghị sử dụng hoạt động DeleteItem với﻿ ConditionExpression xác minh giá trị TTL vẫn trong phạm vi mong đợi﻿.\nTạo EventBridge Scheduler﻿ Bây giờ chúng tôi tạo lịch trình EventBridge gọi Lambda function mỗi 5 phút. Bạn có thể điều chỉnh khoảng thời gian này để phù hợp với yêu cầu loại bỏ dữ liệu của bạn.\nTrên console EventBridge, chọn﻿ Schedules trong navigation pane﻿.\nChọn﻿ Create schedule.\nCho﻿ Schedule name, nhập tên cho lịch trình mới của bạn﻿.\nCho﻿ Schedule pattern, chọn﻿ Recurring schedule.\nCho﻿ Schedule type, chọn﻿ Rate-based schedule.\nCho﻿ Rate expression, đặt﻿ Value thành﻿ 5 và﻿ Unit thành﻿ minutes.\nCho﻿ Flexible time window, chọn﻿ Off.\nĐể tất cả cấu hình khác mặc định và chọn﻿ Next.\nCho﻿ Templated targets, chọn﻿ AWS Lambda Invoke.\nCho﻿ Lambda function, chọn Lambda function StrictDataManagement của bạn﻿.\nĐể tất cả cấu hình khác mặc định và chọn﻿ Next.\nCho﻿ Action after schedule completion, chọn﻿ NONE.\nĐể tất cả cấu hình khác mặc định và chọn﻿ Next.\nXem lại cấu hình của bạn và chọn﻿ Create schedule. Tạo mục mẫu để xem giải pháp hoạt động﻿ Bạn có thể kiểm tra giải pháp bằng cách thêm mục vào bảng DynamoDB với giá trị TTL. Đây là ví dụ tạo 10 mục mẫu với giá trị TTL bằng AWS CLI﻿:\n#!/bin/bash TABLE=\u0026#34;TTL-Table\u0026#34; for PK_VALUE in {1..10}; do # Get current UTC time in ISO 8601 format ISO_TIMESTAMP=$(date -u +\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) # Generate a random shard value between 0 and 3 GSI_PK_VALUE=$((RANDOM % 4)) # Put item into DynamoDB aws dynamodb put-item --table-name $TABLE \\ --item \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;StaticSK\u0026#34;}, \u0026#34;GSI_PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$GSI_PK_VALUE\u0026#39;\u0026#34;}, \u0026#34;TTL\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$ISO_TIMESTAMP\u0026#39;\u0026#34;}, \u0026#34;SessionData\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;{\\\u0026#34;cart\\\u0026#34;: \\\u0026#34;item\u0026#39;$PK_VALUE\u0026#39;\\\u0026#34;}\u0026#34;}}\u0026#39; done Để theo dõi các hoạt động xóa trên bảng DynamoDB của bạn, điều hướng đến tab﻿ Monitoring trên console DynamoDB. Trong thiết lập này, lịch trình EventBridge gọi Lambda function mỗi 5 phút để lấy và xóa mục bằng lệnh﻿ BatchWriteItem. Bạn có thể theo dõi các hoạt động xóa bằng cách xem metric﻿ SuccessfulRequestLatency cho hoạt động﻿ BatchWriteItem, sử dụng thống kê﻿ Sample Count để xem số lần gọi xóa. Để biết thêm chi tiết về metrics DynamoDB, tham khảo﻿ DynamoDB Metrics and dimensions.\nBiểu đồ sau cho thấy﻿ BatchWriteItem được gọi bốn lần, một lần gọi cho mỗi shard được định nghĩa cho trường hợp sử dụng của chúng tôi﻿.\nCân nhắc chi phí﻿ Chi phí sử dụng phương pháp này cho 1.000.000 mục TTL được ước tính trong bảng sau với so sánh sử dụng chức năng DynamoDB gốc. Mỗi mục DynamoDB nhỏ hơn 1KB và được lưu trữ trong bảng sử dụng chế độ on-demand ở Region us-east-1. Free tier không được xem xét cho phân tích này.\nTTL gần thời gian thực TTL DynamoDB bản địa DynamoDB global secondary index Viết: $0.63 Đọc: $0.11 - Lambda EventBridge Scheduler $1 - DynamoDB Delete $1.26 - Tổng Chi phí $2.43 $0 Dọn dẹp﻿ Nếu bạn tạo môi trường kiểm tra để theo dõi bài đăng này, hãy đảm bảo﻿:\nXóa DynamoDB table﻿\nXóa Lambda function﻿\nXóa EventBridge schedule﻿\nXóa bất kỳ IAM role nào còn lại được tạo trong quá trình này﻿\nXóa bất kỳ tài nguyên nào khác bạn tạo để kiểm tra giải pháp﻿.\nTóm tắt﻿ Trong bài đăng này, chúng tôi đã thảo luận về cách DynamoDB GSI kết hợp với EventBridge và Lambda cung cấp giải pháp mạnh mẽ để quản lý hết hạn dữ liệu trong thời gian thực, cung cấp hiệu suất ứng dụng tối ưu và xử lý dữ liệu hiệu quả.\nTrong﻿ Phần 3﻿, chúng tôi khám phá cách EventBridge Scheduler có thể cho phép lập lịch chi tiết các sự kiện downstream. Phương pháp này cung cấp quản lý dữ liệu tương lai chính xác cho ứng dụng của bạn, nâng cao kiến trúc hướng sự kiện của bạn.\nVề các tác giả﻿ Lee Hannigan Lee Hannigan là Chuyên gia giải pháp DynamoDB cao cấp (Sr. DynamoDB Specialist Solutions Architect) làm việc tại Donegal, Ireland. Anh có chuyên môn sâu rộng về các hệ thống phân tán (distributed systems), cùng nền tảng vững chắc về các công nghệ dữ liệu lớn (big data) và phân tích (analytics technologies). Trong vai trò Chuyên gia giải pháp DynamoDB, Lee xuất sắc trong việc hỗ trợ khách hàng thiết kế, đánh giá và tối ưu hóa khối lượng công việc (workloads) sử dụng các khả năng của DynamoDB. Aman Dhingra Aman Dhingra là Chuyên gia giải pháp DynamoDB cao cấp (Sr. DynamoDB Specialist Solutions Architect) làm việc tại Dublin, Ireland. Anh có đam mê về các hệ thống phân tán (distributed systems) và nền tảng chuyên sâu về dữ liệu lớn \u0026amp; phân tích (big data \u0026amp; analytics). Aman là tác giả của cuốn \u0026ldquo;Amazon DynamoDB – The Definitive Guide\u0026rdquo; và hỗ trợ khách hàng trong việc thiết kế, đánh giá và tối ưu hóa khối lượng công việc vận hành trên Amazon DynamoDB. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"\nHệ thống Ứng phó Sự cố và Điều tra Số Tự động trên AWS Liên kết Đề xuất: Proposal\n1. Tóm tắt Điều hành Nhóm của chúng tôi đang xây dựng một giải pháp ứng phó sự cố và điều tra số tự động như một phần của chương trình thực tập AWS First Cloud Journey. Ý tưởng rất đơn giản—khi một vấn đề bảo mật xảy ra trong AWS, chúng tôi muốn hệ thống phản ứng tự động mà không cần chờ đợi sự can thiệp thủ công.\nChúng tôi đang tạo ra một nền tảng tự động phát hiện các phát hiện bảo mật từ GuardDuty, cô lập các tài nguyên bị ảnh hưởng, thu thập bằng chứng pháp y thông qua việc thu thập dữ liệu toàn diện, và cung cấp các phân tích và bảng điều khiển để các đội bảo mật có thể điều tra những gì đã xảy ra. Mọi thứ được xây dựng bằng Infrastructure-as-Code với AWS CDK, vì vậy khách hàng có thể dễ dàng triển khai nó vào tài khoản AWS của riêng họ.\n2. Báo cáo Vấn đề Vấn đề là gì? Tần suất và sự tinh vi ngày càng tăng của các mối đe dọa mạng đặt ra những rủi ro đáng kể cho các tổ chức dựa vào cơ sở hạ tầng đám mây. Quy trình ứng phó sự cố thủ công thường chậm chạp, không nhất quán và dễ mắc lỗi của con người, có thể dẫn đến thời gian ngừng hoạt động hệ thống kéo dài, vi phạm dữ liệu và tổn thất tài chính. Dự án nhằm giải quyết những thách thức này bằng cách phát triển một hệ thống ứng phó sự cố tự động, đáng tin cậy và có khả năng mở rộng.\nGiải pháp Các trường hợp sử dụng chính bao gồm phát hiện việc sử dụng trái phép thông tin xác thực AWS, xác định các EC2 instance bị xâm nhập, và đảm bảo dữ liệu pháp y được thu thập, xử lý và lưu trữ đúng cách để điều tra. Kiến trúc của chúng tôi tích hợp VPC Flow Logs, CloudTrail, CloudWatch và GuardDuty để phát hiện các mối đe dọa, trong khi Step Functions điều phối quy trình ứng phó tự động bao gồm cô lập EC2, tách khỏi ASG, tạo Snapshot và cách ly IAM. Tất cả bằng chứng được thu thập và xử lý thông qua Lambda ETL tùy chỉnh và Data Firehose, sử dụng Athena để phân tích pháp y. Hệ thống cũng bao gồm alert dispatching, notification bằng email và Slack, và cho chúng ta cái dashboard để analyze và điều tra chuyện đã xảy ra.\nLợi ích và Tỷ suất Lợi nhuận (ROI) Phát hiện mối đe dọa nhanh chóng: Phản ứng tự động giúp giảm thiểu khoảng thời gian dễ bị tổn thương. Thu thập bằng chứng toàn diện: Tự động hóa việc thu thập dữ liệu pháp y, tạo điều kiện cho các cuộc điều tra nhanh hơn. Hiệu quả về chi phí: Tận dụng các dịch vụ serverless của AWS giúp giảm thiểu chi phí cơ sở hạ tầng. Cải thiện tư thế bảo mật: Thông qua giám sát liên tục và cảnh báo thời gian thực. Thông tin chi tiết hữu ích: Các bảng điều khiển và phân tích trao quyền cho các đội bảo mật. Khả năng mở rộng: Thích ứng với các tổ chức có quy mô và khối lượng sự cố khác nhau. 3. Kiến trúc Giải pháp Giải pháp của chúng tôi sử dụng một kiến trúc đa giai đoạn toàn diện cho việc ứng phó sự cố và điều tra số tự động:\nCác Dịch vụ AWS Được Sử dụng Amazon GuardDuty: Liên tục theo dõi các mối đe dọa bảo mật và hoạt động đáng ngờ. AWS Step Functions: Điều phối quy trình ứng phó sự cố. AWS Lambda: Chạy mã tự động hóa để cô lập và xử lý dữ liệu. Amazon EventBridge: Định tuyến các phát hiện từ GuardDuty đến Step Functions. Amazon S3: Lưu trữ bằng chứng pháp y và lưu trữ bảng điều khiển tĩnh. Amazon Athena: Cho phép thực hiện các truy vấn SQL trên các tập dữ liệu pháp y. Amazon API Gateway: Tạo điều kiện giao tiếp giữa bảng điều khiển và backend. Amazon Cognito: Bảo mật quyền truy cập cho người dùng bảng điều khiển. Amazon CloudFront: Tăng tốc độ phân phối bảng điều khiển trên toàn cầu. Amazon SNS \u0026amp; SES: Xử lý thông báo qua tin nhắn và email. AWS CloudTrail: Ghi nhật ký tất cả các hành động để kiểm toán. Amazon CloudWatch: Giám sát và bảng điều khiển. Amazon EC2: Các instance tùy chọn để phân tích. AWS KMS: Quản lý khóa để mã hóa. Amazon Kinesis Data Firehose: Truyền dữ liệu đến S3. Thiết kế Thành phần Lớp Thu thập Dữ liệu \u0026amp; Phát hiện: Thu thập các sự kiện từ VPC Flow Logs, CloudTrail, CloudWatch, EC2 và GuardDuty. Lớp Xử lý Sự kiện: Alert Dispatch, EventBridge định tuyến các phát hiện đến Step Functions; các sự kiện được phân loại theo loại. Điều phối Ứng phó Tự động (Orchestration): Step Functions xử lý phân tích, ra quyết định, cô lập EC2, bảo vệ chấm dứt, tách ASG, tạo snapshot và cách ly IAM. Lớp Xử lý Dữ liệu \u0026amp; Phân tích: ETL pipeline với Lambda và Data Firehose xử lý nhật ký thô vào S3; Athena truy vấn dữ liệu. Lớp Bảng điều khiển \u0026amp; Phân tích: Bảng điều khiển React lưu trữ trên S3 với xác thực Cognito, sử dụng dữ liệu qua API Gateway và Athena. 4. Triển khai Kỹ thuật Các Giai đoạn Triển khai Chúng tôi sử dụng Agile Scrum với các sprint 1 tuần trong vòng 6 tuần:\nSprint 1: Nền tảng \u0026amp; Thiết lập (VPC, Security Groups, Đào tạo). Sprint 2: Điều phối Cốt lõi (Step Functions, Lambda, tích hợp GuardDuty). Sprint 3: Dữ liệu \u0026amp; Phân tích (S3, Athena, ETL pipeline). Sprint 4: Bảng điều khiển \u0026amp; UI (Trang web tĩnh, API Gateway, CloudFront). Sprint 5: Kiểm thử \u0026amp; Tối ưu hóa (Cognito, Kiểm thử hiệu suất, Mô phỏng). Sprint 6: Tài liệu \u0026amp; Bàn giao (Hướng dẫn, Demo, Hoàn thiện). Yêu cầu Kỹ thuật Frontend \u0026amp; Bảng điều khiển: HTML/CSS/JS tùy chỉnh được lưu trữ trên S3, phục vụ qua CloudFront. Backend \u0026amp; Xử lý: Python 3.12 cho Lambda, Step Functions để điều phối. Dữ liệu \u0026amp; Lưu trữ: S3 cho bằng chứng, Athena để truy vấn, Firehose để truyền dữ liệu. Cơ sở hạ tầng: Tất cả được định nghĩa trong AWS CDK (Python). Bảo mật: GuardDuty để phát hiện, IAM cho quyền hạn tối thiểu, KMS để mã hóa. 5. Thời gian biểu \u0026amp; Cột mốc Dòng thời gian Dự án Dòng thời gian Dự án\nTuần 6-7 (Nền tảng \u0026amp; Thiết lập) Hoạt động: Đào tạo nhóm về GuardDuty/Step Functions, đánh giá thiết kế kiến trúc, thiết lập VPC và bảo mật. Sản phẩm bàn giao: Tài liệu kiến trúc v1, hoàn thành đào tạo nhóm, kho lưu trữ GitHub được thiết lập. Tuần 7-9 (Điều phối Cốt lõi) Hoạt động: Phát triển quy trình Step Functions, lập trình hàm Lambda cho tất cả các hành động ứng phó, tích hợp EventBridge, thiết lập SNS/SES, kiểm thử tích hợp. Sản phẩm bàn giao: Định nghĩa máy trạng thái Step Functions, hơn 7 hàm Lambda có tài liệu, tích hợp GuardDuty, hệ thống thông báo, API Gateway. Tuần 10 (Dữ liệu \u0026amp; Phân tích) Hoạt động: Thiết lập lưu trữ pháp y S3, tạo bảng Athena, phát triển đường ống ETL, thư viện truy vấn SQL. Sản phẩm bàn giao: Hơn 15 truy vấn Athena được ghi lại, sách hướng dẫn phân tích pháp y, lưu trữ dữ liệu đã xử lý. Tuần 11 (Bảng điều khiển \u0026amp; UI) Hoạt động: Phát triển bảng điều khiển tĩnh, xác thực Cognito, thiết lập API Gateway, cấu hình CloudFront CDN, tích hợp bảng điều khiển. Sản phẩm bàn giao: Bảng điều khiển lưu trữ trên S3, hệ thống xác thực, giao diện truy vấn, tích hợp kết quả thời gian thực. Tuần 12 (Kiểm thử, Xác thực \u0026amp; Tối ưu hóa) Hoạt động: Kiểm thử thủ công, quét bảo mật bao gồm các kịch bản sự cố mô phỏng (hơn 5 quy trình), kiểm thử hiệu suất, mô phỏng tấn công. Tối ưu hóa dữ liệu với truy vấn Athena và Data Firehose. Sản phẩm bàn giao: Kết quả quét bảo mật, video mô phỏng sự cố, tối ưu hóa dữ liệu. Tuần 13 (Tài liệu \u0026amp; Bàn giao) Hoạt động: Hướng dẫn triển khai, tài liệu API, các phiên chuyển giao kiến thức, demo cuối cùng, dọn dẹp GitHub. Sản phẩm bàn giao: Kho lưu trữ GitHub hoàn chỉnh (công khai), hướng dẫn triển khai, buổi trình diễn workshop trực tiếp. 6. Ước tính Ngân sách Bạn có thể tìm thấy ước tính ngân sách chi tiết trên AWS Pricing Calculator.\nChi phí Cơ sở hạ tầng Chi phí triển khai hàng tháng điển hình (Bậc miễn phí / Quy mô nhỏ): ~$5.01\nGuardDuty: ~$1.80/tháng S3: ~$1.07/tháng KMS: ~$1.12/tháng CloudTrail: ~$0.55/tháng Athena: ~$0.29/tháng Amazon Simple Email Service (SES): ~$0.09/tháng Amazon API Gateway: ~$0.05/tháng Amazon Data firehose: ~$0.04/tháng Lambda, Step Functions, SNS: Thường nằm trong giới hạn Bậc miễn phí cho mức sử dụng thông thường. Lưu ý: Chi phí giả định mức sử dụng thông thường từ 20-150 sự cố mỗi tháng.\n7. Đánh giá Rủi ro Ma trận Rủi ro Tắc nghẽn Hiệu suất: Khối lượng dữ liệu lớn làm chậm các truy vấn. Vi phạm Bảo mật: Xâm phạm chính dữ liệu pháp y. Vượt quá Chi phí: Ghi nhật ký không kiểm soát hoặc vòng lặp vô hạn. Chiến lược Giảm thiểu Hiệu suất: Giám sát Athena/Firehose; tối ưu hóa truy vấn; điều chỉnh tài nguyên động. Bảo mật: Mã hóa (KMS), vai trò IAM nghiêm ngặt, ghi nhật ký kiểm toán. Chi phí: Cảnh báo ngân sách AWS, phát hiện bất thường chi phí, giới hạn tự động mở rộng. Khôi phục sau Thảm họa: Sao lưu, quy trình chuyển đổi dự phòng và các biện pháp dự phòng. 8. Kết quả Dự kiến Cải tiến Kỹ thuật Ứng phó Tự động: Cô lập không chạm (zero-touch) các tài nguyên bị xâm nhập. Tốc độ: Giảm thời gian điều tra từ hàng giờ xuống còn vài phút. Độ tin cậy: Thu thập bằng chứng nhất quán, có thể lặp lại mà không có lỗi của con người. Giá trị Dài hạn Kiến trúc Có thể Mở rộng: Nền tảng cho tự động hóa bảo mật trong tương lai. Kiến thức: Năng lực của nhóm về bảo mật AWS nâng cao và các khái niệm serverless. Tài sản Có thể Tái sử dụng: Một giải pháp có thể triển khai cho các khách hàng hoặc nhóm AWS khác. Trạng thái: Sẵn sàng cho Xem xét \u0026amp; Phê duyệt Mã Dự án: AWS-FCJ-IR-FORENSICS-2025\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Báo cáo sự kiện: “AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS” Mục tiêu sự kiện Giới thiệu tổng quan về các khả năng AI/ML/GenAI quan trọng trên AWS. Làm rõ các “building block” thực tế như Amazon Bedrock, các dịch vụ AI dựng sẵn và AgentCore cho bài toán thực tế. Diễn giả Lam Tuan Kiet – Sr DevOps Engineer, FPT Software Danh Hoang Hieu Nghi – AI Engineer, Renova Cloud Dinh Le Hoang Anh – Cloud Engineer Trainee, First Cloud AI Journey Van Hoang Kha – Cloud Security Engineer, AWS Community Builder Nội dung chính Generative AI với Amazon Bedrock – Foundation Models:\nAmazon Bedrock cung cấp nhiều Foundation Model (FM) qua một API được quản lý, cho phép chọn model từ nhiều nhà cung cấp và gắn vào các bài toán như chat, search, tóm tắt… mà không cần tự quản hạ tầng model.\n– Prompt Engineering:\nPhần trình bày đi qua các pattern prompt thực tế để kiểm soát hành vi model:\nZero-shot: hỏi trực tiếp chỉ với yêu cầu, không kèm ví dụ. Few-shot: thêm một vài ví dụ mẫu để dẫn model về đúng format và style mong muốn. Chain-of-thought: yêu cầu model suy luận từng bước, thể hiện lập luận trung gian trước khi cho đáp án cuối. – Retrieval-Augmented Generation (RAG):\nRAG kết hợp bước tìm kiếm với sinh văn bản để model trả lời dựa trên dữ liệu của riêng bạn, không chỉ dựa trên dữ liệu pretrain.\nR – Retrieval: lấy các đoạn nội dung liên quan từ knowledge base hoặc vector store. A – Augmented: đính kèm nội dung thu được vào prompt làm ngữ cảnh bổ sung. G – Generation: để model sinh câu trả lời dựa trên ngữ cảnh đó. Use case phổ biến: chatbot hiểu domain, Q\u0026amp;A trên tài liệu nội bộ, semantic search, tóm tắt nội dung gần real-time.\n– Amazon Titan Embeddings:\nTitan Embeddings chuyển text thành vector số hóa mang nghĩa ngữ nghĩa, phục vụ similarity search chính xác hơn, RAG, gợi ý và clustering trên hơn 100 ngôn ngữ.\n– Các dịch vụ AI dựng sẵn trên AWS:\nSự kiện cũng điểm qua nhóm dịch vụ AI managed, ẩn bớt độ phức tạp ML sau API đơn giản:\nAmazon Rekognition – phân tích ảnh/video (label, khuôn mặt, moderation…). Amazon Translate – tự động nhận diện ngôn ngữ và dịch. Amazon Textract – trích xuất text và layout từ tài liệu. Amazon Transcribe – chuyển giọng nói thành text (caption, phân tích cuộc gọi). Amazon Polly – chuyển text thành giọng nói tự nhiên. Amazon Comprehend – NLP: entity, sentiment, key phrase. Amazon Kendra – enterprise search trên nhiều nguồn dữ liệu. Amazon Lookout services – phát hiện bất thường trong metric, dữ liệu thiết bị, hình ảnh. Amazon Personalize – gợi ý cá nhân hóa. – Demo – AMZPhoto:\nDemo ứng dụng sử dụng Bedrock và nhận diện ảnh để nhận diện khuôn mặt trong ảnh upload, gắn với metadata đã lưu, minh họa pipeline end-to-end từ ingest đến inference.\nAmazon Bedrock AgentCore – Tổng quan:\nAgentCore là nền tảng quản lý agent AI ở mức production, lo phần runtime, security, observability… để đội ngũ tập trung vào logic của agent.\n– Vấn đề AgentCore giải quyết:\nChạy và scale code của agent trên runtime chuyên biệt, có bảo mật. Cung cấp bộ nhớ ngắn hạn và dài hạn để agent “học” từ tương tác cũ. Tích hợp với hệ thống định danh để kiểm soát quyền truy cập công cụ/dữ liệu. Kết nối agent với tool và API (qua Gateway, MCP…) cho các workflow phức tạp. Cung cấp observability và cơ chế đánh giá để theo dõi chất lượng và trace quyết định của agent. – Các nhóm dịch vụ lõi:\nFoundational services: Runtime, Identity, Gateway, Policy – phụ trách thực thi an toàn, truy cập tool và guardrail. Tools \u0026amp; memory layer: Memory, Browser tool, Code Interpreter và các tích hợp mở rộng khả năng agent. Secure deployment at scale: Serverless Runtime và Identity hỗ trợ multi-tenant, kịch bản enterprise. Operational insights: Observability và Evaluations cung cấp trace, metrics và kiểm tra chất lượng liên tục. – Framework xây agent:\nAgentCore tương thích với nhiều framework: CrewAI, Google ADK, LangGraph/LangChain, LlamaIndex, OpenAI Agents SDK, Strands Agents SDK… giúp tránh bị lock-in.\nNhững điểm rút ra Bedrock là trung tâm GenAI: Bedrock gom các FM và công cụ vào một chỗ, giúp thử nghiệm và triển khai tính năng GenAI mà không phải tự dựng hạ tầng model. Tùy biến qua prompt và dữ liệu: Zero-shot, few-shot, chain-of-thought và RAG cho phép “bẻ lái” model theo domain riêng với ít hoặc không cần fine-tuning. Embeddings là “viên gạch” nền tảng: Titan Embeddings và các embedding model khác là lõi cho semantic search và RAG, biến text tự do thành vector dễ index và truy vấn. Dịch vụ dựng sẵn cho use case phổ biến: Rekognition, Textract, Comprehend, Transcribe… giúp giải quyết bài toán hình ảnh, tài liệu, text analytics mà không cần tự train model. AgentCore cho agent production: AgentCore lấp khoảng trống từ PoC agent lên production bằng cách cung cấp runtime, memory, identity và quan sát vận hành ngay từ đầu. Ứng dụng vào công việc Lên kế hoạch sử dụng FM trên Bedrock và Titan Embeddings cho các project sắp tới, đặc biệt là search và tính năng kiểu RAG trong tool nội bộ. Đánh giá xem các dịch vụ dựng sẵn (Rekognition, Textract, Comprehend…) có thể thay thế script tự viết ở khâu xử lý dữ liệu nào để giảm công bảo trì. Cân nhắc AgentCore cho các thành phần “agentic” trong kiến trúc tương lai, nhất là những chỗ cần dùng tool an toàn và cần quan sát chi tiết. Trải nghiệm sự kiện Các diễn giả trình bày rõ ràng, nhiều ví dụ gắn trực tiếp với dịch vụ AWS nên khá dễ liên hệ giữa ý tưởng tổng quan và cách triển khai thực tế. Trong phần Q\u0026amp;A, một bạn trong team nêu bài toán kiến trúc: SNS topic đang nhận burst hơn 1000 GuardDuty alert, có nguy cơ xử lý không kịp. Gợi ý từ diễn giả là chèn thêm SQS queue giữa SNS và consumer để buffer backlog, đảm bảo không mất sự kiện. Kết thúc sự kiện, nhóm lọt top 10 trong bài Kahoot và có dịp chụp hình chung với diễn giả. Tụi mình còn lập “liên minh” nhỏ “Mèo Cam Đeo Khăn” gồm thành viên từ “The Ballers” và “Vinhomies”, tạo thêm cảm giác vui và gắn kết cộng đồng. Một vài hình ảnh sự kiện "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.2-week2/","title":"Nhật ký tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2 Nghỉ ngơi và hồi phục sau phẫu thuật áp-xe nhẹ. Tuân thủ hướng dẫn của bác sĩ, tránh hoạt động nặng. Thay băng vết thương hằng ngày theo chỉ định. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Nghỉ ngơi tại nhà sau phẫu thuật; uống thuốc giảm đau đúng giờ; đi tái khám kiểm tra vết thương lần đầu. 15/09/2025 15/09/2025 – Ba Thay băng vết thương hằng ngày theo hướng dẫn của bác sĩ; hạn chế ngồi lâu. 16/09/2025 16/09/2025 – Tư Thay băng; chỉ đi lại nhẹ nhàng; theo dõi cảm giác đau và tình trạng vết thương. 17/09/2025 17/09/2025 – Năm Thay băng; giữ vùng vết thương luôn sạch và khô. 18/09/2025 18/09/2025 – Sáu Thay băng hằng ngày; tập trung nghỉ ngơi và ăn uống đầy đủ để hồi phục. 19/09/2025 19/09/2025 – Kết quả đạt được trong tuần 2 Tuân thủ đúng phác đồ chăm sóc sau phẫu thuật, bao gồm thay băng hằng ngày và nghỉ ngơi theo lời dặn của bác sĩ. Không tham gia học tập hay làm project để giảm rủi ro biến chứng và giúp vết thương lành tốt hơn. Ghi lại ngắn gọn quá trình hồi phục để giữ cho worklog tuần tự và đầy đủ. Sẵn sàng cả về thể chất lẫn tinh thần để quay lại học AWS và làm project vào tuần 3. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/","title":"Cài đặt IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo IAM role và Policy cho Lambda. Sau đó bạn sẽ tạo Lambda Function để thực thi truy vấn.\nNội dung Tạo Lambda Execution Roles và Policy Tạo Lambda Function "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.2-create-lambda-function/","title":"Cài đặt Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Lambda sử dụng Python để thực thi truy vấn dùng dịch vụ Athena.\nTạo Lambda Function Mở Lambda Console\nĐiều hướng tới https://console.aws.amazon.com/lambda/ Hoặc: AWS Management Console → Services → Lambda Tạo Function:\nNhấn Create Function Trong mục cài đặt tạo mới, sử dụng cài đặt sau: Chọn Author from scratch Name: dashboard-query Runtime: Python 3.12 Architecture: x86_64 Change default execution role: Use an existing role Chọn dashboard-query-role Nhấn Create Thêm mã nguồn (code):\nTrong code editor copy và paste đoạn mã bên dưới sau đó nhấn Deploy: import boto3 import time import os import json athena = boto3.client(\u0026#39;athena\u0026#39;) RESOURCE_MAP = { \u0026#39;/logs/cloudtrail\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_cloudtrail\u0026#39; }, \u0026#39;/logs/guardduty\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_guardduty\u0026#39; }, \u0026#39;/logs/vpc\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;vpc_logs\u0026#39; }, \u0026#39;/logs/eni_logs\u0026#39;:{ \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;eni_flow_logs\u0026#39; } } OUTPUT_BUCKET_NAME = os.environ.get(\u0026#34;ATHENA_OUTPUT_BUCKET\u0026#34;) REGION = os.environ.get(\u0026#34;REGION\u0026#34;) OUTPUT_BUCKET = f\u0026#39;s3://{OUTPUT_BUCKET_NAME}/\u0026#39; def lambda_handler(event, context): print(\u0026#34;Received event:\u0026#34;, json.dumps(event)) resource_path = event.get(\u0026#39;resource\u0026#39;) config = RESOURCE_MAP.get(resource_path) if not config: return api_response(400, {\u0026#39;error\u0026#39;: f\u0026#39;Unknown resource path: {resource_path}\u0026#39;}) database_name = config[\u0026#39;db\u0026#39;] table_name = config[\u0026#39;table\u0026#39;] query_params = event.get(\u0026#39;queryStringParameters\u0026#39;, {}) or {} if config[\u0026#39;table\u0026#39;] == \u0026#39;processed_cloudtrail\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by eventtime desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;processed_guardduty\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by date desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;vpc_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;eni_flow_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp_str desc\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Querying DB: {database_name}, Table: {table_name}, Output: {OUTPUT_BUCKET}\u0026#34;) try: response = athena.start_query_execution( QueryString=query_string, QueryExecutionContext={\u0026#39;Database\u0026#39;: database_name}, ResultConfiguration={\u0026#39;OutputLocation\u0026#39;: OUTPUT_BUCKET} ) query_execution_id = response[\u0026#39;QueryExecutionId\u0026#39;] status = \u0026#39;RUNNING\u0026#39; while status in [\u0026#39;RUNNING\u0026#39;, \u0026#39;QUEUED\u0026#39;]: response = athena.get_query_execution(QueryExecutionId=query_execution_id) status = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;][\u0026#39;State\u0026#39;] if status in [\u0026#39;FAILED\u0026#39;, \u0026#39;CANCELLED\u0026#39;]: reason = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;].get(\u0026#39;StateChangeReason\u0026#39;, \u0026#39;Unknown\u0026#39;) return api_response(500, {\u0026#39;error\u0026#39;: f\u0026#39;Query Failed: {reason}\u0026#39;}) time.sleep(1) results = athena.get_query_results(QueryExecutionId=query_execution_id) return api_response(200, results) except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return api_response(500, {\u0026#39;error\u0026#39;: str(e)}) def api_response(code, body): return { \u0026#34;statusCode\u0026#34;: code, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET, OPTIONS\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps(body) } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.10-cleanup/5.10.2-cdk-cleanup/","title":"Dọn dẹp CDK","tags":[],"description":"","content":"Clean up (CDK) Hướng dẫn này đảm bảo bạn hủy bỏ (decommission) chính xác tất cả các tài nguyên được cung cấp bởi AWS CDK stack và dọn dẹp dữ liệu được tạo thủ công để tránh các khoản phí phát sinh.\nGiai đoạn 1: Dọn dẹp dữ liệu thủ công (Trước khi CDK Destroy) CDK tự động xóa hầu hết các tài nguyên nhưng không xóa nội dung trong S3 buckets. Bạn phải làm trống nội dung của các buckets này trước khi chạy lệnh cdk destroy.\nTên Resource Mục đích Hành động yêu cầu incident-response-log-list-bucket Nguồn Log Chính Làm trống nội dung processed-cloudwatch-logs ETL Destination Làm trống nội dung processed-guardduty-findings ETL Destination Làm trống nội dung processed-cloudtrail-logs ETL Destination Làm trống nội dung athena-query-results Kết quả truy vấn Athena Làm trống nội dung aws-incident-response-automation-dashboard React Dashboard S3 Bucket Làm trống nội dung Hướng dẫn làm trống Buckets:\nMở Amazon S3 Console trong trình duyệt của bạn. Đối với mỗi buckets được liệt kê ở trên (tìm tên dựa trên AWS Account ID và Region của bạn): Nhấn vào tên bucket. Điều hướng đến tab \u0026ldquo;Objects\u0026rdquo;. Nhấn nút \u0026ldquo;Empty\u0026rdquo;. Làm theo các lời nhắc để xác nhận xóa vĩnh viễn tất cả các objects. Giai đoạn 2: CDK Stack Destruction Bước này sử dụng CDK CLI để phá hủy tất cả các tài nguyên được cung cấp bởi CloudFormation stack.\nĐảm bảo môi trường ảo (Virtual Environment) đang hoạt động\nNếu bạn đã tắt môi trường Python, hãy kích hoạt lại nó (ví dụ: source .venv/bin/activate). Điều hướng đến Project Root\nĐảm bảo bạn đang ở thư mục chính nơi chứa file cdk.json. Thực thi lệnh Destroy\nChạy lệnh để phá hủy tất cả các stacks đã triển khai. Khi được nhắc, gõ y để chấp nhận việc xóa. $ cdk destroy --all Giai đoạn 3: Dọn dẹp sau khi phá hủy Bước này giải quyết việc dọn dẹp thủ công các tài nguyên còn sót lại.\nXóa các S3 Buckets còn lại\nLệnh cdk destroy sẽ xóa các S3 buckets trống. Nếu còn sót lại bucket nào (do kiểm tra cuối cùng hoặc bảo vệ dịch vụ), hãy xóa chúng ngay bây giờ qua S3 Console. Vô hiệu hóa Amazon GuardDuty\nVào GuardDuty Console → Settings → General. Xác minh dịch vụ đã bị vô hiệu hóa để đảm bảo ngừng tính phí. Xóa Cognito User và Pool\nVào Cognito Console → User pools. Xóa test user bạn đã tạo. Xóa User Pool đã tạo cho dashboard. Xóa SES Identity\nVào Amazon SES Console → Verified Identities. Xóa sender email identity (sender_email) bạn đã xác minh. Hủy kích hoạt môi trường ảo\nHủy kích hoạt môi trường ảo Python: $ deactivate "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.2-prerequiste/","title":"Điều kiện tiên quyết","tags":[],"description":"","content":"Các yêu cầu về Truy cập và Thông tin Trước khi tiến hành thiết lập Hệ thống Phản hồi Sự cố và Điều tra số AWS Tự động (Automated AWS Incident Response and Forensics System), hãy đảm bảo bạn đã thu thập đủ các thông tin và quyền truy cập cần thiết dưới đây.\n🔑 Truy cập \u0026amp; Định danh Tài khoản AWS với Quyền Quản trị (Administrative Access) Bạn cần toàn quyền quản trị để tạo tài nguyên trên nhiều dịch vụ AWS. Truy cập vào AWS Management Console. AWS Account ID của bạn Định dạng: số có 12 chữ số (ví dụ: 123456789012). Placeholder: Thay thế ACCOUNT_ID trong toàn bộ hướng dẫn. AWS Region Mục tiêu Chọn region nơi bạn sẽ triển khai hệ thống (ví dụ: us-east-1). Placeholder: Thay thế REGION trong toàn bộ hướng dẫn. VPC ID Một VPC có ít nhất một subnet được yêu cầu cho VPC Flow Logs. Placeholder: Thay thế YOUR_VPC_ID trong hướng dẫn. Địa chỉ Email đã xác thực Amazon SES Cần thiết để gửi và nhận thông báo qua email. Xác thực địa chỉ này trong SES Console. Placeholder: Thay thế YOUR_VERIFIED_EMAIL@example.com. Slack Webhook URL (Tùy chọn) Nếu bạn muốn nhận thông báo qua Slack, hãy lấy webhook URL từ Slack workspace của bạn. Placeholder: Thay thế YOUR_SLACK_WEBHOOK_URL. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.2-guardduty-etl/","title":"Mã GuardDuty ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.2-guardduty-etl/","title":"Mã GuardDuty ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.2-create-aws-glue-database-and-tables/","title":"Tạo AWS Glue Database và Tables","tags":[],"description":"","content":"Tạo AWS Glue Database và Tables Tạo Database Mở Glue Console → Databases → Add database\nDatabase name: security_logs\nCreate database\nTạo Tables (Sử dụng Athena DDL) Mở Athena Console\nĐặt vị trí lưu kết quả truy vấn (query result location): s3://athena-query-results-ACCOUNT_ID-REGION/\nChọn database: security_logs\nTạo bảng processed_cloudtrail Chạy DDL này trong Athena (thay thế ACCOUNT_ID và REGION):\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_cloudtrail ( `eventtime` string, `eventname` string, `eventsource` string, `awsregion` string, `sourceipaddress` string, `useragent` string, `useridentity` struct\u0026lt; type:string, invokedby:string, principalid:string, arn:string, accountid:string, accesskeyid:string, username:string, sessioncontext:struct\u0026lt; attributes:map\u0026lt;string,string\u0026gt;, sessionissuer:struct\u0026lt; type:string, principalid:string, arn:string, accountid:string, username:string \u0026gt; \u0026gt;, inscopeof:struct\u0026lt; issuertype:string, credentialsissuedto:string \u0026gt; \u0026gt;, `requestparameters` string, `responseelements` string, `resources` array\u0026lt;struct\u0026lt;arn:string,type:string\u0026gt;\u0026gt;, `recipientaccountid` string, `serviceeventdetails` string, `errorcode` string, `errormessage` string, `hour` string, `usertype` string, `username` string, `isconsolelogin` boolean, `isfailedlogin` boolean, `isrootuser` boolean, `isassumedrole` boolean, `ishighriskevent` boolean, `isprivilegedaction` boolean, `isdataaccess` boolean, `target_bucket` string, `target_key` string, `target_username` string, `target_rolename` string, `target_policyname` string, `new_access_key` string, `new_instance_id` string, `target_group_id` string, `identity_principalid` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng processed_guardduty Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_guardduty ( `finding_id` string, `finding_type` string, `title` string, `severity` double, `account_id` string, `region` string, `created_at` string, `event_last_seen` string, `remote_ip` string, `remote_port` int, `connection_direction` string, `protocol` string, `dns_domain` string, `dns_protocol` string, `scanned_ip` string, `scanned_port` int, `aws_api_service` string, `aws_api_name` string, `aws_api_caller_type` string, `aws_api_error` string, `aws_api_remote_ip` string, `target_resource_arn` string, `instance_id` string, `instance_type` string, `image_id` string, `instance_tags` string, `resource_region` string, `access_key_id` string, `principal_id` string, `user_name` string, `s3_bucket_name` string, `service_raw` string, `resource_raw` string, `metadata_raw` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/\u0026#39; TBLPROPERTIES ( \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39;, \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/date=${date}/\u0026#39; ); Tạo bảng vpc_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.vpc_logs ( `version` string, `account_id` string, `region` string, `vpc_id` string, `query_timestamp` string, `query_name` string, `query_type` string, `query_class` string, `rcode` string, `answers` string, `srcaddr` string, `srcport` int, `transport` string, `srcids_instance` string, `timestamp` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;ignore.malformed.json\u0026#39; = \u0026#39;true\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng eni_flow_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.eni_flow_logs ( `version` int, `account_id` string, `interface_id` string, `srcaddr` string, `dstaddr` string, `srcport` int, `dstport` int, `protocol` int, `packets` bigint, `bytes` bigint, `start_time` bigint, `end_time` bigint, `action` string, `log_status` string, `timestamp_str` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.2-create-service-roles/","title":"Tạo Service Roles","tags":[],"description":"","content":"Tạo Firehose Roles Tạo CloudTrailFirehoseRole Mở IAM Console → Roles → Create role\nChọn trusted entity:\nTrusted entity type: AWS service Use case: Chọn \u0026ldquo;Kinesis\u0026rdquo; → \u0026ldquo;Kinesis Firehose\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nBỏ qua việc thêm managed policies (chúng ta sẽ thêm inline policy) Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên và tạo:\nRole name: CloudTrailFirehoseRole Description: Allows Firehose to write CloudTrail logs to S3 Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nPolicy name: FirehosePolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo CloudWatchFirehoseRole Role name: CloudWatchFirehoseRole Description: Allows Firehose to write CloudWatch logs to S3 Trusted entity: Kinesis Firehose Inline policy name: FirehosePolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo Step Functions Role Tạo StepFunctionsRole Tạo role:\nTrusted entity: Step Functions Role name: StepFunctionsRole Description: Execution role for Incident Response Step Functions Thêm HAI inline policies:\nPolicy 1: LambdaInvokePolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-parse-findings-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-quarantine-iam-lambda\u0026#34; ] } ] } Policy 2: EC2AutoScalingPolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;autoscaling:DescribeAutoScalingInstances\u0026#34;, \u0026#34;autoscaling:DetachInstances\u0026#34;, \u0026#34;autoscaling:UpdateAutoScalingGroup\u0026#34;, \u0026#34;ec2:CreateSnapshot\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:DescribeVolumes\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo EventBridge Role Tạo IncidentResponseStepFunctionsEventRole Role name: IncidentResponseStepFunctionsEventRole Description: Allows EventBridge to trigger Step Functions Trusted entity: EventBridge Inline policy name: StartStepFunctionsPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;states:StartExecution\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:REGION:ACCOUNT_ID:stateMachine:IncidentResponseStepFunctions\u0026#34; } ] } Tạo VPC Flow Logs Role Tạo FlowLogsIAMRole Tạo role:\nTrusted entity: EC2 (will edit trust policy - sẽ chỉnh sửa trust policy sau) Role name: FlowLogsIAMRole Chỉnh sửa trust relationship thành:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;vpc-flow-logs.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } Thêm inline policy: Policy name: FlowLogsPolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo Glue Role Tạo GlueCloudWatchRole Role name: GlueCloudWatchRole Description: Allows Glue to access S3 and CloudWatch Logs Trusted entity: Glue Managed policies (đính kèm 3 policies): AWSGlueServiceRole CloudWatchLogsReadOnlyAccess AmazonS3FullAccess Không cần inline policies "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.2-set-up-s3-buckets-policies/","title":"Thiết lập S3 buckets policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ cấu hình bucket policy cho bucket log chính để cho phép CloudTrail, GuardDuty, và CloudWatch Logs ghi log.\nCấu hình Bucket Policy Điều hướng đến bucket log chính: Trong S3 Console, nhấn vào incident-response-log-list-bucket-ACCOUNT_ID-REGION Mở tab Permissions:\nNhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Cuộn đến Bucket policy:\nCuộn xuống phần \u0026ldquo;Bucket policy\u0026rdquo; Nhấn \u0026ldquo;Edit\u0026rdquo; Dán bucket policy: Copy JSON policy sau Quan trọng: Thay thế ACCOUNT_ID và REGION bằng giá trị thực tế của bạn trong policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyGetBucketLocation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsGetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailAclCheck\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailWrite\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/AWSLogs/ACCOUNT_ID/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34;, \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } } ] } Nhấn \u0026ldquo;Save changes\u0026rdquo;\nXác minh policy đã lưu: Bạn sẽ thấy policy hiển thị trong phần Bucket policy\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Báo cáo sự kiện: “AWS Cloud Mastery Series #2 – DevOps on AWS” Mục tiêu sự kiện Giới thiệu các dịch vụ DevOps cốt lõi trên AWS và các pipeline CI/CD. Giải thích khái niệm Infrastructure as Code (IaC) và các công cụ phổ biến. Trình bày các lựa chọn container hóa trên AWS. Minh họa cách giám sát và quan sát hệ thống (monitoring \u0026amp; observability) bằng dịch vụ AWS. Diễn giả Truong Quang Tinh – AWS Community Builder, Platform Engineer – TymeX Bao Huynh – AWS Community Builder Nguyen Khanh Phuc Thinh – AWS Community Builder Tran Dai Vi – AWS Community Builder Huynh Hoang Long – AWS Community Builder Pham Hoang Quy – AWS Community Builder Nghiem Le – AWS Community Builder Dinh Le Hoang Anh – Cloud Engineer Trainee, First Cloud AI Journey DevOps Mindset – Văn hóa (Culture):\nNhấn mạnh hợp tác giữa các team, tự động hóa cao, học tập liên tục và ra quyết định dựa trên số liệu đo được.\n– Vai trò DevOps:\nCác vai trò thường gặp trong tổ chức DevOps hiện đại gồm: DevOps Engineer, Cloud Engineer, Platform Engineer, Site Reliability Engineer (SRE)… tập trung vào độ tin cậy, tốc độ triển khai và vận hành hiệu quả.\n– Chỉ số thành công:\nTriển khai ổn định, ít lỗi. Tăng tốc độ deliver, giảm lead time cho mỗi thay đổi. Hệ thống ổn định, chịu lỗi tốt. Trải nghiệm người dùng cuối mượt hơn. Chứng minh được giá trị kinh doanh từ đầu tư công nghệ. NÊN (DO) KHÔNG NÊN (DON\u0026rsquo;T) Bắt đầu từ nền tảng cơ bản Mắc kẹt mãi trong “tutorial hell” Học bằng cách tự xây project Copy-paste mù quáng Ghi chép/tài liệu hóa đầy đủ So sánh bản thân với người khác Làm chủ từng thứ một Bỏ cuộc sau vài lần thất bại Rèn luyện kỹ năng mềm – Continuous Integration (CI):\nDev liên tục merge code vào nhánh chung (main), với build + test tự động để mỗi commit luôn ở trạng thái có thể release, tạo tiền đề cho Continuous Delivery/Deployment.\nInfrastructure as Code (IaC) – Lợi ích:\nIaC giúp tự động hóa, lặp lại được và dễ scale khi quản lý hạ tầng. Hạ tầng có thể version-control, tạo/xóa môi trường theo nhu cầu, và các thay đổi được review như code thay vì thao tác ClickOps thủ công.\nAWS CloudFormation Dịch vụ IaC “chính chủ” của AWS, dùng file JSON/YAML để mô tả và tạo toàn bộ stack tài nguyên AWS một cách dự đoán được và dễ audit.\n– Stack:\nStack là tập hợp tài nguyên AWS được định nghĩa trong một template. Các thao tác create, update, delete đều thực hiện ở cấp độ stack, giúp quản lý môi trường phức tạp dễ hơn.\n– CloudFormation Template:\nFile khai báo (YAML/JSON) mô tả tài nguyên, cấu hình và quan hệ giữa chúng, đóng vai trò “bản vẽ” có thể tái sử dụng cho các môi trường dev/test/prod.\n– Cách hoạt động (tổng quan):\nViết template mô tả hạ tầng mong muốn. Lưu local hoặc trên S3, tạo stack từ template đó. CloudFormation tự tạo/cập nhật/xóa tài nguyên để khớp với template. – Drift Detection:\nCho phép phát hiện tài nguyên bị chỉnh sửa ngoài IaC. Từ đó team có thể đồng bộ lại template với trạng thái thực tế hoặc rollback những thay đổi trái phép.\nAWS Cloud Development Kit (CDK) Framework open-source cho phép định nghĩa CloudFormation stack bằng ngôn ngữ lập trình thực (TypeScript/JavaScript, Python, Java, C#/.NET, Go).\n– Construct:\nConstruct là “viên gạch” trong CDK, đại diện cho một hoặc nhiều tài nguyên kèm cấu hình. Có 3 cấp:\nL1: Low-level, map 1:1 với resource CloudFormation, kiểm soát chi tiết nhất. L2: API cấp cao, đóng gói best practice và default hợp lý. L3: Pattern sẵn (opinionated), ghép nhiều resource thành kiến trúc hoàn chỉnh (ví dụ: API Gateway + Lambda + DynamoDB). AWS Amplify Nền tảng tập trung vào build và deploy web/mobile app. Amplify dùng CloudFormation phía sau để dựng backend và hosting, nhưng cung cấp trải nghiệm thân thiện hơn qua CLI và console.\nTerraform Công cụ IaC đa cloud (AWS, Azure, GCP…) dùng HCL (HashiCorp Configuration Language).\n– Thế mạnh:\nHỗ trợ multi-cloud với ngôn ngữ và quy trình thống nhất. Có “state” để nắm rõ chênh lệch giữa trạng thái hiện tại và định nghĩa trong code. Cách chọn công cụ IaC? – Cần cân nhắc:\nHạ tầng xài 1 cloud (AWS-only) hay đa cloud? Vai trò của bạn thiên về dev ứng dụng hay platform/ops? Ecosystem (doc, ví dụ, module chính thức, support) quanh công cụ đó trên cloud bạn dùng. Dịch vụ Container trên AWS Dockerfile Dockerfile mô tả cách build image: base image, dependency, step build, env, entrypoint… giúp app chạy nhất quán giữa các môi trường.\n– Image:\nImage là blueprint bất biến, build từ Dockerfile theo kiểu layered. Container chạy từ image đó ở dev/stage/prod.\n– Workflow:\nViết Dockerfile → build image → chạy container local hoặc trên AWS → push image lên registry (ECR/Docker Hub).\nAmazon ECR Registry container private, được quản lý toàn phần trên AWS.\n– Tính năng chính:\nQuét image tìm lỗ hổng bảo mật. Immutable tag tránh overwrite nhầm. Lifecycle policy dọn image cũ. Mã hóa \u0026amp; tích hợp IAM để kiểm soát truy cập. Container Orchestration Orchestrator quản lý scheduling, scaling, lifecycle container:\nRestart container lỗi. Scale in/out theo traffic/metrics. Cân bằng tải và phân bố workload hiệu quả. Kubernetes (K8s) Nền tảng orchestrator mã nguồn mở, tự động deploy, scale và self-heal ứng dụng container.\n– Thành phần chính:\nControl Plane (Master): quản lý trạng thái cluster, scheduling, API. Worker Node: chạy workload trong các pod. Pod: đơn vị deploy nhỏ nhất, thường chứa 1–vài container gắn chặt với nhau. Service: endpoint ổn định + load balancing cho nhóm pod. ECS vs EKS Tiêu chí Amazon ECS Amazon EKS Công nghệ lõi Orchestrator container “nhà trồng” trên AWS Kubernetes được AWS quản lý (chuẩn open-source) Độ phức tạp Đơn giản, dễ vận hành Linh hoạt hơn nhưng phức tạp hơn Kiến thức yêu cầu Không cần biết Kubernetes Cần nắm khái niệm K8s (pod, deployment, service, …) Tích hợp với AWS Tích hợp sâu với dịch vụ AWS Tích hợp theo chuẩn K8s, dễ dùng thêm tool từ ecosystem Use case / Lợi ích Deploy nhanh, ít gánh nặng vận hành Phù hợp khi cần tính năng K8s, multi-cluster, portability Ecosystem / Community Tool \u0026amp; cộng đồng xoay quanh ECS Cộng đồng và hệ sinh thái Kubernetes rất lớn Tóm tắt Phù hợp khi muốn nền tảng container AWS-managed Phù hợp khi cần full power của Kubernetes App Runner Dịch vụ fully-managed để deploy nhanh web app/API chạy container từ source hoặc registry, phù hợp team nhỏ hoặc workload muốn “ít đụng vào hạ tầng” nhất.\nMonitoring \u0026amp; Observability CloudWatch Dịch vụ trung tâm để giám sát tài nguyên và ứng dụng AWS gần real-time. Cung cấp metrics, logs, alarm, dashboard để cải thiện độ tin cậy và nhìn rõ chi phí. Tích hợp với Auto Scaling, EventBridge… để tự động phản ứng theo sự kiện. – CloudWatch Metrics:\nLưu lại số liệu hiệu năng/trạng thái từ dịch vụ AWS và workload on-prem (thông qua agent), có thể dùng làm trigger cho alarm, scaling policy, DevOps workflow.\nAWS X-Ray – Distributed Tracing:\nX-Ray trace request đi qua nhiều microservice, vẽ sơ đồ call graph và độ trễ, giúp tìm ra bottleneck hoặc điểm lỗi trong kiến trúc phức tạp.\n– Performance Insight:\nHỗ trợ phân tích nguyên nhân gốc rễ của lỗi và vấn đề hiệu năng, cho thấy request tốn thời gian ở đâu, lỗi xảy ra tại service nào.\nTrải nghiệm sự kiện Sự kiện này đặc biệt hữu ích cho project hiện tại vì trùng với định hướng của nhóm: chuyển từ ClickOps sang IaC với AWS CDK, giúp hạ tầng dễ bảo trì, tái sử dụng và làm việc nhóm tốt hơn. Phần CloudWatch và X-Ray cũng hỗ trợ cho yêu cầu monitoring và quan sát dữ liệu mà nhóm đang cần.\nCác diễn giả cũng giải đáp một số câu hỏi của team:\nHỏi: Project hiện tại đang dựng bằng ClickOps, muốn chuyển sang CDK thì có tool nào scan hạ tầng hiện tại và tự sinh CDK/CloudFormation không?\nTrả lời: Hiện chưa có công cụ nào làm việc này một cách đáng tin cậy cho toàn bộ môi trường. Cách tốt nhất là dựng lại hạ tầng bằng IaC và dần dần đồng bộ môi trường thực với code.\nHỏi: X-Ray nhìn khá giống CloudTrail, khác nhau chỗ nào?\nTrả lời: X-Ray tập trung vào trace request ứng dụng và call giữa service để phân tích hiệu năng và debug. CloudTrail thì chuyên về audit API call và hoạt động của user/role trong tài khoản AWS.\nHỏi: Project nhóm đang dựng quanh GuardDuty findings, có gợi ý nào để mô phỏng finding ổn định cho demo không?\nTrả lời: Có thể dùng port scanning để tạo finding, hoặc cấu hình thêm custom threat list (IP/domain độc hại) để tạo cảnh báo khi có hoạt động liên quan.\nĐây cũng là lần đầu một số diễn giả trình bày các chủ đề này:\nPhần DevOps và IaC được trình bày rõ ràng, mạch lạc và dễ theo dõi. Phần Monitoring \u0026amp; Observability tuy có chút hồi hộp nhưng vẫn mang lại nhiều thông tin thực tế và áp dụng được. Một vài hình ảnh sự kiện "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.3-week3/","title":"Nhật ký tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3 Tiếp tục hồi phục sức khỏe nhưng vẫn cố gắng duy trì tiến độ học khi có thể. Bắt đầu tìm hiểu Amazon S3 và cách host website tĩnh. Ôn lại IAM, Organizations và các best practices về bảo mật khi tình trạng ổn hơn. Trao đổi ý tưởng project với các bạn trong nhóm khi có thời gian và sức. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Vẫn đang trong giai đoạn hồi phục sau phẫu thuật. Đi bệnh viện rửa vết thương và thay băng. Chủ yếu nghỉ ngơi tại nhà, chưa thể ngồi hoặc dùng máy tính lâu, không làm bài lab hay học gì thêm. 22/09/2025 22/09/2025 – Ba Tiếp tục đi bệnh viện thay băng và kiểm tra vết thương. Mức độ đau vẫn còn cao, phần lớn thời gian phải nằm nghỉ. Chỉ xem lướt ghi chú trên điện thoại, chưa làm lab thực hành. 23/09/2025 23/09/2025 – Tư Ngày cuối của lịch thay băng dày đặc tại bệnh viện. Bác sĩ cho phép bắt đầu ngồi dậy trong thời gian ngắn, nhưng vẫn chưa đủ sức để tập trung học lâu. Dành thời gian suy nghĩ về phần S3 sẽ học và một vài ý tưởng cho project, nhưng chưa làm lab thực tế. 24/09/2025 24/09/2025 – Năm Sức khỏe khá hơn, có thể ngồi bàn học trong thời gian ngắn, vẫn phải đi thay băng hằng ngày nhưng bắt đầu học lại. Bắt đầu “Khởi đầu với Amazon S3”: + Tìm hiểu khái niệm cơ bản về Amazon S3, cách lưu trữ dạng object, độ bền dữ liệu và các use case phổ biến. + Xem lại các yêu cầu trước khi làm việc với S3 và tạo một S3 bucket cho lab. + Bật chế độ static website hosting cho S3 bucket và upload các file website ban đầu. + Cấu hình Block Public Access để mở public có kiểm soát cho website. 25/09/2025 25/09/2025 Giới thiệu Amazon S3 Chuẩn bị Bật Static Website Cấu hình Block Public Access Sáu Vẫn phải thay băng mỗi ngày nhưng đã ngồi được lâu hơn, tiếp tục làm lab về S3. Tiếp tục “Khởi đầu với Amazon S3”: + Cấu hình quyền public ở mức object để website có thể phục vụ nội dung. + Test truy cập website tĩnh trên trình duyệt để kiểm tra cấu hình. + Tìm hiểu lý thuyết về tăng tốc website tĩnh với CloudFront (chưa triển khai đầy đủ do sức khỏe/thời gian). + Thực hành Bucket Versioning, di chuyển object giữa thư mục/bucket và replicate object sang region khác. + Ôn lại các bước dọn dẹp tài nguyên và best practices về bảo mật, chi phí với S3. 26/09/2025 26/09/2025 Cấu hình Public Object Kiểm tra Website Tăng tốc với CloudFront Bucket Versioning Di chuyển \u0026amp; sao chép Object S3 Cross-Region Replication Cleanup \u0026amp; Best Practices Kết quả đạt được trong tuần 3 Cân bằng khá tốt giữa việc hồi phục sức khỏe và học tập bằng cách bắt đầu học lại từ từ từ thứ Năm trở đi. Nắm được nền tảng về Amazon S3, bao gồm bucket, object, static website hosting và cách quản lý quyền truy cập public. Triển khai thành công một website tĩnh đơn giản trên S3, kiểm tra truy cập và tìm hiểu thêm về việc tăng tốc với CloudFront. Thực hành các tính năng như Bucket Versioning, di chuyển object, replicate cross-region và dọn dẹp tài nguyên theo đúng best practices. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.3-setup-api-gateway/","title":"Cài đặt API Gateway","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một API Gateway để định tuyến cuộc gọi api từ dashboard tới Lambda.\nTạo API Gateway Mở API Gateway Console\nĐiều hướng tới https://console.aws.amazon.com/apigateway/ Hoặc: AWS Management Console → Services → API Gateway Tạo API:\nNhấn Create API Chọn REST API và nhấn Build Sử dụng cài đặt này để tạo: Chọn New API Name: dashboard-api API endpoint type: Regional Security policy: SecurityPolicy_TLS13_1_3_2025_09 Endpoint access mode: Basic IP address type: IPv4 Tạo Resources:\nBật CORS cho root resource Nhấn Create resource và đặt tên là logs Sau đó nhấn vào tài nguyên /logs vừa tạo và nhấn Create Resource để tạo tài nguyên con của /logs Đặt tên là cloudtrail và bật CORS Lặp lại ba lần nữa cho eni_logs, guardduty và vpc Tạo methods:\nNhấn vào /cloudtrail vừa tạo và nhấn Create method\nTrong phần tạo method, sử dụng cài đặt này:\nMethod type: GET Intergration type: Lambda function Bật Lambda proxy intergration chọn Buffered Lambda function: chọn region của bạn, tìm kiếm dashboard-query và chọn nó Timout: 29000 Lặp lại ba lần nữa cho eni_logs, guardduty và vpc\nTriển khai API (Deploy API):\nNhấn Deploy API ở góc phải Trong phần deploy API, sử dụng cài đặt này: Stage: New stage Name: prod Nhấn Deploy "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.3-cloudwatch-etl/","title":"Mã CloudWatch ETL","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.3-cloudwatch-etl/","title":"Mã CloudWatch ETL","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.3-create-iam-policy/","title":"Tạo IAM Policy","tags":[],"description":"","content":"Tạo IAM Quarantine Policy Tạo IrQuarantineIAMPolicy Điều hướng đến IAM Console → Policies → Create policy\nPolicy JSON:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Policy name: IrQuarantineIAMPolicy Description: Deny-all policy for quarantining compromised IAM users "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/","title":"Tạo IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 17 IAM roles cùng với các policies liên quan cho Lambda functions, Firehose streams, Step Functions, và các dịch vụ khác.\nTổng quan về IAM Roles Lambda Execution Roles (9 roles):\nCloudTrailETLLambdaServiceRole GuardDutyETLLambdaServiceRole CloudWatchETLLambdaServiceRole CloudWatchENIETLLambdaServiceRole CloudWatchExportLambdaServiceRole ParseFindingsLambdaServiceRole IsolateEC2LambdaServiceRole QuarantineIAMLambdaServiceRole AlertDispatchLambdaServiceRole Service Roles (6 roles): 10. CloudTrailFirehoseRole 11. CloudWatchFirehoseRole 12. StepFunctionsRole 13. IncidentResponseStepFunctionsEventRole 14. FlowLogsIAMRole 15. GlueCloudWatchRole\nIAM Policy (1 policy): 16. IrQuarantineIAMPolicy\nNội dung Tạo Lambda Execution Roles Tạo Service Roles Tạo IAM Policy "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.3-create-lambda-function-etl-processing/","title":"Tạo Lambda Function - Xử lý ETL","tags":[],"description":"","content":"Tạo Lambda Functions - Xử lý ETL Trong phần này, bạn sẽ tạo 5 Lambda functions để xử lý logs và gửi chúng đến Kinesis Firehose hoặc S3.\nincident-response-cloudtrail-etl Runtime: Python 3.12 Handler: CloudTrailETL.lambda_handler Role: CloudTrailETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: FIREHOSE_STREAM_NAME=cloudtrail-firehose-stream Code: cloudtrail-etl incident-response-guardduty-etl Runtime: Python 3.12 Handler: guardduty_etl.lambda_handler Role: GuardDutyETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: DESTINATION_BUCKET, S3_LOCATION_GUARDDUTY, DATABASE_NAME, TABLE_NAME_GUARDDUTY Code: guardduty-etl cloudwatch-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_etl.lambda_handler Role: CloudWatchETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-dns-firehose-stream Code: cloudwatch-etl cloudwatch-eni-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_eni_etl.lambda_handler Role: CloudWatchENIETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-flow-firehose-stream Code: cloudwatch-eni-etl cloudwatch-export-lambda Runtime: Python 3.12 Handler: cloudwatch_autoexport.lambda_handler Role: CloudWatchExportLambdaServiceRole Env: DESTINATION_BUCKET=incident-response-log-list-bucket-ACCOUNT_ID-REGION Code: cloudwatch-autoexport Cấu hình CloudWatch Logs Subscription Filter Cấu hình Subscription Filter Mở CloudWatch Console.\nỞ ngăn điều hướng bên trái, chọn Log Management.\nNhấn vào centralized log group: /aws/incident-response/centralized-logs.\nTạo Subscription Filter:\nNhấn vào tab \u0026ldquo;Subscription filters\u0026rdquo;. Nhấn \u0026ldquo;Create Lambda subscription filter\u0026rdquo;. Cấu hình Destination:\nDestination Lambda function: Chọn function cloudwatch-export-lambda. Log format: Chọn \u0026ldquo;Other\u0026rdquo;. (Điều này đảm bảo dữ liệu log thô được chuyển đi hiệu quả để Lambda xử lý). Cấu hình Log Format và Filter:\nSubscription filter name: Nhập tên mô tả, ví dụ, VPC-Log-Export-Filter. Filter pattern: Để trống trường này blank. (Đảm bảo tất cả logs trong group đều được xử lý). Nhấn \u0026ldquo;Start streaming\u0026rdquo;.\nCấu hình S3 Event Notifications S3 Console → incident-response-log-list-bucket-ACCOUNT_ID-REGION → Properties → Event notifications\nTạo 4 notifications với Event types/Object creation/✅All object create events:\nCloudTrailETLTrigger: Prefix AWSLogs/ACCOUNT_ID/CloudTrail/ → Lambda incident-response-cloudtrail-etl VPCDNSLogsTrigger: Prefix exportedlogs/vpc-dns-logs/ → Lambda cloudwatch-etl-lambda VPCFlowLogsTrigger: Prefix exportedlogs/vpc-flow-logs/ → Lambda cloudwatch-eni-etl-lambda GuardDutyFindingsTrigger: Prefix AWSLogs/ACCOUNT_ID/GuardDuty/ → Lambda incident-response-guardduty-etl "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.3-foundation-setup/","title":"Thiết lập nền tảng","tags":[],"description":"","content":"Giai đoạn Thiết lập nền tảng ban đầu này xây dựng các điều kiện tiên quyết cốt lõi cho Hệ thống Phản hồi Sự cố Tự động, tập trung vào việc triển khai lưu trữ chuyên dụng và ủy quyền bảo mật thiết yếu. Điều này bắt buộc phải tạo năm Amazon S3 buckets an toàn để thu thập và xử lý log tập trung, áp dụng Bucket Policy cần thiết để phân phối log an toàn, và định nghĩa 17 IAM roles cùng chính sách cách ly (quarantine policy) để thực thi quyền truy cập đặc quyền tối thiểu (least-privilege access) trên tất cả các dịch vụ AWS được tích hợp.\nNội dung Thiết lập Amazon S3 Bucket Cấu hình S3 Bucket Policy cho Primary Log Bucket Tạo IAM Roles và Policies "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Báo cáo sự kiện: “Secure Your Applications: AWS Perimeter Protection Workshop” Mục tiêu sự kiện Giới thiệu Amazon CloudFront như nền tảng cho bảo vệ vành đai (perimeter protection). Giải thích AWS WAF và các mô hình bảo vệ ở tầng ứng dụng. Thực hành: Tối ưu một web app bằng CloudFront. Thực hành: Bảo vệ web app internet-facing bằng WAF. Diễn giả Nguyen Gia Hung – Head of Solution Architect Julian Ju – Senior Edge Services Specialist Solutions Architect Kevin Lim – Senior Edge Services Specialist GTM Nội dung chính Amazon CloudFront Nhu cầu bảo mật và vị trí CloudFront Các nhóm khách hàng khác nhau cần mức độ bảo vệ khác nhau:\nChủ website nhỏ: Cần lớp bảo vệ đơn giản, chi phí thấp. Doanh nghiệp tầm trung: Cần che chắn trước DDoS, bot và traffic độc hại. Doanh nghiệp lớn/đang scale: Cần cấu hình nâng cao như origin failover, origin offload và tích hợp chặt với WAF, Shield. CloudFront được trình bày như lớp edge nền tảng cho cả ba nhóm: giá dễ dự đoán, phủ toàn cầu, tích hợp sâu với các dịch vụ bảo mật của AWS.\nCloudFront Flat-Rate Pricing CloudFront hiện có các gói trả phí trọn gói, gom CDN, WAF, DDoS protection, DNS và storage vào một mức phí/tháng:\nGói:\nFree: 0 USD/tháng Pro: 15 USD/tháng Business: 200 USD/tháng Premium: 1000 USD/tháng Ví dụ mức sử dụng:\nFree: 1M request + 100 GB data Pro: 10M request + 50 TB data Business: 125M request + 50 TB data Premium: 500M request + 50 TB data Khi vượt “soft limit”, CloudFront không tính phí vượt ngay mà có thể giảm hiệu năng và cảnh báo để bạn nâng gói hoặc tối ưu.\nBảo vệ vành đai với CloudFront Phòng thủ phân tán: Tấn công được “hấp thụ” tại edge gần attacker thay vì đánh thẳng vào origin. Tích hợp AWS Shield Advanced: Có thêm visibility cho DDoS layer hạ tầng và được SRT hỗ trợ 24/7. Giảm tấn công volumetric: STN proxy và global routing giúp giảm SYN flood và các tấn công volume lớn ngay trên đường đi. Tối ưu chi phí với CloudFront Giảm/miễn phí egress: Data từ nhiều dịch vụ AWS về CloudFront thường rẻ hơn hoặc miễn phí so với egress trực tiếp ra internet.\nNén HTTP: Nén nội dung có thể giảm kích thước payload rất nhiều, tăng tốc và giảm băng thông.\nTối ưu TLS:\nTự động cấp và gia hạn chứng chỉ (ACM). HTTPS miễn phí với policy bảo mật sẵn cho cipher/TLS. Hỗ trợ TLS hiện đại (TLS 1.3, ECDSA, chuẩn “sẵn sàng hậu lượng tử”). Redirect HTTP → HTTPS ngay tại edge. Mutual TLS (sắp có): Hỗ trợ xác thực 2 chiều bằng client certificate tại edge.\nOrigin cloaking:\nOrigin Access Control (OAC): Ký request tới S3, Lambda Function URL… bằng credential ngắn hạn, chặn truy cập trực tiếp. Custom origin: Chỉ cho phép IP CloudFront và yêu cầu secret header. Bảo vệ nội dung:\nSigned URL/cookie ngăn hotlink và copy link chia sẻ bừa bãi. Caching \u0026amp; tính sẵn sàng:\nCache bằng TTL để giảm tải origin. Serve stale content khi origin chậm hoặc tạm thời lỗi. Origin failover sang origin dự phòng. Trang lỗi custom và cache error hợp lý. Tăng hiệu năng với CloudFront Multi-layer caching: Dùng edge location, Regional Edge Cache, Origin Shield để gom request và tăng cache hit. Tối ưu kết nối: Kết nối multiplexed để tải nhiều asset song song. Kết nối persist tới origin để tránh bắt tay TCP nhiều lần. Hạ tầng mạng AWS: Traffic giữa edge và origin đi trên backbone của AWS, giảm độ trễ và tránh nghẽn internet công cộng. Logic tại edge: CloudFront Functions, Lambda@Edge cho redirect, rewrite URL, A/B test, routing theo geo/device. Có thể làm rate limit, mock API, health check, xử lý lỗi ngay gần user. Use case phổ biến của CloudFront Static website \u0026amp; asset: Hit cache cao, tăng tốc độ và giảm chi phí origin. Full website delivery: Kết hợp performance, security, HA cho cả nội dung tĩnh và động. API acceleration: Tái dùng kết nối lâu dài, cache hợp lý để giảm latency. Streaming media: Phục vụ số lượng lớn người xem với độ trễ thấp và chi phí tốt. Large file download: Tận dụng range request và edge cache cho file lớn. Best practice với CloudFront Theo dõi end-to-end: user metrics, internet path và backend. Tối đa hóa caching (chuẩn hóa cache key, cache response động khi an toàn, cache error). Dùng WAF chặn traffic xấu, rate limit, lọc API. Đưa logic nhẹ ra edge (CORS, redirect, header/cookie). Kết hợp Route 53 failover với origin group để tăng độ bền. AWS WAF \u0026amp; Application Protection Mối đe dọa và tác động Nhóm threat chính:\nDDoS và cạn kiệt tài nguyên. Tấn công lỗ hổng ứng dụng (XSS, SQLi, path traversal\u0026hellip;). Bot độc hại, traffic lạm dụng. Hậu quả: rò rỉ dữ liệu, lộ credential, spam/abuse, downtime, tăng chi phí, mất uy tín.\nBot traffic tăng mạnh Lượng bot (bao gồm bot dùng AI, scraper…) tăng rõ rệt, khiến việc phát hiện và chặn phức tạp hơn, cần cơ chế tinh vi hơn (behavioral, fingerprint…).\nRoute 53 trong bảo vệ vành đai Hệ thống DNS phân tán toàn cầu. Sẵn sàng cao, chống DDoS tốt. Thường là điểm vào đầu tiên cùng với CloudFront + WAF. Bảo vệ hạ tầng với AWS Shield Tại edge:\nSYN proxy, packet validation. Lọc và “rửa” tấn công volumetric. Điều phối routing tránh path không khỏe. Tại “border”:\nLọc traffic, phát hiện bất thường ở mức resource. Phát hiện theo health và mitigation nhắm vào resource được bảo vệ. Bảo vệ tầng ứng dụng với AWS WAF Thường đứng trước CloudFront hoặc ALB. Phát hiện HTTP flood, pattern xấu, IP đáng ngờ. Có thêm Bot Control và Fraud Control add-on. Shield Advanced incident response Phát hành metrics và alarm để kích hoạt quy trình xử lý sự cố. Truy cập SRT 24/7 để escalation. Xác định vector tấn công, nguồn chính và gợi ý phương án giảm thiểu. Khái niệm cấu hình WAF Rule và Rule Group: kết hợp managed + custom rule. Managed rules: bộ rule có sẵn (ví dụ OWASP Top 10). Custom rules: tinh chỉnh theo path/header/pattern của ứng dụng. COUNT trước, BLOCK sau: ban đầu chỉ đếm để quan sát, tránh false positive, rồi mới chuyển sang chặn. Label: gắn nhãn cho request để dùng cho logic phức tạp hơn. Scope-down: thu hẹp phạm vi rule để giảm chi phí và tránh match ngoài ý muốn. Web ACL / Protection Pack Web ACL là cấu hình WAF tổng thể: rule, rule group, default action. Gắn vào CloudFront, ALB, API Gateway. Có logging và sampling để xem log và fine-tune. WAF rules và DDoS ở tầng ứng dụng Rule đọc IP, header, URI, body rồi quyết định Allow/Block/Count hoặc trả về custom response. Rate-based rule giới hạn request theo IP (hoặc key khác), tự động bóp traffic lạm dụng. Dùng rule để giảm thiểu HTTP flood ở tầng ứng dụng. WAF label \u0026amp; loại bot Labels: do managed/custom rule thêm, đánh dấu geo, IP reputation, bot/fraud category, match… Common bots: bot tự khai báo (search engine, social, library), có thể nhận diện qua header, TLS fingerprint, IP reputation. Evasive bots: scraper, tool login/brute force, scanner… cố bắt chước người dùng thực; cần client interrogation, phân tích hành vi theo session. Lab CloudFront: Perimeter Protection So sánh S3 static origin vs S3 sau CloudFront Trong lab, so sánh direct S3 website và S3 sau CloudFront:\nCloudFront phục vụ nội dung cache nhanh hơn nhiều. Edge location + backbone AWS cho latency tốt hơn đường internet công cộng. Nén ở edge giúp giảm kích thước, tăng tốc thêm một bước. Lab AWS WAF: “Strengthen Your Web Application Defenses” Trong lab WAF, nhóm cấu hình và kiểm thử rule để chặn:\nXSS. SQL Injection. Path traversal. Mẫu abuse server-side. Bot phổ thông và bot “lẩn tránh”. API misuse. Một bài test “bí ẩn” dùng header mã hóa, đòi hỏi rule custom để chặn. Trải nghiệm sự kiện Workshop diễn ra rất đúng thời điểm với nhóm, vì ngay tối hôm trước bọn mình vừa bắt đầu cấu hình CloudFront. Mô hình flat-rate bao gồm WAF đặc biệt phù hợp với bài toán hiện tại vì giúp đơn giản hóa cả ước tính chi phí lẫn cấu hình bảo mật.\nCác phần lab khá vui và thực tế, và anh Julian hỗ trợ cực kỳ nhiệt tình, thường xuyên đi vòng để xem và giúp debug khi có lỗi cấu hình. Sau workshop, nhóm cũng tranh thủ hỏi thêm:\nHỏi: WAF có thể chặn bot, nhưng với AI agent kiểu Gemini dùng trình duyệt thật (browser integration) thì sao?\nTrả lời: Dù là Gemini hay agent khác, traffic cuối cùng vẫn là HTTP/API và thường có thể nhận diện/chặn ở tầng request. Một số agent (ví dụ vài công cụ assist dựa trên Claude) giống hệt người dùng thật và không nhất thiết gây hại, nên không phải lúc nào cũng cần chặn gắt. Sự kiện kết thúc với phần chụp ảnh kỷ niệm và quiz Kahoot; việc nhìn thấy dashboard WAF báo “chặn hết các threat trong lab” tạo cảm giác khá “đã”, giống như thấy cả pipeline bảo vệ hoạt động trơn tru từ đầu đến cuối.\nMột vài hình ảnh sự kiện Hình chụp nhóm tham dự workshop\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.4-week4/","title":"Nhật ký tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4 Hoàn thành Module 6 (Amazon RDS). Bắt đầu phác thảo proposal cho workshop. “Đổi gió” với một công nghệ ngoài AWS (Three.js) để tránh bị quá tải. Làm quen với Three.js và 3D trên trình duyệt. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Module 6 – Amazon RDS (Phần 1): + Ôn lại các khái niệm cơ bản về cơ sở dữ liệu quan hệ (RDBMS) trong bối cảnh dịch vụ managed trên AWS. + Tìm hiểu tổng quan và lợi ích của Amazon RDS so với tự quản lý database trên EC2 (backup, cập nhật bản vá, scale, Multi-AZ, read replica được quản lý). + Tìm hiểu các engine được hỗ trợ trên RDS (Aurora, MySQL, MariaDB, PostgreSQL, Oracle, SQL Server). + So sánh khi nào nên dùng RDS thay vì DynamoDB, Redshift, Neptune, ElastiCache hoặc S3 cho từng loại workload. 29/09/2025 29/09/2025 Amazon RDS – Giới thiệu Ba Module 6 – Amazon RDS (Phần 2): + Tìm hiểu các tính năng quản lý của RDS: automated backup, snapshot, maintenance window, cập nhật phần mềm, thông báo sự kiện qua SNS. + Học về mã hóa dữ liệu at rest và in transit với KMS và SSL, cách tạo DB instance được mã hóa từ snapshot. + Ôn lại thiết kế mạng cho RDS với DB subnet group và VPC (đặt DB trong private subnet, đa AZ). + Tìm hiểu các thành phần chính trong chi phí RDS: giờ chạy instance, storage, IOPS, dung lượng backup, Multi-AZ. 30/09/2025 30/09/2025 Amazon RDS – Quản lý \u0026amp; Bảo mật Tư Module 6 – Amazon RDS (Phần 3): + Học về khía cạnh hiệu năng: các loại storage (gp2, Provisioned IOPS, magnetic) và use case tương ứng. + Tìm hiểu cơ chế hoạt động của Multi-AZ, các kịch bản failover thường gặp và cách cập nhật endpoint DNS khi failover. + Ôn lại Read Replica để scale đọc, và các mô hình HA/DR giữa AZ/Region. + Đọc thêm về snapshot, khôi phục và các lựa chọn migration với DMS và Schema Conversion Tool (SCT). 01/10/2025 01/10/2025 Amazon RDS – Hiệu năng, Multi-AZ \u0026amp; Read Replica Năm Học Three.js: + Tìm hiểu Three.js là gì và cách nó dựng đồ họa 3D trong trình duyệt dựa trên WebGL. + Học các khái niệm cốt lõi: Scene, Camera, Renderer, Mesh, Geometry, Material và ánh sáng cơ bản. + Làm theo ví dụ cơ bản để dựng một vật thể 3D quay đơn giản và thử điều khiển camera. + Ghi chú lại các ý tưởng dùng Three.js để làm visualization/interactive cho project sau này. 02/10/2025 02/10/2025 Three.js Documentation Sáu Tham gia sự kiện “AI-Driven Development Life Cycle: Reimagining Software Engineering”. 03/10/2025 04/10/2025 – Kết quả đạt được trong tuần 4 Xây dựng được nền tảng lý thuyết vững chắc về Amazon RDS: engine, bảo mật, mạng, Multi-AZ và mô hình Read Replica. Hiểu rõ hơn vị trí của RDS so với các dịch vụ dữ liệu khác trên AWS như DynamoDB, Redshift, Neptune, ElastiCache và S3. “Đổi gió” khỏi nội dung thuần AWS bằng cách học Three.js, nắm được các khái niệm 3D cơ bản và thử nghiệm scene đơn giản cho ý tưởng project sau này. Duy trì nhịp học và mở rộng góc nhìn về AI/software engineering thông qua việc tham dự một sự kiện về AI-Driven Development. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/4-eventparticipated/","title":"Các sự kiện đã tham gia","tags":[],"description":"","content":"Trong thời gian thực tập, mình đã tham gia 7 sự kiện. Mỗi sự kiện đều là một trải nghiệm đáng nhớ, mang lại thêm nhiều kiến thức mới, thú vị và hữu ích, cùng với quà tặng và những khoảnh khắc rất vui với mọi người.\nEvent 1 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 09:00, ngày 03/10/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Tham dự (Attendee)\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS\nThời gian: 08:30, ngày 15/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Tham dự (Attendee)\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #2 – DevOps on AWS\nThời gian: 08:30, ngày 17/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Tham dự (Attendee)\nEvent 4 Tên sự kiện: Secure Your Applications: AWS Perimeter Protection Workshop\nThời gian: 08:30, ngày 19/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Tham dự (Attendee)\nEvent 5 Tên sự kiện: AWS Well-Architected – Security Pillar Workshop\nThời gian: 08:30, ngày 29/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Tham dự (Attendee)\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.4-setup-cloudfront/","title":"Cài đặt Cloudfront","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Cloudfront để cache, định tuyến và truy cập web.\nTạo Cloudfront Distribution Mở Cloudfront Console\nĐiều hướng tới https://console.aws.amazon.com/cloudfront/ Hoặc: AWS Management Console → Services → Cloudfront Tạo Distribution:\nNhấn nút Create distribution Trong phần tạo distribution, sử dụng cài đặt này: Chọn plan: Free plan Name: Static Dashboard Website CloudFront Origin type: Amazom S3 S3 Origin: Chọn static-dashboard-bucket Giữ phần còn lại như mặc định Bật security: Sử dụng cái này nếu bạn chọn free plan Xem lại và nhấn Create distribution Cài đặt chung (General setting):\nSau khi tạo xong, trên tab General của Cloudfront nhấn vào Edit Tại Default root object nhập index.html Description: Static Dashboard Distribution Nhấn Save change Tạo API Gateway origin:\nNhấn Origins trên các tab menu Sau đó nhấn Create origin Trong phần tạo origin, sử dụng cài đặt này: Origin domain: chọn dashboard-api Protocol: HTTPS only HTTPS port: 443 Minimum Origin SSL protocol: TLSv1.2 Origin path: /prod Nhấn Create origin Tạo behaviors cho API Gateway:\nNhấn Behaviors trên các tab menu Sau đó nhấn Create behavior Trong phần tạo behavior, sử dụng cài đặt này: Path pattern: /logs/* Origin và origin groups: chọn dashboard-api Để các cài đặt còn lại như mặc định Nhấn Create behavior Cập nhật S3 policy để hoạt động với Cloudfront:\nNhấn Origins trên các tab menu, chọn tên origin s3-static-dashboard Nhấn Edit Tại phần Origin access controll nhấn Go to S3 bucket permissions Kiểm tra xem quyền S3 của bạn có giống thế này không, nếu không hãy copy và paste nó vào quyền S3 của bạn (Thay đổi ACCOUNT_ID, ACCOUNT_REGION và CLOUDFRONT_ID thành của bạn): { \u0026#34;Version\u0026#34;: \u0026#34;2008-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PolicyForCloudFrontPrivateContent\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-static-dashboard-[ACCOUNT_ID]-[ACCOUNT_REGION]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::[ACCOUNT_ID]:distribution/[CLOUDFRONT_ID]\u0026#34; } } } ] } Nhấn Save change Tạo error pages:\nNhấn Error pages trên các tab menu Nhấn Create custom error page Trong phần tạo custom error page, sử dụng cài đặt này: HTTP error code: 403: Forbident Error caching minimum TTL: 300 Customize error response: Yes Response page path: /index.html HTTP Response code: 200: OK Lặp lại bước này cho 404 code "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"Mã CloudWatch ENI ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # Cột 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # Cột 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # Cột 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # Cột 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duyệt qua các file S3 gửi về (Iterate through files sent from S3) for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Chỉ xử lý file .gz (Process .gz files only) if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # Đọc nội dung (Read content) content = read_gz(bucket, key) if not content: continue # Parse từng dòng log (Parse each log line) for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuyển thành JSON string và thêm xuống dòng (\\n) (Convert to JSON string and add newline) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Đẩy sang Firehose (Batching 500 dòng) (Push to Firehose - batching 500 lines) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"Mã CloudWatch ENI ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # Cột 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # Cột 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # Cột 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # Cột 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duyệt qua các file S3 gửi về (Iterate through files sent from S3) for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Chỉ xử lý file .gz (Process .gz files only) if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # Đọc nội dung (Read content) content = read_gz(bucket, key) if not content: continue # Parse từng dòng log (Parse each log line) for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuyển thành JSON string và thêm xuống dòng (\\n) (Convert to JSON string and add newline) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Đẩy sang Firehose (Batching 500 dòng) (Push to Firehose - batching 500 lines) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/","title":"Thiết lập giám sát","tags":[],"description":"","content":"Giai đoạn Thiết lập giám sát này kích hoạt và cấu hình ba nguồn log cốt lõi để phát hiện mối đe dọa. Giai đoạn này bao gồm việc bật CloudTrail cho các sự kiện quản lý và dữ liệu toàn diện, kích hoạt GuardDuty để xuất các phát hiện bảo mật sang S3 bucket chính, và thiết lập VPC Flow Logs trên mạng của bạn để gửi tất cả metadata lưu lượng truy cập đến CloudWatch Log Group chuyên dụng. Điều này đảm bảo luồng dữ liệu log liên tục, tập trung luôn sẵn sàng cho việc xử lý và phản hồi tự động.\nTạo CloudWatch Log Group Mở CloudWatch Console → Log Management → Create log group Cấu hình:\nLog group name: /aws/incident-response/centralized-logs Retention: 90 ngày KMS key: None Nhấn \u0026ldquo;Create\u0026rdquo;\nBật AWS CloudTrail Mở CloudTrail Console → Trail → Create trail Thuộc tính Trail:\nTrail name: incident-responses-cloudtrail-ACCOUNT_ID-REGION Storage location: Sử dụng S3 bucket hiện có S3 bucket: Chọn incident-response-log-list-bucket-ACCOUNT_ID-REGION của bạn Log file SSE-KMS encryption: Disable (Tắt) Log file validation: Enabled (Bật) Nhấn next Chọn log events:\nEvents Chọn Management events, Data events Management events: Tất cả (Read + Write) Data events: S3 - Log tất cả events Nhấn next đến bước 4 và Create Trail Advanced event selectors: Loại trừ log buckets:\nNhấn vào Trail sau đó cuộn xuống Data Event và nhấn Edit Thiết lập như hình với định dạng dưới đây: -arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\n-arn:aws:s3:::athena-query-results-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/\nLưu thay đổi Bật Amazon GuardDuty Mở GuardDuty Console → Get Started → Enable GuardDuty\nCấu hình cài đặt:\nFinding export frequency: Update CWE và S3 mỗi 15 phút S3 export: incident-response-log-list-bucket-ACCOUNT_ID-REGION KMS encryption: Chọn hoặc tạo KMS key Bật VPC Flow Logs Mở VPC Console → Your VPCs → Chọn VPC của bạn\nActions → Create flow log\nCấu hình:\nFilter: All (Tất cả) Aggregation interval: 10 phút Destination: CloudWatch Logs Log group: /aws/incident-response/centralized-logs IAM role: FlowLogsIAMRole Log format: Default (Mặc định) Tạo flow log\nBật VPC DNS Query Logging Cấu hình Resolver Query Logging Mở Amazon Route 53 Console.\nỞ thanh điều hướng bên trái, chọn VPC Resolver -\u0026gt; Query logging.\nNhấn \u0026ldquo;Configure query logging\u0026rdquo;.\nCấu hình:\nName: Nhập tên mô tả, ví dụ: IR-DNS-Query-Log-Config. Destination for query logs: CloudWatch Logs log group Log group: Chọn \u0026ldquo;Existing log group\u0026rdquo; và chọn: /aws/incident-response/centralized-logs Nhấn \u0026ldquo;Configure query logging\u0026rdquo;.\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Báo cáo sự kiện: “AWS Cloud Mastery Series #3 – AWS Well-Architected: Security Pillar Workshop” Mục tiêu sự kiện Giới thiệu AWS Cloud Club. Trụ cột 1: Identity \u0026amp; Access Management (IAM). Trụ cột 2: Phát hiện \u0026amp; Giám sát liên tục (Detection \u0026amp; Continuous Monitoring). Trụ cột 3: Bảo vệ hạ tầng (Infrastructure Protection). Trụ cột 4: Bảo vệ dữ liệu (Data Protection). Trụ cột 5: Ứng phó sự cố (Incident Response). [web:143] Diễn giả Le Vu Xuan An – AWS Cloud Club Captain, HCMUTE\nTran Duc Anh – AWS Cloud Club Captain, SGU\nTran Doan Cong Ly – AWS Cloud Club Captain, PTIT\nDanh Hoang Hieu Nghi – AWS Cloud Club Captain, HUFLIT\nHuynh Hoang Long – AWS Community Builder\nDinh Le Hoang Anh – AWS Community Builder\nNguyen Tuan Thinh – Cloud Engineer Trainee\nNguyen Do Thanh Dat – Cloud Engineer Trainee\nVan Hoang Kha – Cloud Security Engineer, AWS Community Builder\nThinh Lam – FCJ Member\nViet Nguyen – FCJ Member\nMendel Grabski (Long) – Ex-Head of Security \u0026amp; DevOps, Cloud Security Solution Architect\nTinh Truong – Platform Engineer, TymeX, AWS Community Builder\nNội dung chính AWS Cloud Club Phần mở đầu giới thiệu về AWS Cloud Club – cộng đồng do sinh viên dẫn dắt, tập trung vào học và thực hành cloud:\nGiúp sinh viên khám phá và rèn kỹ năng cloud qua sự kiện, lab, workshop. Tạo cơ hội phát triển năng lực lãnh đạo kỹ thuật (Cloud Club Captain). Kết nối với bạn bè, chuyên gia AWS và cộng đồng công nghệ rộng hơn. Các Cloud Club tham gia FCJA:\nAWS Cloud Club HCMUTE AWS Cloud Club SGU AWS Cloud Club PTIT AWS Cloud Club HUFLIT Lợi ích chính: học kỹ năng thực chiến, xây dựng cộng đồng, mở ra cơ hội nghề nghiệp qua networking, mentorship và trải nghiệm thực tế.\nIdentity \u0026amp; Access Management (IAM) IAM được trình bày như nền tảng của Security Pillar, kiểm soát “ai được làm gì” trong môi trường AWS. [web:143]\nNhiệm vụ chính:\nQuản lý danh tính (User, Group, Role) và quyền truy cập. Thực thi xác thực (authentication) và phân quyền (authorization) trên nhiều account và workload. Best practice:\nÁp dụng nguyên tắc least privilege ở mọi nơi. [web:145] Không dùng access key của root lâu dài; xóa sau khi cấu hình ban đầu. Hạn chế wildcard \u0026quot;*\u0026quot; trong Action/Resource; ưu tiên policy thu hẹp phạm vi. Dùng SSO và AWS Organizations để quản lý truy cập đa account. Cơ chế kiểm soát nâng cao:\nService Control Policies (SCP):\nẤn định “trần” quyền tối đa ở cấp Organization/OU. Chỉ hạn chế, không tự cấp quyền. Permission boundary:\nXác định quyền tối đa mà user/role có thể nhận. Hữu ích khi cho dev tự tạo role nhưng vẫn phải nằm trong guardrail. So sánh MFA:\nTOTP (Time-based OTP) FIDO2 Dùng shared secret và mã 6 số Dùng mật mã khóa công khai Nhập mã thủ công Thường chỉ cần chạm hoặc sinh trắc học Miễn phí (app authenticator) Có thể cần token phần cứng Dễ backup/khôi phục Bảo mật rất cao, gần như không có recovery Rotate credential với Secrets Manager:\nDùng Lambda rotation theo 4 bước: createSecret → setSecret → testSecret → finishSecret. Lên lịch tự động (ví dụ 7 ngày) và dùng EventBridge để điều phối. Rotate không downtime, vô hiệu an toàn version cũ. Detection \u0026amp; Continuous Monitoring Trụ cột thứ hai tập trung vào nhìn rõ hệ thống ở nhiều lớp và tự động hóa phản ứng.\nMulti-layer visibility:\nManagement events: API/console event trên toàn account (CloudTrail). Data events: Log chi tiết truy cập S3 object, Lambda invoke. Network activity: VPC Flow Logs cho traffic pattern, kết nối cho/không cho phép. Toàn tổ chức: Gom log đa account/region về một nơi. Alert \u0026amp; automation với EventBridge:\nCloudTrail đẩy event vào EventBridge để xử lý gần real-time. Rule EventBridge route event đến Lambda, SNS, SQS, v.v. Hỗ trợ cross-account, dùng một security account trung tâm. Detection-as-Code:\nDùng CloudTrail Lake hoặc log query được để định nghĩa rule phát hiện kiểu SQL. Lưu rule trong VCS và deploy bằng CI/CD cho đồng nhất. Dùng IaC để bật logging/detection cho toàn bộ account theo chuẩn chung. Amazon GuardDuty GuardDuty được nhấn mạnh là dịch vụ threat detection managed, luôn chạy nền. [web:143]\nBa nguồn dữ liệu chính:\nNguồn log Giám sát gì Ví dụ finding CloudTrail events Hành vi IAM, API call Tắt logging, tạo role quyền cao bất thường VPC Flow Logs Traffic vào/ra tài nguyên EC2 gửi dữ liệu ra máy chủ C2 điều khiển DNS logs DNS query trong môi trường Malware truy cập domain đáng ngờ/crypto-mining Gói bảo vệ mở rộng:\nS3 Protection: Phát hiện pattern truy cập object bất thường, scan malware. EKS Protection: Dùng audit log K8s để phát hiện thao tác bất thường. Malware Protection: Scan EBS volume khi nghi ngờ bị compromise. RDS Protection: Theo dõi login pattern, phát hiện brute-force. Lambda Protection: Giám sát network Lambda để phát hiện exfiltration/beaconing. Runtime Monitoring: Agent trên EC2/EKS/ECS Fargate quan sát process, file, syscall, privilege escalation. Chuẩn tuân thủ:\nGuardDuty + Security Hub hỗ trợ:\nAWS Foundational Security Best Practices. CIS AWS Foundations Benchmark. PCI DSS, NIST, và các chuẩn khác thông qua Security Hub. Compliance-as-Code:\nDùng CloudFormation hoặc IaC khác để bật GuardDuty, Security Hub, cấu hình chung. Security Hub chạy check theo standard trên S3, EC2, RDS, v.v. Gom finding về một central account phục vụ audit và cải tiến liên tục. Network Security Controls Phần này gom lại các vector tấn công và control tương ứng:\nIngress: DDoS, SQLi, port scan. Egress: Data exfiltration, DNS tunneling. Lateral: Di chuyển ngang sau khi một resource bị xâm nhập. Thành phần chính:\nSecurity Group (SG):\nStateful, gắn với ENI/instance. Chỉ có allow rule, còn lại bị chặn. Network ACL (NACL):\nStateless, gắn với subnet. Rule có thứ tự, ALLOW hoặc DENY. Hữu ích cho lớp chặn rộng. Transit Gateway SG referencing:\nCho phép tham chiếu SG qua các VPC gắn TGW, đơn giản hóa quản lý rule. Route 53 Resolver:\nĐiều phối DNS cho private hosted zone, DNS nội bộ và internet, hỗ trợ mô hình DNS tập trung. AWS Network Firewall:\nDPI, egress filter, segmentation. Rule theo domain/protocol, tích hợp threat intel để block tự động. Data Protection \u0026amp; Governance Mã hóa với KMS:\nDữ liệu dùng data key, data key được bọc bởi CMK. Policy và condition key của KMS kiểm soát ai/khung cảnh nào được encrypt/decrypt. Quản lý chứng chỉ (ACM):\nCấp chứng chỉ public miễn phí cho nhiều endpoint tích hợp AWS. Tự động gia hạn, thường 60 ngày trước khi hết hạn. Khuyến nghị DNS validation để tự động và ổn định. Quản lý secrets:\nSecrets Manager giúp loại bỏ secret hard-code trong code/pipeline. Hỗ trợ rotation tự động qua Lambda. Bảo mật ở mức dịch vụ:\nS3 \u0026amp; DynamoDB: Bắt buộc HTTPS, có thể ép aws:SecureTransport = true trong policy. RDS: Yêu cầu client trust AWS root CA. Có thể ép SSL/TLS (ví dụ rds.force_ssl=1 cho Postgres). Incident Response \u0026amp; Prevention Best practice phòng ngừa:\nƯu tiên credential tạm thời (STS, role) thay vì key dài hạn. Không mở S3/public endpoint thừa. Đặt workload nhạy cảm trong private subnet, có entry point kiểm soát. Chuẩn hóa IaC cho mọi môi trường để rebuild/audit dễ hơn. Dùng “double gate” cho thay đổi nhạy cảm: review code + phê duyệt pipeline. Vòng đời ứng phó sự cố:\nChuẩn bị: Viết runbook, tập dượt, phân vai. Phát hiện \u0026amp; phân tích: Dùng GuardDuty, Security Hub, log để xác định sự cố. Cô lập: Cắt network, rotate credential, giới hạn quyền. Xử lý \u0026amp; khôi phục: Loại bỏ root cause, rebuild hoặc restore từ bản sạch. Hậu kiểm: Họp rút kinh nghiệm, cập nhật runbook, tăng cường kiểm soát. Trải nghiệm sự kiện Workshop này cực kỳ “trúng trọng tâm” với project Automated Incident Response \u0026amp; Forensics của nhóm, nhất là phần GuardDuty, detection pipeline và pattern xử lý sự cố. [web:143]\nHỏi: Project dựa vào GuardDuty để trigger automation, nhưng độ trễ tới ~5 phút từ lúc sự việc xảy ra tới khi có finding. Có cách nào giảm rõ rệt không?\nTrả lời: Độ trễ ~5 phút là bình thường vì GuardDuty cần gom và phân tích nhiều tín hiệu để đưa ra kết luận đáng tin cậy. Để phản ứng sớm hơn, có thể kết hợp thêm công cụ bên thứ ba hoặc xây detection bổ sung dựa trên CloudTrail/log khác, sau đó dùng GuardDuty để enrich khi finding đến. [web:143]\nSau buổi workshop, anh Mendel Grabski dành thêm thời gian trao đổi về project, gợi ý hướng đi và cách tích hợp, rất hữu ích cho bước tiếp theo.\nMột vài hình ảnh sự kiện Picture of all attendees\nGroup picture with speakers Mendel Grabski and Van Hoang Kha\n"},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.5-week5/","title":"Nhật ký tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5 Tiếp tục hoàn thiện và lên kế hoạch chi tiết cho workshop proposal. Khám phá tự động hóa workflow với n8n và thử xây bot Messenger cơ bản. Học về Auto Scaling và giám sát hệ thống (CloudWatch) cho workload trên AWS. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Tìm hiểu n8n như một công cụ tự động hóa workflow (self-hosted, tương tự Zapier). Học các khái niệm chính: workflow, trigger, node, credential, execution. Triển khai n8n cục bộ bằng Docker (docker-compose cơ bản) và tạo vài workflow test đơn giản (HTTP trigger, timer, xử lý dữ liệu cơ bản). 06/10/2025 06/10/2025 Tài liệu n8n Ba Làm theo video hướng dẫn để xây một bot Messenger dùng n8n và Facebook: + Tạo Facebook App và Fanpage cho bot. + Cấu hình webhook và token để Messenger gửi tin nhắn vào n8n. + Xây flow trả lời đơn giản trong n8n để xử lý tin nhắn đến và phản hồi lại. + Test đầy đủ luồng bot từ Messenger trên điện thoại/máy tính. 07/10/2025 07/10/2025 Video hướng dẫn bot Messenger Tư Dịch 3 bài blog được giao phục vụ tài liệu và nội dung workshop, tập trung giữ đúng thuật ngữ kỹ thuật và văn phong. 08/10/2025 08/10/2025 Blog1 Blog2 Blog3 Năm Tham gia workshop “FCJ Management with Auto Scaling Group”: + Ôn lại kiến trúc tổng thể và các yêu cầu trước khi deploy ứng dụng FCJ Management. + Học cách tạo Launch Template dựa trên AMI sẵn có của FCJ Management. + Tìm hiểu cấu hình Elastic Load Balancer để phân phối traffic cho các instance ứng dụng. + Học các bước tạo và cấu hình Auto Scaling Group, thiết lập scaling policy và cách kiểm thử scale/failover. 09/10/2025 09/10/2025 FCJ Management với Auto Scaling Group Sáu Tham gia AWS CloudWatch Workshop: + Tìm hiểu mục đích chính của Amazon CloudWatch trong việc giám sát metrics, logs và events trên tài nguyên và ứng dụng AWS. + Xem lại các bước chuẩn bị để bật CloudWatch trong account. + Học CloudWatch Metrics hoạt động như thế nào, các loại metric mặc định và custom có thể thu thập. + Tìm hiểu CloudWatch Logs và cách ứng dụng gửi log tập trung để phân tích. + Học cách tạo CloudWatch Alarm và Dashboard, cũng như các bước dọn lab sau khi hoàn thành. 10/10/2025 10/10/2025 AWS CloudWatch Workshop Kết quả đạt được trong tuần 5 Nắm được các khái niệm cơ bản của n8n, triển khai được bằng Docker và kết nối thành công với Facebook Messenger để tạo một bot đơn giản. Dịch xong 3 bài blog kỹ thuật, vừa củng cố kiến thức nội dung, vừa cải thiện kỹ năng viết tài liệu cho workshop. Hiểu rõ quy trình deploy ứng dụng FCJ Management với Launch Template, Load Balancer và Auto Scaling Group trên AWS. Xây dựng nền tảng vững chắc về Amazon CloudWatch, bao gồm metrics, logs, alarm và dashboard để giám sát hệ thống trên AWS. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.5-setup-cognito/","title":"Cài đặt Cognito","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ tạo một Cognito user pool để đăng nhập dashboard.\nTạo Cognito User Pool Mở Amazon Cognito Console\nĐiều hướng tới https://console.aws.amazon.com/cognito/ Hoặc: AWS Management Console → Services → Cognito Tạo user pool:\nNhấn Create user pool Trong phần tạo user pool, sử dụng cài đặt này: Application type: Single-page application (SPA) Application name: dashboard-user-pool-client Options for sign-in identifiers: Email và Username Self-registration: Enable self-registration Required attributes for sign-up: email Add a return URL: Vào Cloudfront, chọn cái bạn vừa tạo và copy Distribution domain name và dán vào đây (Ví dụ: https://d2bvvvpr6s4eyd.cloudfront.net) Nhấn Create user directory Sau khi tạo, cuộn xuống và nhấn Go to overview Cấu hình User pool App clients:\nChọn App clients trên menu bên trái Chọn dashboard-user-pool-client Trong phần App client information, nhấn Edit Thay đổi cài đặt như hình bên dưới: Nhấn Save change Cấu hình Managed login pages:\nTrong phần Managed login pages configuration, nhấn Edit Nhấn Add sign-out URL tại phần Allowed sign-out URLs Copy URL trên callbacks URL và dán vào Allowed sign-out URLs Cuộn xuống OpenID Connect scopes thêm Profile vào scopes Nhấn Save change Tạo một user:\nTrên menu bên trái, chọn tùy chọn User Nhấn Create user Nhập thông tin người dùng của bạn Nhấn Create user "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"Mã CloudWatch Autoexport","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION (CẤU HÌNH) --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"Mã CloudWatch Autoexport","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION (CẤU HÌNH) --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.5-processing-setup/","title":"Thiết lập xử lý","tags":[],"description":"","content":"Giai đoạn Thiết lập xử lý này xây dựng đường ống dữ liệu (data pipeline) cốt lõi để cấu trúc log thô và chuẩn bị chúng cho việc phân tích truy vấn. Giai đoạn này bắt buộc triển khai ba luồng Kinesis Data Firehose để đệm và phân phối CloudTrail và VPC logs đến các S3 buckets đích. Đồng thời, bạn sẽ cấu hình AWS Glue Database và bốn bảng Athena thông qua DDL để làm cho dữ liệu có cấu trúc có thể truy vấn được. Pipeline này dựa vào năm Lambda functions ETL được kích hoạt bởi S3 Event Notifications để thực hiện chuyển đổi dữ liệu cần thiết khi log đến.\nNội dung Tạo Kinesis Data Firehose Delivery Streams Tạo AWS Glue Database và Tables Tạo Lambda Functions - Xử lý ETL "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Thiết lập hệ thống phản hồi sự cố tự động AWS Tổng quan Hướng dẫn này cung cấp quy trình từng bước hoàn chỉnh để triển khai hệ thống phản hồi sự cố và điều tra số (forensics) tự động của chúng tôi trên AWS. Hệ thống này tận dụng CloudTrail, GuardDuty, VPC Flow Logs, Kinesis Firehose, Glue, Athena, và Lambda functions được điều phối bởi AWS Step Functions để tự động phát hiện, phân tích và cách ly các tài nguyên bị xâm phạm như EC2 instances và IAM users. Khả năng điều tra log sâu hơn được bổ sung bằng cách thiết lập Security Dashboard lưu trữ trên S3 và truy cập qua CloudFront và Cognito, truy vấn log sử dụng API Gateway và Lambda.\nNội dung Tổng quan Điều kiện tiên quyết Giai đoạn 1: Thiết lập nền tảng Giai đoạn 2: Thiết lập giám sát Giai đoạn 3: Thiết lập xử lý Giai đoạn 4: Thiết lập tự động hóa Giai đoạn 5: Thiết lập Dashboard Kiểm tra Sử dụng CDK Dọn dẹp Phụ lục "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.6-week6/","title":"Nhật ký tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6 Thảo luận và chỉnh sửa proposal, nội dung workshop. Học Blender và tự làm một mô hình 3D của riêng mình. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Học các kiến thức cơ bản về Blender cho dựng hình 3D. Làm theo một số tutorial cho người mới để làm quen giao diện, cách thao tác với đối tượng, dùng modifier và thiết lập ánh sáng/render đơn giản. Tạo được sản phẩm 3D đầu tay và xuất bản render cuối cùng. Thành phẩm: Blender render. 13/10/2025 13/10/2025 – Ba Họp nhóm. Chỉnh sửa workshop proposal: chuyển sang sử dụng GuardDuty để phát hiện xâm nhập thay cho Lambda tự viết, do cần lượng dữ liệu lớn và thời gian phát triển dài. Vẽ lại kiến trúc AWS: thêm GuardDuty thay cho CloudWatch Alarm. Viết bản nháp proposal, mô tả các chức năng chính và ước tính chi phí ở mức tương đối. 14/10/2025 14/10/2025 – Tư Họp nhóm. Tiếp tục chỉnh sửa proposal: + Thêm EventBridge vào luồng xử lý. + Tối ưu lại chi phí bằng cách giảm cấu hình instance EC2 và số giờ hoạt động. Cập nhật sơ đồ kiến trúc, bổ sung icon và kết nối của EventBridge. 15/10/2025 15/10/2025 – Năm Cập nhật kiến trúc AWS: + Sắp xếp lại icon để luồng kết nối dễ nhìn hơn. + Đưa SSM vào trong group theo Region. + Thêm public subnet group cho EC2 instance. Cài Amazon Q để hỗ trợ phân tích proposal. Chỉnh sửa proposal, tính toán lại chi phí bằng AWS Pricing Calculator. 16/10/2025 16/10/2025 – Sáu Việc gia đình. Không thực hiện thêm học tập hay công việc liên quan workshop trong ngày này. 17/10/2025 17/10/2025 – Kết quả đạt được trong tuần 6 Tiến triển rõ rệt với proposal và kiến trúc workshop, liên tục lặp lại thiết kế, tối ưu chi phí và bổ sung công cụ (GuardDuty, EventBridge, Amazon Q, AWS Pricing Calculator). Hoàn thiện và triển khai được tài liệu proposal cùng worklog lên GitHub Pages. Học được các kiến thức nền tảng về Blender và hoàn thành một sản phẩm 3D đầu tay như một kỹ năng bổ trợ. Cân bằng tương đối tốt giữa công việc nhóm, kế hoạch học tập và trách nhiệm gia đình trong tuần. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.8-use-cdk/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.9-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.6-parse-findings/","title":"Mã Parse Findings","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- # --- 2. Trích xuất từ cấu trúc mảng \u0026#39;resources\u0026#39; cũ/phụ --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.6-parse-findings/","title":"Mã Parse Findings","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- # --- 2. Trích xuất từ cấu trúc mảng \u0026#39;resources\u0026#39; cũ/phụ --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.6-automation-setup/","title":"Thiết lập tự động hóa","tags":[],"description":"","content":"Giai đoạn 4: Thiết lập tự động hóa Tạo Isolation Security Group EC2 Console → Security Groups → Create security group Name: IR-Isolation-SG Description: Denies all inbound and outbound traffic for compromised instances (Chặn tất cả lưu lượng đi và đến cho các instance bị xâm phạm) VPC: Chọn VPC của bạn Inbound rules: Không có (từ chối tất cả - deny all) Outbound rules: Xóa mặc định (từ chối tất cả - deny all) Tạo và ghi lại Security Group ID (ví dụ: sg-0078026b70389e7b3) Tạo SNS Topic SNS Console → Create topic Type: Standard, Name: IncidentResponseAlerts Access policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AWSEvents_IncidentResponseAlert_Target0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;SNS:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; } ] } Tạo Lambda Functions - Phản hồi sự cố (Incident Response) ir-parse-findings-lambda Handler: parse_findings.lambda_handler Role: ParseFindingsLambdaServiceRole Code: parse-findings ir-isolate-ec2-lambda Handler: isolate_ec2.lambda_handler Role: IsolateEC2LambdaServiceRole Env: ISOLATION_SG_ID=sg-XXXXXXX (từ bước 12) Code: isolate-ec2 ir-quarantine-iam-lambda Handler: quarantine_iam.lambda_handler Role: QuarantineIAMLambdaServiceRole Env: QUARANTINE_POLICY_ARN=arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy Code: quarantine-iam ir-alert-dispatch Handler: alert_dispatch.lambda_handler Role: AlertDispatchLambdaServiceRole Env: SENDER_EMAIL, RECIPIENT_EMAIL, SLACK_WEBHOOK_URL Add SNS trigger: Topic IncidentResponseAlerts Code: alert-dispatch Cập nhật SNS Topic Subscription SNS Console → IncidentResponseAlerts → Subscriptions Xác minh: Protocol=AWS Lambda, Endpoint=ir-alert-dispatch, Status=Confirmed Tạo Step Functions State Machine Step Functions Console → Create state machine Type: Standard, Name: IncidentResponseStepFunctions Definition: Step Functions Definition Role: StepFunctionsRole Create Tạo EventBridge Rule EventBridge Console → Rules → Create rule Name: IncidentResponseAlert Event pattern: { \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;] } Targets (2): SNS topic: IncidentResponseAlerts Step Functions: IncidentResponseStepFunctions với role IncidentResponseStepFunctionsEventRole Cấu hình Athena Workgroup Athena Console → Workgroups → primary → Edit Query result location: s3://athena-query-results-ACCOUNT_ID-REGION/ Lưu (Save) "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong thời gian thực tập tại First Cloud Journey (FCJ) từ 09/09/2025 đến 05/12/2025, mình có cơ hội học hỏi, thực hành và áp dụng những kiến thức đã được học ở trường vào môi trường làm việc thực tế.\nMình tham gia vào dự án xây dựng workshop “Automated Incident Response \u0026amp; Forensics on AWS” và dashboard giám sát đi kèm, qua đó cải thiện kỹ năng về cloud (AWS), lập trình, phân tích hệ thống, đọc tài liệu tiếng Anh, viết báo cáo, làm việc nhóm và giao tiếp trong môi trường kỹ thuật.\nVề tác phong làm việc, mình luôn cố gắng hoàn thành tốt nhiệm vụ được giao, tuân thủ nội quy và quy định của đơn vị, chủ động trao đổi với mentor và các anh chị trong team để nâng cao hiệu quả công việc.\nĐể phản ánh khách quan hơn về quá trình thực tập, mình tự đánh giá theo các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức \u0026amp; kỹ năng chuyên môn Hiểu biết về lĩnh vực, áp dụng kiến thức vào thực tế, sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học nhanh, tự tìm hiểu khi gặp vấn đề ☐ ✅ ☐ 3 Tính chủ động Chủ động nhận việc, tìm việc để làm, không chỉ chờ giao việc ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành nhiệm vụ đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, quy định và quy trình làm việc ☐ ✅ ☐ 6 Tinh thần cầu tiến Sẵn sàng nhận góp ý và cố gắng cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng, biết lắng nghe và đặt câu hỏi ☐ ✅ ☐ 8 Làm việc nhóm Phối hợp tốt với đồng đội, hỗ trợ lẫn nhau trong team ✅ ☐ ☐ 9 Tác phong chuyên nghiệp Tôn trọng đồng nghiệp, mentor, đối tác và môi trường làm việc ☐ ✅ ☐ 10 Kỹ năng giải quyết vấn đề Nhận diện vấn đề, đề xuất hướng giải quyết, có tư duy sáng tạo ☐ ✅ ☐ 11 Đóng góp cho dự án/nhóm Hiệu quả công việc, ý tưởng đóng góp, mức độ được ghi nhận trong nhóm ☐ ✅ ☐ 12 Đánh giá chung Nhận xét tổng quan về toàn bộ quá trình thực tập ☐ ✅ ☐ Những điểm cần cải thiện Cần rèn luyện tính kỷ luật hơn nữa và tuân thủ thật nghiêm túc các quy định, quy trình của công ty hoặc bất kỳ tổ chức nào mình tham gia. Cải thiện tư duy giải quyết vấn đề, luyện thói quen phân tích nguyên nhân gốc rễ và thử nhiều hướng tiếp cận khác nhau. Nâng cao kỹ năng giao tiếp trong cả trao đổi hằng ngày và bối cảnh chuyên môn, bao gồm cách xử lý tình huống, đặt câu hỏi và báo cáo tiến độ một cách rõ ràng, ngắn gọn. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.7-week7/","title":"Nhật ký tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7 Học cách xây dựng website tĩnh serverless có SSL trên AWS (S3 + CloudFront + ACM + Route 53). Xây một front-end đơn giản gọi API Gateway và Lambda trong kiến trúc serverless. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Workshop “Serverless – SSL S3 Static Website”: + Tìm hiểu kiến trúc tổng thể để host website tĩnh trên S3 với HTTPS, kết hợp ACM, Route 53 và CloudFront. + Ôn lại các bước chuẩn bị và yêu cầu trước khi làm workshop. + Học cách dùng ACM để cấp và quản lý chứng chỉ SSL/TLS cho CloudFront. + Ôn lại cách dùng Route 53 (hosted zone, custom domain) để trỏ traffic về CloudFront distribution. 20/10/2025 20/10/2025 Serverless – SSL S3 Static Website Ba Serverless – Build Frontend to call API Gateway (Phần 1): + Xem kiến trúc tổng thể: front-end tĩnh trên S3/CloudFront gọi API Gateway, Lambda và DynamoDB. + Đọc phần giới thiệu và yêu cầu của workshop. + Triển khai ứng dụng front-end theo hướng dẫn. + Kiểm tra để đảm bảo front-end đã chạy ổn định và sẵn sàng kết nối với API. 21/10/2025 21/10/2025 Serverless – Build Frontend to call API Gateway Tư Serverless – Build Frontend to call API Gateway (Phần 2): + Ôn lại cách Lambda function và bảng DynamoDB hoạt động phía sau API Gateway. + Cấu hình route và integration của API Gateway theo nội dung workshop. + Test API bằng Postman, sau đó test từ front-end để xác nhận luồng end-to-end hoạt động. + Ôn lại các bước cleanup để xóa API Gateway, Lambda và tài nguyên liên quan sau khi thử nghiệm. 22/10/2025 22/10/2025 Serverless – Build Frontend to call API Gateway Năm Họp nhóm: ôn nhanh các dịch vụ AWS và trao đổi về thay đổi trong proposal. Cập nhật kiến trúc AWS, bổ sung AWS Detective. Chỉnh sửa proposal để đưa AWS Detective vào luồng xử lý và thêm plan dùng CDK sau workshop. Cấu hình EventBridge để bắt GuardDuty findings, gửi email qua SNS cho các thành viên và kích hoạt một Lambda đơn giản. Lên ý tưởng cho một trang dashboard đơn giản host trên S3, dùng API Gateway + Lambda + Athena để lấy dữ liệu forensics. 23/10/2025 23/10/2025 Tài liệu EventBridge, SNS, Lambda, Detective Sáu Chơi thử AWS Card Clash với các thành viên trong nhóm để ôn lại dịch vụ AWS và cách đặt chúng trong kiến trúc. Ôn kiến thức AWS cho kỳ kiểm tra giữa kỳ bằng cách dùng LLM tạo bộ câu hỏi theo yêu cầu. 24/10/2025 24/10/2025 AWS Card Clash Kết quả đạt được trong tuần 7 Học được cách host website tĩnh bảo mật với HTTPS trên S3 bằng cách kết hợp ACM, Route 53 và CloudFront. Hiểu rõ hơn về kiến trúc web serverless, nơi front-end tĩnh gọi API Gateway, Lambda và DynamoDB phía sau. Tiến thêm một bước với proposal và kiến trúc workshop khi bổ sung AWS Detective và tự động hóa xử lý sự kiện qua EventBridge, SNS và Lambda. Củng cố kiến thức dịch vụ AWS thông qua game AWS Card Clash và ôn tập có cấu trúc cho kỳ giữa kỳ. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Mong công ty bố trí thêm khu vực uống nước (máy lọc nước hoặc nước uống dùng chung) để mọi người dễ dàng sử dụng trong giờ làm việc, đặc biệt là những ngày làm việc dài hoặc có workshop. Nên tổ chức các sự kiện trong chuỗi AWS Cloud Mastery (hoặc các buổi định hướng tương tự) sớm hơn trong kỳ thực tập, để thực tập sinh có cái nhìn tổng quan tốt hơn và định hình project ngay từ đầu. Trong tương lai, mình rất mong có cơ hội tiếp tục tham gia hoặc hỗ trợ các khóa FCJ tiếp theo, cũng như được đóng góp thêm vào các hoạt động cộng đồng của chương trình. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.7-isolate-ec2/","title":"Mã Isolate EC2","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.7-isolate-ec2/","title":"Mã Isolate EC2","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/","title":"Thiết lập Dashboard","tags":[],"description":"","content":"Hướng dẫn này sẽ chỉ cho bạn cách thiết lập security dashboard. Security dashboard sẽ sử dụng S3 để chứa các file và thư mục web, Lambda để truy vấn dữ liệu bằng Athena, API Gateway để định tuyến api tới Lambda và Cloudfront để caching và truy cập web bằng URL của nó.\nNội dung Thiết lập S3 Thiết lập Lambda Thiết lập API Gateway Thiết lập Cloudfront Thiết lập Cognito "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.8-week8/","title":"Nhật ký tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8 Ôn tập lại kiến thức AWS. Hoàn thành bài kiểm tra giữa kỳ (FCJ Mid-Term). Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Xem lại các video học trong FCJ Bootcamp. Hoàn thành bài kiểm tra AWS Cloud Essentials Quiz. Ôn sâu các dịch vụ AWS đã học và so sánh các dịch vụ tương tự với nhau. Xem thêm một số AWS Well-Architected Labs để hiểu rõ hơn về các trụ cột chính. Thiết lập export log stream sang S3 thành công. Tạo CloudTrail trail để theo dõi hoạt động của S3 và Lambda. Kiến trúc AWS: + Nghiên cứu cách đưa AWS Step Functions vào kiến trúc workshop thay vì gom tất cả hành động IR vào một Lambda duy nhất. + Cân nhắc dùng AWS Kinesis Data Firehose để đẩy log liên tục về S3. 27/10/2025 27/10/2025 AWS Cloud Essentials Quiz AWS Well-Architected Lab Ba Cùng các thành viên trong nhóm tạo 500 flashcard về AWS để phục vụ việc ôn tập tập trung. 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ Tư Ôn bài cho kỳ thi giữa kỳ. 29/10/2025 29/10/2025 Introduction to Research for Essay Writing Năm Luyện đề với tài liệu ghi chú của AWS Certified Cloud Practitioner do cộng đồng chia sẻ: làm 5 bài practice test. Luyện thêm 40 câu hỏi practice của AWS Certified Solutions Architect Associate. 30/10/2025 30/10/2025 AWS Certified Cloud Practitioner notes AWS Certified Solutions Architect Associate practice Sáu Tham gia làm bài FCJ Midterm Exam. 31/10/2025 31/10/2025 – Kết quả đạt được trong tuần 8 Hoàn thành khối lượng luyện tập lớn trước kỳ thi bằng cách làm 5 bài practice AWS Cloud Practitioner và 40 câu hỏi AWS Solutions Architect Associate. Phối hợp với các thành viên trong nhóm tạo 500 flashcard AWS để ôn tập chủ động và có hệ thống. Ôn lại các kiến thức nền tảng về AWS qua quiz, video Bootcamp và các Well-Architected Labs, củng cố hiểu biết về các trụ cột kiến trúc. Tham gia và hoàn thành bài kiểm tra giữa kỳ FCJ Midterm Exam. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.8-verify-setup/","title":"Kiểm tra thiết lập","tags":[],"description":"","content":"Sau tất cả các giai đoạn thiết lập, vui lòng tham khảo checklist để đảm bảo việc tạo tài nguyên đã hoàn tất.\nXác minh thiết lập Checklist xác minh hoàn thành:\nIncident Response and Forensics:\n✅ S3 Buckets: Tất cả 5 buckets đã được tạo với versioning/encryption ✅ IAM Roles: Tất cả 17 roles với đúng policies ✅ CloudTrail: Logging đã được bật ✅ GuardDuty: Đã bật với S3 export ✅ VPC Flow Logs: Đang hoạt động (Active) ✅ Lambda Functions: Tất cả 9 functions đã deploy ✅ Firehose Streams: Tất cả 3 streams đang hoạt động ✅ Glue Tables: Tất cả 4 tables đã được tạo ✅ S3 Events: Tất cả 4 triggers đã được cấu hình ✅ SNS Topic: Đã tạo với subscription ✅ Step Functions: Đang hoạt động (Active) ✅ EventBridge Rule: Đã bật với 2 targets Security Dashboard:\n✅ S3 Buckets: Bucket đã được tạo với file dashboard được lưu trữ và bật hosting ✅ Query Lambda: Lambda đã được tạo với các roles thích hợp ✅ API Gateway: API Gateway đã được tạo với đúng API và tài nguyên ✅ CloudFront: Distribution đã được tạo với API và S3 origins đã cấu hình ✅ Cognito: Đã liên kết với CloudFront distribution và tạo user trong user pool Kiểm tra đầu cuối (End-to-End Test)\nTạo mẫu các phát hiện GuardDuty: 1.1 GuardDuty Console → Settings → Generate sample findings (200+ findings) hoặc 1.2 Kích hoạt một finding đơn lẻ qua CloudShell (Detector Id nằm trong GuardDuty Console → Settings ) aws guardduty create-sample-findings --detector-id [$dectector-id] --finding-types \u0026#34;Recon:EC2/PortProbeUnprotectedPort\u0026#34; Giám sát workflow: Kiểm tra EventBridge, SNS, Step Functions, Lambda logs Xác minh cảnh báo: Kiểm tra email và Slack Truy vấn dữ liệu trong Athena: "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.8-quarantine-iam/","title":"Mã Quarantine IAM","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Kiểm tra nếu policy đã được gán (Check if policy is already attached) attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.8-quarantine-iam/","title":"Mã Quarantine IAM","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Kiểm tra nếu policy đã được gán (Check if policy is already attached) attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.9-week9/","title":"Nhật ký tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9 Hỗ trợ bạn bè làm project game với scene 3D và video cho màn hình main menu. Học cách phân tích chi phí và mức sử dụng bằng AWS Glue và Amazon Athena. Bắt đầu thiết kế dashboard cho workshop. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Đám tang trong gia đình. Dành trọn ngày cho gia đình và các công việc liên quan, không học hay làm project. 03/11/2025 03/11/2025 – Ba Hỗ trợ nhóm bạn đang thực tập ở công ty khác với project game (màn hình main menu): + Thiết kế và dựng khung (blockout) scene 3D cho main menu của game. + Thiết lập góc camera và ánh sáng cơ bản phù hợp cho background main menu. + Chỉnh sửa bố cục để phù hợp với phong cách hình ảnh chung của game. 04/11/2025 04/11/2025 – Tư Tiếp tục hoàn thiện scene và video cho main menu: + Tinh chỉnh chi tiết trong scene 3D (môi trường, vật thể, ánh sáng). + Ghi hình và xuất video sequence của scene để dùng làm background cho màn hình menu. + Gửi bộ asset và video hoàn chỉnh cho team game sử dụng. 05/11/2025 05/11/2025 3D \u0026amp; video outputs Năm Học lab phân tích chi phí với AWS Glue \u0026amp; Athena: + Xem lại flow workshop phân tích báo cáo chi phí và usage bằng Glue và Athena. + Tìm hiểu cách Glue Crawler tạo bảng từ dữ liệu cost \u0026amp; usage trong S3. + Ôn lại cách dùng Athena query để phân tích chi phí và hiệu năng theo dịch vụ. 06/11/2025 06/11/2025 AWS Glue \u0026amp; Athena – Cost and Usage Analysis Sáu Thiết kế phiên bản đầu tiên của dashboard custom trên Figma: + Phác thảo layout hiển thị GuardDuty findings, xu hướng chi phí và trạng thái IR workflow. + Chọn bảng màu và typography theo phong cách AWS/cloud. + Tạo wireframe và một số màn hình hi-fi ban đầu để sau này triển khai thành dashboard host trên S3. 07/11/2025 07/11/2025 – Kết quả đạt được trong tuần 9 Dù tuần khó khăn vì đám tang, vẫn cố gắng sắp xếp thời gian để hỗ trợ bạn bè trong project game. Hoàn thiện scene 3D và video background cho main menu game, bàn giao asset sử dụng được cho nhóm bạn thực tập. Nắm được khái niệm và quy trình cơ bản dùng AWS Glue và Amazon Athena để phân tích chi phí và mức sử dụng dịch vụ. Thiết kế được bản phác thảo đầu tiên của dashboard trên Figma, đặt nền tảng UI/UX cho dashboard của workshop. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.9-alert-dispatch/","title":"Mã Alert Dispatch","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # ... (Code commented out, keeping as is or translating if needed, but it is commented out so skipping detailed translation for brevity unless enabled) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;🔴 CAO (HIGH)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;🟠 TRUNG BÌNH (MEDIUM)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;🔵 THẤP (LOW)\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;🚨 {sev} – {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;🚨 GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mức độ (Severity):*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Khu vực (Region):*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mô tả (Description):*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Tài khoản (Account):* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Loại (Type):* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH (CAO)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM (TRUNG BÌNH)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW (THẤP)\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;🚨 Cảnh báo GuardDuty: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Tài khoản:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Khu vực:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Loại:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Phát hiện:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Được tạo bởi AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.9-use-cdk/","title":"Sử dụng CDK","tags":[],"description":"","content":"Tổng quan Chúng tôi đã cung cấp CDK stack để tạo toàn bộ cơ sở hạ tầng cần thiết cho workshop này.\nĐể lấy các file, vui lòng truy cập Github Link và clone hoặc tải xuống tất cả các file về một thư mục.\nHướng dẫn cài đặt Trước khi triển khai CDK stack, bạn phải cấu hình môi trường cục bộ của mình để xác thực với tài khoản AWS bằng AWS Command Line Interface (CLI).\nCài đặt AWS CLI.\nLấy Credentials: Bạn cần một Access Key ID và một Secret Access Key từ một IAM user có quyền deployment.\nChạy lệnh cấu hình: Mở terminal và chạy lệnh aws configure.\n$ aws configure Khi được nhắc, nhập credentials và các cài đặt mong muốn. Default region name nên khớp với region nơi bạn định triển khai stack (ví dụ: ap-southeast-1):\nPrompt Example Value AWS Access Key ID AKIA... AWS Secret Access Key wJalr... Default region name ap-southeast-1 Default output format json Xác minh cấu hình: Kiểm tra thiết lập bằng cách lấy user identity. Kết quả thành công xác nhận bạn đã xác thực.\n$ aws sts get-caller-identity Điều kiện tiên quyết Đảm bảo các công cụ và dịch vụ sau đã được cài đặt và cấu hình trên hệ thống của bạn:\nPython 3.8+ và pip: Cần thiết để thực thi ứng dụng CDK và build Lambda function assets. Node.js và npm: Cần thiết để chạy AWS CDK CLI và build React dashboard. AWS CDK Toolkit: Cài đặt CDK CLI global: $ npm install -g aws-cdk Thiết lập môi trường Python Định nghĩa cơ sở hạ tầng được viết bằng Python. Một virtual environment chuyên dụng được sử dụng để quản lý các dependencies của dự án.\nTạo Virtual Environment:\n$ python -m venv .venv Kích hoạt Virtual Environment:\nOperating System Command macOS / Linux source .venv/bin/activate Windows (Command Prompt) .venv\\Scripts\\activate.bat Windows (PowerShell) .venv\\Scripts\\Activate.ps1 Cài đặt Python Dependencies:\n$ pip install -r requirements.txt Bước build dashboard Tại vị trí thư mục dự án, kiểm tra bên trong thư mục react. Nếu thư mục dist đã tồn tại, bạn không cần phải build. Nếu chưa, vui lòng làm theo các bước dưới đây. Nếu bạn đang dùng cmd sử dụng lệnh này để di chuyển vào thư mục react:\n$ cd react Và sử dụng lệnh này để liệt kê tất cả nội dung trong react:\n$ ls Điều kiện tiên quyết Đảm bảo bạn đã cài đặt Node.js và npm. Bạn có thể kiểm tra phiên bản hiện tại bằng cách chạy:\n$ npm --version Nếu lệnh không được nhận diện, vui lòng tải và cài đặt Node.js từ nodejs.org\nCài đặt dependencies Chạy lệnh sau để cài đặt tất cả các thư viện cần thiết:\n$ npm install Build Project Sau khi cài đặt hoàn tất, chạy lệnh build:\n$ npm run build Sau khi hoàn tất, một thư mục dist sẽ được tạo ra chứa index.html và thư mục assets.\nCấu hình Deployment Context Stack sử dụng các biến context (context variables). Các biến này được đọc từ cdk.context.json hoặc cung cấp qua cờ (flags) dòng lệnh.\nVariable Name Description Required if functionality is desired Default Value (in cdk.context.json) vpc_ids Danh sách các VPC IDs cho Flow Logs và DNS Query Logging. Có [] alert_email Danh sách các địa chỉ email cho thông báo cảnh báo (yêu cầu SES). Có [] sender_email Địa chỉ email người gửi SES đã xác thực. Có (nếu alert_email được thiết lập) \u0026quot;\u0026quot; slack_webhook_url Slack webhook URL để gửi cảnh báo. Không \u0026quot;\u0026quot; Ví dụ\n{ \u0026#34;vpc_ids\u0026#34;: [ \u0026#34;vpc-a1b2c3d4e5f6g7h8i\u0026#34; ], \u0026#34;alert_email\u0026#34;: [ \u0026#34;admin@example.com\u0026#34; ], \u0026#34;sender_email\u0026#34;: \u0026#34;alerts@your-domain.com\u0026#34;, \u0026#34;slack_webhook_url\u0026#34;: \u0026#34;\u0026#34; } Triển khai Stacks (Deploy) Trước khi xử lý tiếp, nếu đang ở trong thư mục /react, nhập lệnh này để quay lại thư mục chính:\n$ cd.. CDK Bootstrapping: Nếu bạn chưa từng sử dụng AWS CDK trong tài khoản AWS và region mục tiêu trước đây, chạy lệnh bootstrap một lần để cung cấp các tài nguyên cần thiết (ví dụ: S3 deployment bucket).\n$ cdk bootstrap (Tùy chọn) Synthesize và Diff: Xem lại các thay đổi CloudFormation được đề xuất trước khi deployment:\n$ cdk synth --all $ cdk diff --all Execute Deployment: Chạy lệnh deployment và phê duyệt bất kỳ thay đổi bảo mật IAM nào được yêu cầu khi được nhắc.\n$ cdk deploy --all Việc deployment hoàn tất khi CDK CLI báo cáo thành công cho stack: AwsIncidentResponseAutomationCdkStack và DashboardCdkStack\nLƯU Ý QUAN TRỌNG: Sau khi deployment hoàn tất, bạn nên xác minh email trong SES. Tạo một user trong Cognito để có thể đăng nhập vào Dashboard. Truy cập Security Group và xóa quy tắc outbound mặc định khỏi QuarantineSecurityGroup "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.10-week10/","title":"Nhật ký tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10 Thử nghiệm host website tĩnh bằng S3 và CloudFront. Thiết lập domain thật và luồng CI/CD cho dashboard viết bằng React. Khám phá mod âm thanh cho World of Tanks bằng Wwise. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Xây một website test cơ bản để kiểm tra static hosting với S3 và CloudFront: + Tạo một S3 bucket cấu hình cho static website hosting. + Deploy một trang HTML/CSS đơn giản lên S3. + Tạo CloudFront distribution trỏ tới bucket để kiểm tra phân phối nội dung toàn cầu và caching. 10/11/2025 10/11/2025 Tài liệu AWS S3 \u0026amp; CloudFront Ba Mua domain trên Porkbun và kết nối vào website: + Đăng ký custom domain và cấu hình DNS record. + Trỏ domain về CloudFront distribution. Bắt đầu hiện thực dashboard bằng React để sau này deploy lên S3/CloudFront. 11/11/2025 11/11/2025 Tài liệu Porkbun, tài liệu React Tư Đưa project React dashboard lên GitHub và thiết lập tự động deploy: + Push source code dashboard lên GitHub repository. + Cấu hình GitHub Actions workflow để build React app mỗi lần push. + Tự động upload build lên S3 và invalidate CloudFront cache sau mỗi lần deploy. 12/11/2025 12/11/2025 Tài liệu GitHub Actions, AWS CLI / SDK Năm Tìm hiểu cách mod âm thanh cho World of Tanks bằng Wwise: + Đọc kỹ hướng dẫn mod Wwise và tài liệu mod chính thức cho World of Tanks. + Nghiên cứu cấu trúc thư mục, sound bank và luồng sự kiện âm thanh cần thiết. + Ghi chú cách đóng gói và nạp mod âm thanh custom vào game. 13/11/2025 13/11/2025 Hướng dẫn tạo Wwise mod Wwise project cho World of Tanks Sáu Hoàn thành và phát hành một sound mod cho World of Tanks bằng Wwise: + Chốt sound bank và cấu hình theo đúng hướng dẫn. + Test mod trong game để đảm bảo âm thanh load và phát đúng như mong muốn. + Đăng mod hoàn chỉnh lên WGMods: Mod đã phát hành. 14/11/2025 14/11/2025 – Kết quả đạt được trong tuần 10 Thiết lập thành công website tĩnh trên S3 + CloudFront và gắn được custom domain mua trên Porkbun. Xây dựng và tự động hóa luồng deploy cho React dashboard bằng GitHub Actions, S3 và CloudFront invalidation. Hoàn thiện và phát hành một sound mod cho World of Tanks sử dụng Wwise, bao gồm test trong game và đưa mod lên WGMods. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.10-cleanup/","title":"Dọn dẹp","tags":[],"description":"","content":"Chúc mừng bạn đã hoàn thành workshop này! Trong workshop này, bạn đã tạo một Hệ thống Phản hồi Sự cố và Điều tra số Tự động và làm quen với Lambda, Step Functions, EventBridge, Glue, Athena, CloudFront, Cognito, S3 Buckets\nHướng dẫn dọn dẹp: Hướng dẫn dọn dẹp cho thiết lập thủ công Hướng dẫn dọn dẹp cho thiết lập CDK "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.10-cleanup/5.10.1-manual-cleanup/","title":"Dọn dẹp thủ công","tags":[],"description":"","content":"Clean up (Thiết lập cơ sở hạ tầng thủ công) Giai đoạn 1: Dọn dẹp Automation và Monitoring Mục tiêu ở đây là dừng tất cả các tiến trình đang hoạt động và xóa các tài nguyên monitoring và automation cốt lõi (EventBridge, Step Functions, SNS, GuardDuty, Flow Logs, CloudTrail).\n1. Xóa Incident Response Automation 1.1 Xóa EventBridge Rule\nVào EventBridge Console → Rules. Chọn rule: IncidentResponseAlert. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.2 Xóa Step Functions State Machine\nVào Step Functions Console → State Machines. Chọn State Machine: IncidentResponseStepFunctions. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.3 Xóa SNS Topic và Subscription\nVào SNS Console → Topics → IncidentResponseAlerts. Đầu tiên, xóa subscription liên kết với ir-alert-dispatch. Sau đó, xóa chính topic bằng cách nhấn \u0026ldquo;Delete topic\u0026rdquo;. 1.4 Xóa GuardDuty Detector\nVào GuardDuty Console → Settings → General. Nhấn \u0026ldquo;Suspend\u0026rdquo; để dừng xử lý, sau đó nhấn \u0026ldquo;Disable GuardDuty\u0026rdquo; (hoặc \u0026ldquo;Delete detector\u0026rdquo;). 1.5 Vô hiệu hóa VPC Flow Logs\nVào VPC Console → VPC Flow Logs. Chọn flow log đã tạo (liên kết với YOUR_VPC_ID). Nhấn \u0026ldquo;Delete flow log\u0026rdquo;. 1.6 Xóa CloudTrail Trail\nVào CloudTrail Console → Trails. Chọn trail: incident-responses-cloudtrail-ACCOUNT_ID-REGION. Nhấn \u0026ldquo;Delete\u0026rdquo;. Giai đoạn 2: Dọn dẹp Lambda và Compute 2. Xóa tất cả Lambda Functions (9 Functions) Vào Lambda Console và xóa các functions sau:\nincident-response-cloudtrail-etl incident-response-guardduty-etl cloudwatch-etl-lambda cloudwatch-eni-etl-lambda cloudwatch-export-lambda ir-parse-findings-lambda ir-isolate-ec2-lambda ir-quarantine-iam-lambda ir-alert-dispatch 3. Xóa Isolation Security Group Vào EC2 Console → Security Groups. Tìm và chọn Security Group: IR-Isolation-SG (sử dụng ID sg-XXXXXXX). Nhấn \u0026ldquo;Delete security group\u0026rdquo;. 4. Xóa CloudWatch Log Groups Vào CloudWatch Console → Log Groups và xóa:\nCentralized log group: /aws/incident-response/centralized-logs. Bất kỳ Lambda log groups nào liên quan đến 9 functions đã xóa (ví dụ: /aws/lambda/ir-parse-findings-lambda). Giai đoạn 3: Dọn dẹp Processing và Data Lake 5. Xóa Kinesis Data Firehose Streams Vào Kinesis Console → Delivery Streams và xóa:\ncloudtrail-firehose-stream vpc-dns-firehose-stream vpc-flow-firehose-stream 6. Xóa AWS Glue Tables và Database 6.1 Xóa Glue Tables\nVào Glue Console → Tables. Chọn và xóa: security_logs.processed_cloudtrail, security_logs.processed_guardduty, security_logs.vpc_logs, và security_logs.eni_flow_logs. 6.2 Xóa Glue Database\nVào Glue Console → Databases. Chọn database: security_logs và nhấn \u0026ldquo;Delete\u0026rdquo;. 7. Xóa IAM Roles và Policies 7.1 Xóa IAM Policies\nVào IAM Console → Policies. Xóa custom managed policy: IrQuarantineIAMPolicy. Lưu ý: Inline policies được tạo trong quá trình cài đặt sẽ tự động bị xóa khi role tương ứng bị xóa. 7.2 Xóa IAM Roles\nVào IAM Console → Roles. Xóa 17 roles sau: Lambda Execution Roles: CloudTrailETLLambdaServiceRole, GuardDutyETLLambdaServiceRole, CloudWatchETLLambdaServiceRole, CloudWatchENIETLLambdaServiceRole, CloudWatchExportLambdaServiceRole, ParseFindingsLambdaServiceRole, IsolateEC2LambdaServiceRole, QuarantineIAMLambdaServiceRole, AlertDispatchLambdaServiceRole. Service Roles: CloudTrailFirehoseRole, CloudWatchFirehoseRole, StepFunctionsRole, IncidentResponseStepFunctionsEventRole, FlowLogsIAMRole, GlueCloudWatchRole. Giai đoạn 4: Dọn dẹp S3 Bucket (Xóa dữ liệu) 8. Làm trống và Xóa S3 Buckets Đây là bước cuối cùng để đảm bảo tất cả các khoản phí lưu trữ được dừng lại.\nBucket Name Mục đích incident-response-log-list-bucket-ACCOUNT_ID-REGION Nguồn Log Chính (CloudTrail/GuardDuty/Exported CW) processed-cloudtrail-logs-ACCOUNT_ID-REGION Firehose Destination cho CloudTrail logs processed-cloudwatch-logs-ACCOUNT_ID-REGION Firehose Destination cho VPC DNS/Flow logs processed-guardduty-findings-ACCOUNT_ID-REGION ETL Destination cho GuardDuty logs athena-query-results-ACCOUNT_ID-REGION Lưu trữ kết quả truy vấn Athena Vào S3 Console. Đối với mỗi bucket trong 5 buckets: Nhấn vào tên bucket. Vào tab \u0026ldquo;Objects\u0026rdquo;. Nhấn \u0026ldquo;Empty\u0026rdquo; để xóa tất cả dữ liệu. Bạn phải xác nhận việc xóa vĩnh viễn bằng cách gõ permanently delete. Quay lại danh sách S3 bucket, chọn bucket, và nhấn \u0026ldquo;Delete\u0026rdquo;. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Mã Định nghĩa Step Functions ASL","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2 (Kiểm tra nếu là EC2)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM (Kiểm tra nếu là IAM)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Mã Định nghĩa Step Functions ASL","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2 (Kiểm tra nếu là EC2)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM (Kiểm tra nếu là IAM)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.11-week11/","title":"Nhật ký tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11 Tinh chỉnh và kết nối các thành phần của project (dashboard, API, data layer). Chuẩn bị cho giai đoạn hạ tầng-as-code với AWS CDK. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Tham gia sự kiện AWS Cloud Mastery Series #2 – DevOps on AWS. Học thêm nhiều góc nhìn về cách dùng CloudFormation và CDK để quản lý hạ tầng. Nhận được một số gợi ý từ mentor về chiến lược demo cho project và ghi lại cảm nhận, kinh nghiệm sau sự kiện. 17/11/2025 17/11/2025 Event Summary and Experience Ba Thiết lập API Gateway và một Lambda đơn giản để thử gọi API từ dashboard: + Tạo REST API trong API Gateway với Lambda proxy integration. + Viết Lambda handler cơ bản trả về JSON test. + Kết nối React dashboard tới endpoint của API và kiểm tra luồng end-to-end. 18/11/2025 18/11/2025 Lambda proxy integration trong API Gateway Tư Cập nhật Lambda để truy vấn dữ liệu bằng Athena: + Cài một Lambda có nhiệm vụ gửi câu lệnh query lên Athena và chờ kết quả. + Cấu hình vị trí S3 lưu kết quả query của Athena. + Kiểm tra để đảm bảo Lambda trả được kết quả về dashboard thông qua API Gateway. 19/11/2025 19/11/2025 Query Athena từ Lambda Năm Tinh chỉnh lại kiến trúc bên ngoài xung quanh dashboard: + Tạm thời loại Route 53 ra khỏi kiến trúc ở giai đoạn này, dùng CloudFront làm entry point chính. + Test lại toàn bộ luồng giữa CloudFront, API Gateway và Lambda. + Cập nhật sơ đồ kiến trúc và ghi chú để phản ánh đường đi mới, gọn hơn. 20/11/2025 20/11/2025 – Sáu Nghiên cứu AWS CDK để chuẩn bị chuyển kiến trúc sang hạ tầng-as-code: + Xem lại cách cài đặt và bootstrap dự án AWS CDK. + Học các khái niệm cơ bản: App, Stack, Construct và cách khai báo tài nguyên hạ tầng bằng code. + Tham khảo ví dụ khai báo API Gateway, Lambda, S3/CloudFront bằng CDK. 21/11/2025 23/11/2025 AWS CDK GitHub AWS CDK Developer Guide Kết quả đạt được trong tuần 11 Hiểu rõ hơn về CDK và CloudFormation thông qua AWS Cloud Mastery Series #2, đồng thời thu thập được nhiều góp ý hữu ích cho phần demo project. Kết nối thành công React dashboard với REST API xây bằng API Gateway và Lambda, kiểm chứng được flow proxy integration và response JSON cơ bản. Xây dựng được Lambda truy vấn Athena và trả kết quả về dashboard, giúp mở đường cho các màn hình data-driven. Đơn giản hóa và xác nhận kiến trúc bên ngoài bằng việc test luồng CloudFront → API Gateway → Lambda (không dùng Route 53), và sẵn sàng đưa kiến trúc này vào AWS CDK. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/5.11-appendices/","title":"Phụ lục","tags":[],"description":"","content":"Phụ lục Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/5-workshop/5.11-appendices/","title":"Phụ lục","tags":[],"description":"","content":"Phụ lục Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.12-week12/","title":"Nhật ký tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12 Tối ưu truy vấn Athena và hiệu năng dashboard. Cải thiện UI/UX và quy trình deploy cho dashboard. Bắt đầu định nghĩa hạ tầng dashboard bằng AWS CDK. Công việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Tham gia GitHub organization của team thay vì tạo org mới, và sắp xếp lại các repository cho dashboard và backend. Dọn lại cấu trúc repo và phân quyền để dễ phối hợp làm việc về sau. 24/11/2025 24/11/2025 – Ba Áp dụng partition projection cho bảng Athena để tối ưu truy vấn: + Xem lại các partition hiện có và định nghĩa bảng dùng cho dữ liệu cost/performance. + Cấu hình các thuộc tính partition projection trên bảng Athena để giảm số lần truy vấn metadata. + Test truy vấn trước và sau khi bật partition projection để kiểm tra tốc độ planning và lượng dữ liệu quét được cải thiện. 25/11/2025 25/11/2025 Athena partition projection Tư Cải thiện UI cho dashboard: + Tinh chỉnh layout cho các panel chính (threats, trạng thái IR workflow, cost metrics). + Chỉnh lại màu sắc, font chữ, khoảng cách để giao diện dễ nhìn và dễ đọc hơn. + Mài giũa lại các biểu đồ/thẻ thông tin để dữ liệu dễ scan hơn trong lúc demo. 26/11/2025 26/11/2025 – Năm Chuyển repo dashboard từ GitHub sang GitLab và thiết lập GitLab CI: + Import project React dashboard hiện có vào GitLab. + Tạo file .gitlab-ci.yml để build dự án và deploy file tĩnh lên S3. + Thêm bước invalidate CloudFront sau mỗi lần deploy thành công. 27/11/2025 27/11/2025 GitLab CI/CD deploy lên S3 \u0026amp; CloudFront Sáu Bắt đầu viết AWS CDK cho dashboard stack: + Tạo app và stack CDK mới dành riêng cho dashboard. + Khai báo các resource S3 để host dashboard tĩnh. + Thêm các IAM policy cơ bản phục vụ việc deploy và truy cập bucket (sau này sẽ mở rộng). 28/11/2025 30/11/2025 AWS CDK Developer Guide Kết quả đạt được trong tuần 12 Tổ chức lại cách làm việc với mã nguồn bằng cách tham gia GitHub org sẵn có và sắp xếp lại repo cho project. Cải thiện hiệu năng Athena bằng partition projection, giúp giảm overhead phần planning và lượng dữ liệu bị scan. Nâng cấp trải nghiệm dashboard (UI/UX) và chuyển pipeline deploy từ GitHub sang GitLab CI với S3 + CloudFront. Khởi tạo stack CDK cho dashboard, bắt đầu từ S3 và IAM để từng bước chuyển sang hạ tầng-as-code hoàn chỉnh. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/1-worklog/1.13-week13/","title":"Nhật ký tuần 13","tags":[],"description":"","content":"Mục tiêu tuần 13 Hoàn thành project và nộp bài.\nCông việc thực hiện trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Hai Tiếp tục viết AWS CDK cho backend và lớp edge của dashboard: + Mở rộng CDK app hiện có để khai báo các Lambda dùng cho API của dashboard. + Thêm cấu hình CloudFront distribution để phục vụ dashboard và điều hướng các đường dẫn API. + Định nghĩa tài nguyên API Gateway và integration với Lambda bằng CDK. 01/12/2025 01/12/2025 CDK Lambda + API tutorial Ba Thêm Amazon Cognito vào kiến trúc để hỗ trợ đăng nhập cho dashboard: + Thiết kế vị trí của Cognito user pool giữa front-end và API Gateway. + Ôn lại luồng authentication và cách token được dùng để bảo vệ API. + Cập nhật sơ đồ kiến trúc để bổ sung Cognito và ghi chú cho phần triển khai sau này. 02/12/2025 02/12/2025 Amazon Cognito user pools Tư Kiểm thử deploy CDK và debug lỗi: + Chạy cdk synth và cdk deploy cho các stack liên quan đến dashboard. + Sửa lỗi logic và phân quyền (IAM policy, thiếu biến môi trường, sai reference, v.v.). + Deploy lại nhiều lần cho đến khi CloudFront, API Gateway và Lambda hoạt động đúng như mong đợi. 03/12/2025 03/12/2025 – Năm Gộp các stack của các thành viên và test deploy tổng thể: + Kéo các CDK stack của những thành viên khác trong organization. + Tích hợp các stack đó (ETL, IR workflow, thành phần bảo mật) với stack dashboard. + Deploy ứng dụng tổng thể và kiểm tra các stack chạy cùng nhau mà không bị xung đột. 04/12/2025 04/12/2025 – Sáu Việc gia đình. Không ghi nhận thêm công việc project trong ngày. 05/12/2025 05/12/2025 – Kết quả đạt được trong tuần 13 Mở rộng codebase CDK để mô tả đầy đủ các thành phần Lambda, CloudFront và API Gateway phục vụ cho đường đi của dashboard từ đầu đến cuối. Thiết kế và ghi lại kiến trúc tích hợp Amazon Cognito để hỗ trợ đăng nhập và bảo vệ truy cập vào dashboard. Deploy và debug thành công các stack CDK, sau đó gộp nhiều stack của cả nhóm thành một ứng dụng có thể triển khai đồng bộ. Cân đối được thời gian giữa việc hoàn thiện project và xử lý công việc gia đình vào cuối tuần. "},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://LGK2005.github.io/LGKiet-AWS-Worklog/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]